{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import pandas as pd\n",
    "import statsmodels as st\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import torch.utils.data as data_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>egm</th>\n",
       "      <th>medianhouseprice</th>\n",
       "      <th>offencecount</th>\n",
       "      <th>traveltimetogpominutes</th>\n",
       "      <th>areakm2</th>\n",
       "      <th>ariamin</th>\n",
       "      <th>ariamax</th>\n",
       "      <th>ariaavg</th>\n",
       "      <th>commercialkm2</th>\n",
       "      <th>...</th>\n",
       "      <th>presentationstoemergencydepartments201213</th>\n",
       "      <th>traveltimetonearestpublichospitalwithemergencydepartment</th>\n",
       "      <th>presentationstoemergencydepartmentsduetoinjury</th>\n",
       "      <th>category45emergencydepartmentpresentations</th>\n",
       "      <th>numberofdwellings</th>\n",
       "      <th>population</th>\n",
       "      <th>locationx</th>\n",
       "      <th>locationy</th>\n",
       "      <th>absremotenesscategory</th>\n",
       "      <th>crime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>392.000000</td>\n",
       "      <td>3.920000e+02</td>\n",
       "      <td>3.920000e+02</td>\n",
       "      <td>392.000000</td>\n",
       "      <td>392.000000</td>\n",
       "      <td>392.000000</td>\n",
       "      <td>392.000000</td>\n",
       "      <td>392.000000</td>\n",
       "      <td>392.000000</td>\n",
       "      <td>392.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>392.000000</td>\n",
       "      <td>392.000000</td>\n",
       "      <td>392.000000</td>\n",
       "      <td>392.000000</td>\n",
       "      <td>392.000000</td>\n",
       "      <td>392.000000</td>\n",
       "      <td>392.000000</td>\n",
       "      <td>392.000000</td>\n",
       "      <td>392.000000</td>\n",
       "      <td>392.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2017.000000</td>\n",
       "      <td>4.479159e+07</td>\n",
       "      <td>6.974263e+05</td>\n",
       "      <td>8807.719388</td>\n",
       "      <td>87.531777</td>\n",
       "      <td>2427.304028</td>\n",
       "      <td>0.638564</td>\n",
       "      <td>0.915607</td>\n",
       "      <td>0.765623</td>\n",
       "      <td>0.015513</td>\n",
       "      <td>...</td>\n",
       "      <td>0.270842</td>\n",
       "      <td>25.794808</td>\n",
       "      <td>0.248449</td>\n",
       "      <td>0.567065</td>\n",
       "      <td>40813.517857</td>\n",
       "      <td>101211.071429</td>\n",
       "      <td>-0.204235</td>\n",
       "      <td>26.559082</td>\n",
       "      <td>0.589286</td>\n",
       "      <td>8604.032054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.002556</td>\n",
       "      <td>3.648647e+07</td>\n",
       "      <td>4.668703e+05</td>\n",
       "      <td>6836.585681</td>\n",
       "      <td>89.737139</td>\n",
       "      <td>4388.218811</td>\n",
       "      <td>0.926171</td>\n",
       "      <td>1.249630</td>\n",
       "      <td>1.076033</td>\n",
       "      <td>0.024319</td>\n",
       "      <td>...</td>\n",
       "      <td>0.117438</td>\n",
       "      <td>23.200132</td>\n",
       "      <td>0.039385</td>\n",
       "      <td>0.076904</td>\n",
       "      <td>24837.496782</td>\n",
       "      <td>67489.684405</td>\n",
       "      <td>103.654912</td>\n",
       "      <td>82.711984</td>\n",
       "      <td>0.702344</td>\n",
       "      <td>3506.884396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2014.000000</td>\n",
       "      <td>1.892293e+06</td>\n",
       "      <td>1.587500e+05</td>\n",
       "      <td>387.000000</td>\n",
       "      <td>4.897709</td>\n",
       "      <td>20.822930</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050232</td>\n",
       "      <td>3.930699</td>\n",
       "      <td>0.140255</td>\n",
       "      <td>0.399250</td>\n",
       "      <td>4874.000000</td>\n",
       "      <td>9873.000000</td>\n",
       "      <td>-310.285714</td>\n",
       "      <td>-81.599301</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3076.800763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2015.000000</td>\n",
       "      <td>1.182050e+07</td>\n",
       "      <td>3.520722e+05</td>\n",
       "      <td>3061.750000</td>\n",
       "      <td>20.246923</td>\n",
       "      <td>79.778887</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.180694</td>\n",
       "      <td>8.626692</td>\n",
       "      <td>0.218529</td>\n",
       "      <td>0.513066</td>\n",
       "      <td>18526.750000</td>\n",
       "      <td>41610.000000</td>\n",
       "      <td>-23.545417</td>\n",
       "      <td>-15.651445</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6471.102274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2017.000000</td>\n",
       "      <td>3.108051e+07</td>\n",
       "      <td>5.853513e+05</td>\n",
       "      <td>8011.000000</td>\n",
       "      <td>52.602954</td>\n",
       "      <td>667.579973</td>\n",
       "      <td>0.064858</td>\n",
       "      <td>0.193099</td>\n",
       "      <td>0.117857</td>\n",
       "      <td>0.002763</td>\n",
       "      <td>...</td>\n",
       "      <td>0.252941</td>\n",
       "      <td>16.079150</td>\n",
       "      <td>0.256317</td>\n",
       "      <td>0.567085</td>\n",
       "      <td>40520.000000</td>\n",
       "      <td>94681.500000</td>\n",
       "      <td>5.389039</td>\n",
       "      <td>1.222753</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8194.577278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2019.000000</td>\n",
       "      <td>6.885112e+07</td>\n",
       "      <td>9.037315e+05</td>\n",
       "      <td>12515.500000</td>\n",
       "      <td>131.271874</td>\n",
       "      <td>3206.892301</td>\n",
       "      <td>1.088661</td>\n",
       "      <td>1.512202</td>\n",
       "      <td>1.384535</td>\n",
       "      <td>0.025111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.375373</td>\n",
       "      <td>34.781852</td>\n",
       "      <td>0.278871</td>\n",
       "      <td>0.616169</td>\n",
       "      <td>59403.000000</td>\n",
       "      <td>151932.500000</td>\n",
       "      <td>27.746864</td>\n",
       "      <td>40.975396</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10228.073289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2020.000000</td>\n",
       "      <td>1.430457e+08</td>\n",
       "      <td>2.841161e+06</td>\n",
       "      <td>37886.000000</td>\n",
       "      <td>384.960766</td>\n",
       "      <td>23359.313312</td>\n",
       "      <td>3.272194</td>\n",
       "      <td>4.383425</td>\n",
       "      <td>3.737190</td>\n",
       "      <td>0.127473</td>\n",
       "      <td>...</td>\n",
       "      <td>0.553260</td>\n",
       "      <td>96.843507</td>\n",
       "      <td>0.322547</td>\n",
       "      <td>0.725373</td>\n",
       "      <td>107828.000000</td>\n",
       "      <td>298909.000000</td>\n",
       "      <td>274.239407</td>\n",
       "      <td>343.714443</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>25932.263717</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 84 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              year           egm  medianhouseprice  offencecount   \n",
       "count   392.000000  3.920000e+02      3.920000e+02    392.000000  \\\n",
       "mean   2017.000000  4.479159e+07      6.974263e+05   8807.719388   \n",
       "std       2.002556  3.648647e+07      4.668703e+05   6836.585681   \n",
       "min    2014.000000  1.892293e+06      1.587500e+05    387.000000   \n",
       "25%    2015.000000  1.182050e+07      3.520722e+05   3061.750000   \n",
       "50%    2017.000000  3.108051e+07      5.853513e+05   8011.000000   \n",
       "75%    2019.000000  6.885112e+07      9.037315e+05  12515.500000   \n",
       "max    2020.000000  1.430457e+08      2.841161e+06  37886.000000   \n",
       "\n",
       "       traveltimetogpominutes       areakm2     ariamin     ariamax   \n",
       "count              392.000000    392.000000  392.000000  392.000000  \\\n",
       "mean                87.531777   2427.304028    0.638564    0.915607   \n",
       "std                 89.737139   4388.218811    0.926171    1.249630   \n",
       "min                  4.897709     20.822930    0.000000    0.000000   \n",
       "25%                 20.246923     79.778887    0.000000    0.000000   \n",
       "50%                 52.602954    667.579973    0.064858    0.193099   \n",
       "75%                131.271874   3206.892301    1.088661    1.512202   \n",
       "max                384.960766  23359.313312    3.272194    4.383425   \n",
       "\n",
       "          ariaavg  commercialkm2  ...   \n",
       "count  392.000000     392.000000  ...  \\\n",
       "mean     0.765623       0.015513  ...   \n",
       "std      1.076033       0.024319  ...   \n",
       "min      0.000000       0.000052  ...   \n",
       "25%      0.000000       0.000368  ...   \n",
       "50%      0.117857       0.002763  ...   \n",
       "75%      1.384535       0.025111  ...   \n",
       "max      3.737190       0.127473  ...   \n",
       "\n",
       "       presentationstoemergencydepartments201213   \n",
       "count                                 392.000000  \\\n",
       "mean                                    0.270842   \n",
       "std                                     0.117438   \n",
       "min                                     0.050232   \n",
       "25%                                     0.180694   \n",
       "50%                                     0.252941   \n",
       "75%                                     0.375373   \n",
       "max                                     0.553260   \n",
       "\n",
       "       traveltimetonearestpublichospitalwithemergencydepartment   \n",
       "count                                         392.000000         \\\n",
       "mean                                           25.794808          \n",
       "std                                            23.200132          \n",
       "min                                             3.930699          \n",
       "25%                                             8.626692          \n",
       "50%                                            16.079150          \n",
       "75%                                            34.781852          \n",
       "max                                            96.843507          \n",
       "\n",
       "       presentationstoemergencydepartmentsduetoinjury   \n",
       "count                                      392.000000  \\\n",
       "mean                                         0.248449   \n",
       "std                                          0.039385   \n",
       "min                                          0.140255   \n",
       "25%                                          0.218529   \n",
       "50%                                          0.256317   \n",
       "75%                                          0.278871   \n",
       "max                                          0.322547   \n",
       "\n",
       "       category45emergencydepartmentpresentations  numberofdwellings   \n",
       "count                                  392.000000         392.000000  \\\n",
       "mean                                     0.567065       40813.517857   \n",
       "std                                      0.076904       24837.496782   \n",
       "min                                      0.399250        4874.000000   \n",
       "25%                                      0.513066       18526.750000   \n",
       "50%                                      0.567085       40520.000000   \n",
       "75%                                      0.616169       59403.000000   \n",
       "max                                      0.725373      107828.000000   \n",
       "\n",
       "          population   locationx   locationy  absremotenesscategory   \n",
       "count     392.000000  392.000000  392.000000             392.000000  \\\n",
       "mean   101211.071429   -0.204235   26.559082               0.589286   \n",
       "std     67489.684405  103.654912   82.711984               0.702344   \n",
       "min      9873.000000 -310.285714  -81.599301               0.000000   \n",
       "25%     41610.000000  -23.545417  -15.651445               0.000000   \n",
       "50%     94681.500000    5.389039    1.222753               0.000000   \n",
       "75%    151932.500000   27.746864   40.975396               1.000000   \n",
       "max    298909.000000  274.239407  343.714443               2.000000   \n",
       "\n",
       "              crime  \n",
       "count    392.000000  \n",
       "mean    8604.032054  \n",
       "std     3506.884396  \n",
       "min     3076.800763  \n",
       "25%     6471.102274  \n",
       "50%     8194.577278  \n",
       "75%    10228.073289  \n",
       "max    25932.263717  \n",
       "\n",
       "[8 rows x 84 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./final.csv', index_col=0)\n",
    "data['crime'] = data['Rate per 100,000 population']\n",
    "data = data.drop(columns=['Rate per 100,000 population'])\n",
    "\n",
    "def normalize(col):\n",
    "    col = ''.join(col.split())\n",
    "    col = ''.join(e for e in col if e.isalnum())\n",
    "    out: str = col.replace(',','_').lower()\n",
    "    if out[0].isdigit():\n",
    "        out = '_' + out\n",
    "    return out\n",
    "\n",
    "data.rename(columns=normalize, inplace=True)\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lga</th>\n",
       "      <th>year</th>\n",
       "      <th>egm</th>\n",
       "      <th>medianhouseprice</th>\n",
       "      <th>traveltimetogpominutes</th>\n",
       "      <th>areakm2</th>\n",
       "      <th>ariamin</th>\n",
       "      <th>ariamax</th>\n",
       "      <th>ariaavg</th>\n",
       "      <th>commercialkm2</th>\n",
       "      <th>...</th>\n",
       "      <th>numberofdwellings</th>\n",
       "      <th>population</th>\n",
       "      <th>locationx</th>\n",
       "      <th>locationy</th>\n",
       "      <th>absremotenesscategory</th>\n",
       "      <th>distance</th>\n",
       "      <th>last_crime</th>\n",
       "      <th>last_house</th>\n",
       "      <th>last_egm</th>\n",
       "      <th>crime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>whittlesea</td>\n",
       "      <td>2015</td>\n",
       "      <td>1.091612e+08</td>\n",
       "      <td>3.864022e+05</td>\n",
       "      <td>34.862554</td>\n",
       "      <td>590.075860</td>\n",
       "      <td>0.007974</td>\n",
       "      <td>0.056596</td>\n",
       "      <td>0.022594</td>\n",
       "      <td>0.005186</td>\n",
       "      <td>...</td>\n",
       "      <td>53907.0</td>\n",
       "      <td>166996.0</td>\n",
       "      <td>16.070609</td>\n",
       "      <td>18.525154</td>\n",
       "      <td>0</td>\n",
       "      <td>24.524392</td>\n",
       "      <td>7233.141209</td>\n",
       "      <td>3.567570e+05</td>\n",
       "      <td>1.035006e+08</td>\n",
       "      <td>6975.468257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>northerngrampians</td>\n",
       "      <td>2015</td>\n",
       "      <td>1.003788e+07</td>\n",
       "      <td>1.590000e+05</td>\n",
       "      <td>179.410340</td>\n",
       "      <td>6720.196354</td>\n",
       "      <td>2.135649</td>\n",
       "      <td>2.837918</td>\n",
       "      <td>2.452597</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>...</td>\n",
       "      <td>7094.0</td>\n",
       "      <td>13042.0</td>\n",
       "      <td>-179.798887</td>\n",
       "      <td>102.227446</td>\n",
       "      <td>2</td>\n",
       "      <td>206.828650</td>\n",
       "      <td>7947.694659</td>\n",
       "      <td>1.587500e+05</td>\n",
       "      <td>1.035065e+07</td>\n",
       "      <td>9876.331158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>greatergeelong</td>\n",
       "      <td>2015</td>\n",
       "      <td>1.130210e+08</td>\n",
       "      <td>4.230712e+05</td>\n",
       "      <td>61.820207</td>\n",
       "      <td>1389.430557</td>\n",
       "      <td>0.152898</td>\n",
       "      <td>0.224843</td>\n",
       "      <td>0.182097</td>\n",
       "      <td>0.002401</td>\n",
       "      <td>...</td>\n",
       "      <td>107828.0</td>\n",
       "      <td>249716.0</td>\n",
       "      <td>-49.407904</td>\n",
       "      <td>-36.376751</td>\n",
       "      <td>0</td>\n",
       "      <td>61.354779</td>\n",
       "      <td>8127.107630</td>\n",
       "      <td>4.084374e+05</td>\n",
       "      <td>1.116281e+08</td>\n",
       "      <td>8950.482127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>colacotway</td>\n",
       "      <td>2015</td>\n",
       "      <td>1.026330e+07</td>\n",
       "      <td>3.823333e+05</td>\n",
       "      <td>137.416278</td>\n",
       "      <td>3232.099823</td>\n",
       "      <td>1.273625</td>\n",
       "      <td>1.806754</td>\n",
       "      <td>1.531375</td>\n",
       "      <td>0.000364</td>\n",
       "      <td>...</td>\n",
       "      <td>11821.0</td>\n",
       "      <td>21429.0</td>\n",
       "      <td>-114.485347</td>\n",
       "      <td>-75.055345</td>\n",
       "      <td>1</td>\n",
       "      <td>136.894848</td>\n",
       "      <td>7259.476598</td>\n",
       "      <td>3.684167e+05</td>\n",
       "      <td>1.007489e+07</td>\n",
       "      <td>7899.199246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>moorabool</td>\n",
       "      <td>2015</td>\n",
       "      <td>1.057564e+07</td>\n",
       "      <td>3.560000e+05</td>\n",
       "      <td>58.368445</td>\n",
       "      <td>2142.863230</td>\n",
       "      <td>0.331739</td>\n",
       "      <td>0.880712</td>\n",
       "      <td>0.598316</td>\n",
       "      <td>0.000394</td>\n",
       "      <td>...</td>\n",
       "      <td>18640.0</td>\n",
       "      <td>47165.0</td>\n",
       "      <td>-63.629211</td>\n",
       "      <td>23.520312</td>\n",
       "      <td>1</td>\n",
       "      <td>67.837170</td>\n",
       "      <td>6183.609090</td>\n",
       "      <td>3.395000e+05</td>\n",
       "      <td>1.030988e+07</td>\n",
       "      <td>6857.124858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>maribyrnong</td>\n",
       "      <td>2020</td>\n",
       "      <td>4.224321e+07</td>\n",
       "      <td>8.882343e+05</td>\n",
       "      <td>11.629266</td>\n",
       "      <td>31.347530</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.068430</td>\n",
       "      <td>...</td>\n",
       "      <td>33248.0</td>\n",
       "      <td>81443.0</td>\n",
       "      <td>-7.275384</td>\n",
       "      <td>1.522394</td>\n",
       "      <td>0</td>\n",
       "      <td>7.432960</td>\n",
       "      <td>9949.698189</td>\n",
       "      <td>8.490697e+05</td>\n",
       "      <td>5.725792e+07</td>\n",
       "      <td>10239.549084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>stonnington</td>\n",
       "      <td>2020</td>\n",
       "      <td>1.411828e+07</td>\n",
       "      <td>2.841161e+06</td>\n",
       "      <td>9.937739</td>\n",
       "      <td>23.986985</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066525</td>\n",
       "      <td>...</td>\n",
       "      <td>46028.0</td>\n",
       "      <td>96855.0</td>\n",
       "      <td>4.834074</td>\n",
       "      <td>-4.292877</td>\n",
       "      <td>0</td>\n",
       "      <td>6.465065</td>\n",
       "      <td>10326.889279</td>\n",
       "      <td>2.535312e+06</td>\n",
       "      <td>1.986235e+07</td>\n",
       "      <td>10291.270757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>gleneira</td>\n",
       "      <td>2020</td>\n",
       "      <td>5.402530e+07</td>\n",
       "      <td>1.516358e+06</td>\n",
       "      <td>15.409791</td>\n",
       "      <td>41.586761</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032422</td>\n",
       "      <td>...</td>\n",
       "      <td>62435.0</td>\n",
       "      <td>150761.0</td>\n",
       "      <td>6.103827</td>\n",
       "      <td>-8.569276</td>\n",
       "      <td>0</td>\n",
       "      <td>10.520894</td>\n",
       "      <td>4799.397152</td>\n",
       "      <td>1.430137e+06</td>\n",
       "      <td>7.424468e+07</td>\n",
       "      <td>5086.773226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>bayside</td>\n",
       "      <td>2020</td>\n",
       "      <td>1.022713e+07</td>\n",
       "      <td>1.744736e+06</td>\n",
       "      <td>20.118347</td>\n",
       "      <td>35.882194</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023797</td>\n",
       "      <td>...</td>\n",
       "      <td>38495.0</td>\n",
       "      <td>97337.0</td>\n",
       "      <td>5.883758</td>\n",
       "      <td>-14.204648</td>\n",
       "      <td>0</td>\n",
       "      <td>15.375000</td>\n",
       "      <td>4849.326535</td>\n",
       "      <td>1.572118e+06</td>\n",
       "      <td>1.380787e+07</td>\n",
       "      <td>5319.088156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>mooneevalley</td>\n",
       "      <td>2020</td>\n",
       "      <td>5.749777e+07</td>\n",
       "      <td>1.261210e+06</td>\n",
       "      <td>13.016887</td>\n",
       "      <td>50.700036</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.040354</td>\n",
       "      <td>...</td>\n",
       "      <td>46767.0</td>\n",
       "      <td>115655.0</td>\n",
       "      <td>-5.548091</td>\n",
       "      <td>7.139844</td>\n",
       "      <td>0</td>\n",
       "      <td>9.042051</td>\n",
       "      <td>6550.321978</td>\n",
       "      <td>1.209735e+06</td>\n",
       "      <td>7.765076e+07</td>\n",
       "      <td>6627.703374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>336 rows Ã— 88 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   lga  year           egm  medianhouseprice   \n",
       "0           whittlesea  2015  1.091612e+08      3.864022e+05  \\\n",
       "1    northerngrampians  2015  1.003788e+07      1.590000e+05   \n",
       "2       greatergeelong  2015  1.130210e+08      4.230712e+05   \n",
       "3           colacotway  2015  1.026330e+07      3.823333e+05   \n",
       "4            moorabool  2015  1.057564e+07      3.560000e+05   \n",
       "..                 ...   ...           ...               ...   \n",
       "331        maribyrnong  2020  4.224321e+07      8.882343e+05   \n",
       "332        stonnington  2020  1.411828e+07      2.841161e+06   \n",
       "333           gleneira  2020  5.402530e+07      1.516358e+06   \n",
       "334            bayside  2020  1.022713e+07      1.744736e+06   \n",
       "335       mooneevalley  2020  5.749777e+07      1.261210e+06   \n",
       "\n",
       "     traveltimetogpominutes      areakm2   ariamin   ariamax   ariaavg   \n",
       "0                 34.862554   590.075860  0.007974  0.056596  0.022594  \\\n",
       "1                179.410340  6720.196354  2.135649  2.837918  2.452597   \n",
       "2                 61.820207  1389.430557  0.152898  0.224843  0.182097   \n",
       "3                137.416278  3232.099823  1.273625  1.806754  1.531375   \n",
       "4                 58.368445  2142.863230  0.331739  0.880712  0.598316   \n",
       "..                      ...          ...       ...       ...       ...   \n",
       "331               11.629266    31.347530  0.000000  0.000000  0.000000   \n",
       "332                9.937739    23.986985  0.000000  0.000000  0.000000   \n",
       "333               15.409791    41.586761  0.000000  0.000000  0.000000   \n",
       "334               20.118347    35.882194  0.000000  0.000000  0.000000   \n",
       "335               13.016887    50.700036  0.000000  0.000000  0.000000   \n",
       "\n",
       "     commercialkm2  ...  numberofdwellings  population   locationx   \n",
       "0         0.005186  ...            53907.0    166996.0   16.070609  \\\n",
       "1         0.000128  ...             7094.0     13042.0 -179.798887   \n",
       "2         0.002401  ...           107828.0    249716.0  -49.407904   \n",
       "3         0.000364  ...            11821.0     21429.0 -114.485347   \n",
       "4         0.000394  ...            18640.0     47165.0  -63.629211   \n",
       "..             ...  ...                ...         ...         ...   \n",
       "331       0.068430  ...            33248.0     81443.0   -7.275384   \n",
       "332       0.066525  ...            46028.0     96855.0    4.834074   \n",
       "333       0.032422  ...            62435.0    150761.0    6.103827   \n",
       "334       0.023797  ...            38495.0     97337.0    5.883758   \n",
       "335       0.040354  ...            46767.0    115655.0   -5.548091   \n",
       "\n",
       "      locationy  absremotenesscategory    distance    last_crime   \n",
       "0     18.525154                      0   24.524392   7233.141209  \\\n",
       "1    102.227446                      2  206.828650   7947.694659   \n",
       "2    -36.376751                      0   61.354779   8127.107630   \n",
       "3    -75.055345                      1  136.894848   7259.476598   \n",
       "4     23.520312                      1   67.837170   6183.609090   \n",
       "..          ...                    ...         ...           ...   \n",
       "331    1.522394                      0    7.432960   9949.698189   \n",
       "332   -4.292877                      0    6.465065  10326.889279   \n",
       "333   -8.569276                      0   10.520894   4799.397152   \n",
       "334  -14.204648                      0   15.375000   4849.326535   \n",
       "335    7.139844                      0    9.042051   6550.321978   \n",
       "\n",
       "       last_house      last_egm         crime  \n",
       "0    3.567570e+05  1.035006e+08   6975.468257  \n",
       "1    1.587500e+05  1.035065e+07   9876.331158  \n",
       "2    4.084374e+05  1.116281e+08   8950.482127  \n",
       "3    3.684167e+05  1.007489e+07   7899.199246  \n",
       "4    3.395000e+05  1.030988e+07   6857.124858  \n",
       "..            ...           ...           ...  \n",
       "331  8.490697e+05  5.725792e+07  10239.549084  \n",
       "332  2.535312e+06  1.986235e+07  10291.270757  \n",
       "333  1.430137e+06  7.424468e+07   5086.773226  \n",
       "334  1.572118e+06  1.380787e+07   5319.088156  \n",
       "335  1.209735e+06  7.765076e+07   6627.703374  \n",
       "\n",
       "[336 rows x 88 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual = data[data['year'].isin(list(range(2015, 2021)))]\n",
    "actual = actual.copy()\n",
    "\n",
    "# insert last year\n",
    "for i, row in actual.iterrows():\n",
    "    last = data[(data['year'] == row['year']-1) & (data['lga'] == row['lga'])].copy()\n",
    "    distance = np.sqrt(row['locationx'] ** 2 + row['locationy'] ** 2)\n",
    "    actual.loc[i, 'distance'] = distance\n",
    "    actual.loc[i, 'last_crime'] = last['crime'].values[0]\n",
    "    actual.loc[i, 'last_house'] = last['medianhouseprice'].values[0]\n",
    "    actual.loc[i, 'last_egm'] = last['egm'].values[0]\n",
    "\n",
    "actual = actual.reset_index(drop=True)\n",
    "actual = actual.drop(columns=['offencecount'], axis=1)\n",
    "cr = actual.pop('crime')\n",
    "actual.insert(actual.shape[1], \"crime\", cr)\n",
    "actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60 56\n",
      "0\n",
      "888074.5887995105\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>last_crime</th>\n",
       "      <th>distance</th>\n",
       "      <th>last_egm</th>\n",
       "      <th>last_house</th>\n",
       "      <th>crime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7233.141209</td>\n",
       "      <td>24.524392</td>\n",
       "      <td>1.035006e+08</td>\n",
       "      <td>3.567570e+05</td>\n",
       "      <td>6.975468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7947.694659</td>\n",
       "      <td>206.828650</td>\n",
       "      <td>1.035065e+07</td>\n",
       "      <td>1.587500e+05</td>\n",
       "      <td>9.876331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8127.107630</td>\n",
       "      <td>61.354779</td>\n",
       "      <td>1.116281e+08</td>\n",
       "      <td>4.084374e+05</td>\n",
       "      <td>8.950482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7259.476598</td>\n",
       "      <td>136.894848</td>\n",
       "      <td>1.007489e+07</td>\n",
       "      <td>3.684167e+05</td>\n",
       "      <td>7.899199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6183.609090</td>\n",
       "      <td>67.837170</td>\n",
       "      <td>1.030988e+07</td>\n",
       "      <td>3.395000e+05</td>\n",
       "      <td>6.857125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9949.698189</td>\n",
       "      <td>7.432960</td>\n",
       "      <td>5.725792e+07</td>\n",
       "      <td>8.490697e+05</td>\n",
       "      <td>10.239549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10326.889279</td>\n",
       "      <td>6.465065</td>\n",
       "      <td>1.986235e+07</td>\n",
       "      <td>2.535312e+06</td>\n",
       "      <td>10.291271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4799.397152</td>\n",
       "      <td>10.520894</td>\n",
       "      <td>7.424468e+07</td>\n",
       "      <td>1.430137e+06</td>\n",
       "      <td>5.086773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4849.326535</td>\n",
       "      <td>15.375000</td>\n",
       "      <td>1.380787e+07</td>\n",
       "      <td>1.572118e+06</td>\n",
       "      <td>5.319088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6550.321978</td>\n",
       "      <td>9.042051</td>\n",
       "      <td>7.765076e+07</td>\n",
       "      <td>1.209735e+06</td>\n",
       "      <td>6.627703</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>336 rows Ã— 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1    2    3    4    5    6    7    8    9  ...   51   52   53   \n",
       "0    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  1.0  0.0  0.0  \\\n",
       "1    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "2    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "3    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "4    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "..   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "331  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "332  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "333  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "334  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "335  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "\n",
       "      54   55    last_crime    distance      last_egm    last_house      crime  \n",
       "0    0.0  0.0   7233.141209   24.524392  1.035006e+08  3.567570e+05   6.975468  \n",
       "1    0.0  0.0   7947.694659  206.828650  1.035065e+07  1.587500e+05   9.876331  \n",
       "2    0.0  0.0   8127.107630   61.354779  1.116281e+08  4.084374e+05   8.950482  \n",
       "3    0.0  0.0   7259.476598  136.894848  1.007489e+07  3.684167e+05   7.899199  \n",
       "4    0.0  0.0   6183.609090   67.837170  1.030988e+07  3.395000e+05   6.857125  \n",
       "..   ...  ...           ...         ...           ...           ...        ...  \n",
       "331  0.0  0.0   9949.698189    7.432960  5.725792e+07  8.490697e+05  10.239549  \n",
       "332  0.0  0.0  10326.889279    6.465065  1.986235e+07  2.535312e+06  10.291271  \n",
       "333  0.0  0.0   4799.397152   10.520894  7.424468e+07  1.430137e+06   5.086773  \n",
       "334  0.0  0.0   4849.326535   15.375000  1.380787e+07  1.572118e+06   5.319088  \n",
       "335  0.0  0.0   6550.321978    9.042051  7.765076e+07  1.209735e+06   6.627703  \n",
       "\n",
       "[336 rows x 61 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one hot encode\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "\n",
    "encoded = actual.copy()\n",
    "# encoded = encoded[[\n",
    "#     'lga', 'last_crime',\n",
    "#       'distance', 'last_egm', 'egm', 'last_house', \n",
    "#       'medianhouseprice', \n",
    "#       'crime']]\n",
    "\n",
    "encoded = encoded[[\n",
    "    'lga', \n",
    "    'last_crime',\n",
    "      'distance', \n",
    "      'last_egm', \n",
    "      'last_house',\n",
    "      'crime']]\n",
    "\n",
    "new_ = encoded.select_dtypes(include=[np.number])\n",
    "\n",
    "\n",
    "# standardize all\n",
    "encoder = OneHotEncoder()\n",
    "out = encoder.fit_transform(encoded[['lga']])\n",
    "lga = pd.DataFrame(out.toarray())\n",
    "\n",
    "new = pd.concat([lga, new_], axis=1)\n",
    "crime_idx = new.columns.get_loc('crime')\n",
    "last_idx = new.columns.get_loc('last_crime')\n",
    "\n",
    "print(crime_idx, last_idx)\n",
    "\n",
    "print(np.sum(new.isna().sum()))\n",
    "print(np.mean((new[\"last_crime\"] - new[\"crime\"])**2))\n",
    "\n",
    "new['crime'] /= 1000\n",
    "\n",
    "new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(235, 60) (235,)\n",
      "(101, 60) (101,)\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.1359, 0.1505, 0.0569, 0.0725]])\n",
      "tensor([6.8571])\n",
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "# ml model\n",
    "\n",
    "\n",
    "# one hot encode\n",
    "\n",
    "state = 41\n",
    "train_data: pd.DataFrame = new.sample(frac=0.7, random_state=state)\n",
    "test_data = new.drop(train_data.index)\n",
    "\n",
    "train_y = train_data['crime'].values\n",
    "train_x = train_data.drop('crime', axis=1).values\n",
    "\n",
    "test_y = test_data['crime'].values\n",
    "test_x = test_data.drop('crime', axis=1).values\n",
    "\n",
    "scaler_x = MinMaxScaler(feature_range=(0,1))\n",
    "scaler_x.fit(train_x)\n",
    "# scaler_y.fit(train_y.reshape(-1, 1))\n",
    "\n",
    "train_x = scaler_x.transform(train_x)\n",
    "# train_y = scaler_y.transform(train_y.reshape(-1, 1))\n",
    "train_y = train_y\n",
    "\n",
    "\n",
    "test_y = test_y\n",
    "# test_y = scaler_y.transform(test_y.reshape(-1, 1))\n",
    "test_x = scaler_x.transform(test_x)\n",
    "\n",
    "print(train_x.shape, train_y.shape)\n",
    "print(test_x.shape, test_y.shape)\n",
    "\n",
    "batch_size = 1\n",
    "\n",
    "train = data_utils.TensorDataset(torch.Tensor(train_x), torch.Tensor(train_y))\n",
    "test = data_utils.TensorDataset(torch.Tensor(test_x), torch.Tensor(test_y))\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(train, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(X)\n",
    "    print(y)\n",
    "    # print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    # print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break\n",
    "\n",
    "\n",
    "# Get cpu, gpu or mps device for training.\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(train_x.shape[1], 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.02)\n",
    "\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # if batch % 10 == 0:\n",
    "            # loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            # print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            # print(np.array(X[:, last_idx]))\n",
    "            # print((np.array(X[:, last_idx]) - np.array(y)))\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    print(f\"Avg loss: {test_loss:>8f} \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss: 8.542667 \n",
      "\n",
      "Avg loss: 7.110602 \n",
      "\n",
      "Avg loss: 5.303505 \n",
      "\n",
      "Avg loss: 4.931800 \n",
      "\n",
      "Avg loss: 2.205848 \n",
      "\n",
      "Avg loss: 4.152782 \n",
      "\n",
      "Avg loss: 2.514545 \n",
      "\n",
      "Avg loss: 2.645728 \n",
      "\n",
      "Avg loss: 2.427235 \n",
      "\n",
      "Avg loss: 2.082872 \n",
      "\n",
      "Avg loss: 2.605463 \n",
      "\n",
      "Avg loss: 2.485910 \n",
      "\n",
      "Avg loss: 2.344805 \n",
      "\n",
      "Avg loss: 10.151146 \n",
      "\n",
      "Avg loss: 12.228356 \n",
      "\n",
      "Avg loss: 9.416579 \n",
      "\n",
      "Avg loss: 9.439227 \n",
      "\n",
      "Avg loss: 9.451780 \n",
      "\n",
      "Avg loss: 9.457507 \n",
      "\n",
      "Avg loss: 9.457122 \n",
      "\n",
      "Avg loss: 9.456789 \n",
      "\n",
      "Avg loss: 9.456502 \n",
      "\n",
      "Avg loss: 9.456255 \n",
      "\n",
      "Avg loss: 9.456043 \n",
      "\n",
      "Avg loss: 9.455859 \n",
      "\n",
      "Avg loss: 9.455701 \n",
      "\n",
      "Avg loss: 9.455565 \n",
      "\n",
      "Avg loss: 9.455448 \n",
      "\n",
      "Avg loss: 9.455346 \n",
      "\n",
      "Avg loss: 9.455260 \n",
      "\n",
      "Avg loss: 9.455184 \n",
      "\n",
      "Avg loss: 9.455119 \n",
      "\n",
      "Avg loss: 9.455064 \n",
      "\n",
      "Avg loss: 9.455014 \n",
      "\n",
      "Avg loss: 9.454973 \n",
      "\n",
      "Avg loss: 9.454936 \n",
      "\n",
      "Avg loss: 9.454904 \n",
      "\n",
      "Avg loss: 9.454876 \n",
      "\n",
      "Avg loss: 9.454852 \n",
      "\n",
      "Avg loss: 9.454832 \n",
      "\n",
      "Avg loss: 9.454816 \n",
      "\n",
      "Avg loss: 9.454800 \n",
      "\n",
      "Avg loss: 9.454787 \n",
      "\n",
      "Avg loss: 9.454775 \n",
      "\n",
      "Avg loss: 9.454765 \n",
      "\n",
      "Avg loss: 9.454757 \n",
      "\n",
      "Avg loss: 9.454749 \n",
      "\n",
      "Avg loss: 9.454743 \n",
      "\n",
      "Avg loss: 9.454737 \n",
      "\n",
      "Avg loss: 9.454733 \n",
      "\n",
      "Avg loss: 9.454727 \n",
      "\n",
      "Avg loss: 9.454723 \n",
      "\n",
      "Avg loss: 9.454720 \n",
      "\n",
      "Avg loss: 9.454717 \n",
      "\n",
      "Avg loss: 9.454715 \n",
      "\n",
      "Avg loss: 9.454713 \n",
      "\n",
      "Avg loss: 9.454711 \n",
      "\n",
      "Avg loss: 9.454710 \n",
      "\n",
      "Avg loss: 9.454708 \n",
      "\n",
      "Avg loss: 9.454707 \n",
      "\n",
      "Avg loss: 9.454706 \n",
      "\n",
      "Avg loss: 9.454705 \n",
      "\n",
      "Avg loss: 9.454705 \n",
      "\n",
      "Avg loss: 9.454704 \n",
      "\n",
      "Avg loss: 9.454704 \n",
      "\n",
      "Avg loss: 9.454703 \n",
      "\n",
      "Avg loss: 9.454703 \n",
      "\n",
      "Avg loss: 9.454702 \n",
      "\n",
      "Avg loss: 9.454702 \n",
      "\n",
      "Avg loss: 9.454702 \n",
      "\n",
      "Avg loss: 9.454702 \n",
      "\n",
      "Avg loss: 9.454701 \n",
      "\n",
      "Avg loss: 9.454701 \n",
      "\n",
      "Avg loss: 9.454701 \n",
      "\n",
      "Avg loss: 9.454701 \n",
      "\n",
      "Avg loss: 9.454701 \n",
      "\n",
      "Avg loss: 9.454701 \n",
      "\n",
      "Avg loss: 9.454701 \n",
      "\n",
      "Avg loss: 9.454701 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Avg loss: 9.454700 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "epochs = 1000\n",
    "for t in range(epochs):\n",
    "    # print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    model.train()\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "    \n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  [3.0748498]\n",
      "Null:  [[1.0592833]]\n",
      "Linear:  [1.0351372]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Linear model\n",
    "m, b = np.polyfit(train_data[\"last_crime\"], train_data[\"crime\"], deg=1)\n",
    "\n",
    "model.eval()\n",
    "predNulls = []\n",
    "predCrimes = []\n",
    "actual = []\n",
    "with torch.no_grad():\n",
    "    i = 0\n",
    "    target = 10\n",
    "    mse = 0\n",
    "    mseNull = 0\n",
    "    mseLinear = 0\n",
    "    for x, y in test_dataloader:\n",
    "        i += 1\n",
    "\n",
    "        out = np.hstack((x[:,56:], y.reshape(-1,1)))\n",
    "        crime = out[:, crime_idx - 56]\n",
    "        x = x.to(device)\n",
    "        \n",
    "        pred = model(x)\n",
    "        pred = pred.detach().cpu().numpy()\n",
    "\n",
    "        x = x.detach().cpu().numpy()\n",
    "        out = np.hstack((x[:,56:], pred.reshape(-1,1)))\n",
    "        pred = out[:, crime_idx - 56]\n",
    "\n",
    "        predNull = scaler_x.inverse_transform(x)[:, last_idx].reshape(-1,1)/1e3\n",
    "\n",
    "        predLinear = b + m * scaler_x.inverse_transform(x)[:, last_idx]\n",
    "\n",
    "\n",
    "        # print(f'Predicted: \"{pred}\",\\n Actual: \"{crime}\"')\n",
    "        # print(\"Linear\", predLinear)\n",
    "\n",
    "        mse += (pred - crime) ** 2\n",
    "        mseNull += (predNull - crime)**2\n",
    "        mseLinear += (predLinear - crime)**2\n",
    "\n",
    "        predNulls.append(predNull)\n",
    "        predCrimes.append(pred)\n",
    "        actual.append(crime)\n",
    "\n",
    "    print(\"Model: \", np.sqrt(mse/i))\n",
    "    print(\"Null: \", np.sqrt(mseNull/i))\n",
    "    print(\"Linear: \", np.sqrt(mseLinear/i))\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(predNulls, predCrimes, s= 5)\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(predNulls, actual, s=5)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
