{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import pandas as pd\n",
    "import statsmodels as st\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import torch.utils.data as data_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>egm</th>\n",
       "      <th>medianhouseprice</th>\n",
       "      <th>offencecount</th>\n",
       "      <th>traveltimetogpominutes</th>\n",
       "      <th>areakm2</th>\n",
       "      <th>ariamin</th>\n",
       "      <th>ariamax</th>\n",
       "      <th>ariaavg</th>\n",
       "      <th>commercialkm2</th>\n",
       "      <th>...</th>\n",
       "      <th>presentationstoemergencydepartments201213</th>\n",
       "      <th>traveltimetonearestpublichospitalwithemergencydepartment</th>\n",
       "      <th>presentationstoemergencydepartmentsduetoinjury</th>\n",
       "      <th>category45emergencydepartmentpresentations</th>\n",
       "      <th>numberofdwellings</th>\n",
       "      <th>population</th>\n",
       "      <th>locationx</th>\n",
       "      <th>locationy</th>\n",
       "      <th>absremotenesscategory</th>\n",
       "      <th>crime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>570.000000</td>\n",
       "      <td>5.700000e+02</td>\n",
       "      <td>4.480000e+02</td>\n",
       "      <td>399.000000</td>\n",
       "      <td>570.000000</td>\n",
       "      <td>570.000000</td>\n",
       "      <td>570.000000</td>\n",
       "      <td>570.000000</td>\n",
       "      <td>570.000000</td>\n",
       "      <td>570.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>570.000000</td>\n",
       "      <td>570.000000</td>\n",
       "      <td>570.000000</td>\n",
       "      <td>570.000000</td>\n",
       "      <td>570.000000</td>\n",
       "      <td>570.000000</td>\n",
       "      <td>570.000000</td>\n",
       "      <td>570.000000</td>\n",
       "      <td>570.000000</td>\n",
       "      <td>399.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2015.500000</td>\n",
       "      <td>4.475087e+07</td>\n",
       "      <td>6.730241e+05</td>\n",
       "      <td>8711.486216</td>\n",
       "      <td>89.606698</td>\n",
       "      <td>2385.559871</td>\n",
       "      <td>0.651840</td>\n",
       "      <td>0.924022</td>\n",
       "      <td>0.776669</td>\n",
       "      <td>0.015653</td>\n",
       "      <td>...</td>\n",
       "      <td>0.275168</td>\n",
       "      <td>25.493637</td>\n",
       "      <td>0.248753</td>\n",
       "      <td>0.567736</td>\n",
       "      <td>40334.421053</td>\n",
       "      <td>99988.000000</td>\n",
       "      <td>-3.804322</td>\n",
       "      <td>24.600444</td>\n",
       "      <td>0.596491</td>\n",
       "      <td>8621.666757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.874804</td>\n",
       "      <td>3.654833e+07</td>\n",
       "      <td>4.536039e+05</td>\n",
       "      <td>6814.604619</td>\n",
       "      <td>90.258987</td>\n",
       "      <td>4359.046867</td>\n",
       "      <td>0.923016</td>\n",
       "      <td>1.239729</td>\n",
       "      <td>1.069332</td>\n",
       "      <td>0.024118</td>\n",
       "      <td>...</td>\n",
       "      <td>0.120782</td>\n",
       "      <td>23.096960</td>\n",
       "      <td>0.039089</td>\n",
       "      <td>0.076362</td>\n",
       "      <td>24869.081733</td>\n",
       "      <td>67492.921038</td>\n",
       "      <td>106.181404</td>\n",
       "      <td>83.253195</td>\n",
       "      <td>0.697967</td>\n",
       "      <td>3480.497806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2011.000000</td>\n",
       "      <td>1.892293e+06</td>\n",
       "      <td>1.512500e+05</td>\n",
       "      <td>387.000000</td>\n",
       "      <td>4.897709</td>\n",
       "      <td>20.822930</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050232</td>\n",
       "      <td>3.930699</td>\n",
       "      <td>0.140255</td>\n",
       "      <td>0.399250</td>\n",
       "      <td>4874.000000</td>\n",
       "      <td>9873.000000</td>\n",
       "      <td>-310.285714</td>\n",
       "      <td>-85.083283</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3076.800763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2013.000000</td>\n",
       "      <td>1.236583e+07</td>\n",
       "      <td>3.380238e+05</td>\n",
       "      <td>3055.500000</td>\n",
       "      <td>20.289781</td>\n",
       "      <td>65.887204</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000369</td>\n",
       "      <td>...</td>\n",
       "      <td>0.183279</td>\n",
       "      <td>8.628051</td>\n",
       "      <td>0.218941</td>\n",
       "      <td>0.514380</td>\n",
       "      <td>18187.000000</td>\n",
       "      <td>38580.000000</td>\n",
       "      <td>-24.132895</td>\n",
       "      <td>-19.991837</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6502.077166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2015.500000</td>\n",
       "      <td>3.027379e+07</td>\n",
       "      <td>5.515666e+05</td>\n",
       "      <td>7867.000000</td>\n",
       "      <td>53.726582</td>\n",
       "      <td>654.711013</td>\n",
       "      <td>0.068634</td>\n",
       "      <td>0.224843</td>\n",
       "      <td>0.130797</td>\n",
       "      <td>0.002820</td>\n",
       "      <td>...</td>\n",
       "      <td>0.253923</td>\n",
       "      <td>15.863108</td>\n",
       "      <td>0.256337</td>\n",
       "      <td>0.567464</td>\n",
       "      <td>38495.000000</td>\n",
       "      <td>92508.000000</td>\n",
       "      <td>4.894320</td>\n",
       "      <td>0.923112</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8254.364090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2018.000000</td>\n",
       "      <td>7.021907e+07</td>\n",
       "      <td>8.867353e+05</td>\n",
       "      <td>12282.000000</td>\n",
       "      <td>135.640780</td>\n",
       "      <td>3198.489793</td>\n",
       "      <td>1.213264</td>\n",
       "      <td>1.483585</td>\n",
       "      <td>1.385136</td>\n",
       "      <td>0.023797</td>\n",
       "      <td>...</td>\n",
       "      <td>0.384497</td>\n",
       "      <td>33.194080</td>\n",
       "      <td>0.278660</td>\n",
       "      <td>0.614959</td>\n",
       "      <td>59303.000000</td>\n",
       "      <td>150781.000000</td>\n",
       "      <td>27.153846</td>\n",
       "      <td>38.319368</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10225.841252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2020.000000</td>\n",
       "      <td>1.456191e+08</td>\n",
       "      <td>2.841161e+06</td>\n",
       "      <td>37886.000000</td>\n",
       "      <td>384.960766</td>\n",
       "      <td>23359.313312</td>\n",
       "      <td>3.272194</td>\n",
       "      <td>4.383425</td>\n",
       "      <td>3.737190</td>\n",
       "      <td>0.127473</td>\n",
       "      <td>...</td>\n",
       "      <td>0.553260</td>\n",
       "      <td>96.843507</td>\n",
       "      <td>0.322547</td>\n",
       "      <td>0.725373</td>\n",
       "      <td>107828.000000</td>\n",
       "      <td>298909.000000</td>\n",
       "      <td>274.239407</td>\n",
       "      <td>343.714443</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>25932.263717</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 84 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              year           egm  medianhouseprice  offencecount  \\\n",
       "count   570.000000  5.700000e+02      4.480000e+02    399.000000   \n",
       "mean   2015.500000  4.475087e+07      6.730241e+05   8711.486216   \n",
       "std       2.874804  3.654833e+07      4.536039e+05   6814.604619   \n",
       "min    2011.000000  1.892293e+06      1.512500e+05    387.000000   \n",
       "25%    2013.000000  1.236583e+07      3.380238e+05   3055.500000   \n",
       "50%    2015.500000  3.027379e+07      5.515666e+05   7867.000000   \n",
       "75%    2018.000000  7.021907e+07      8.867353e+05  12282.000000   \n",
       "max    2020.000000  1.456191e+08      2.841161e+06  37886.000000   \n",
       "\n",
       "       traveltimetogpominutes       areakm2     ariamin     ariamax  \\\n",
       "count              570.000000    570.000000  570.000000  570.000000   \n",
       "mean                89.606698   2385.559871    0.651840    0.924022   \n",
       "std                 90.258987   4359.046867    0.923016    1.239729   \n",
       "min                  4.897709     20.822930    0.000000    0.000000   \n",
       "25%                 20.289781     65.887204    0.000000    0.000000   \n",
       "50%                 53.726582    654.711013    0.068634    0.224843   \n",
       "75%                135.640780   3198.489793    1.213264    1.483585   \n",
       "max                384.960766  23359.313312    3.272194    4.383425   \n",
       "\n",
       "          ariaavg  commercialkm2  ...  \\\n",
       "count  570.000000     570.000000  ...   \n",
       "mean     0.776669       0.015653  ...   \n",
       "std      1.069332       0.024118  ...   \n",
       "min      0.000000       0.000052  ...   \n",
       "25%      0.000000       0.000369  ...   \n",
       "50%      0.130797       0.002820  ...   \n",
       "75%      1.385136       0.023797  ...   \n",
       "max      3.737190       0.127473  ...   \n",
       "\n",
       "       presentationstoemergencydepartments201213  \\\n",
       "count                                 570.000000   \n",
       "mean                                    0.275168   \n",
       "std                                     0.120782   \n",
       "min                                     0.050232   \n",
       "25%                                     0.183279   \n",
       "50%                                     0.253923   \n",
       "75%                                     0.384497   \n",
       "max                                     0.553260   \n",
       "\n",
       "       traveltimetonearestpublichospitalwithemergencydepartment  \\\n",
       "count                                         570.000000          \n",
       "mean                                           25.493637          \n",
       "std                                            23.096960          \n",
       "min                                             3.930699          \n",
       "25%                                             8.628051          \n",
       "50%                                            15.863108          \n",
       "75%                                            33.194080          \n",
       "max                                            96.843507          \n",
       "\n",
       "       presentationstoemergencydepartmentsduetoinjury  \\\n",
       "count                                      570.000000   \n",
       "mean                                         0.248753   \n",
       "std                                          0.039089   \n",
       "min                                          0.140255   \n",
       "25%                                          0.218941   \n",
       "50%                                          0.256337   \n",
       "75%                                          0.278660   \n",
       "max                                          0.322547   \n",
       "\n",
       "       category45emergencydepartmentpresentations  numberofdwellings  \\\n",
       "count                                  570.000000         570.000000   \n",
       "mean                                     0.567736       40334.421053   \n",
       "std                                      0.076362       24869.081733   \n",
       "min                                      0.399250        4874.000000   \n",
       "25%                                      0.514380       18187.000000   \n",
       "50%                                      0.567464       38495.000000   \n",
       "75%                                      0.614959       59303.000000   \n",
       "max                                      0.725373      107828.000000   \n",
       "\n",
       "          population   locationx   locationy  absremotenesscategory  \\\n",
       "count     570.000000  570.000000  570.000000             570.000000   \n",
       "mean    99988.000000   -3.804322   24.600444               0.596491   \n",
       "std     67492.921038  106.181404   83.253195               0.697967   \n",
       "min      9873.000000 -310.285714  -85.083283               0.000000   \n",
       "25%     38580.000000  -24.132895  -19.991837               0.000000   \n",
       "50%     92508.000000    4.894320    0.923112               0.000000   \n",
       "75%    150781.000000   27.153846   38.319368               1.000000   \n",
       "max    298909.000000  274.239407  343.714443               2.000000   \n",
       "\n",
       "              crime  \n",
       "count    399.000000  \n",
       "mean    8621.666757  \n",
       "std     3480.497806  \n",
       "min     3076.800763  \n",
       "25%     6502.077166  \n",
       "50%     8254.364090  \n",
       "75%    10225.841252  \n",
       "max    25932.263717  \n",
       "\n",
       "[8 rows x 84 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./final_outer.csv', index_col=0)\n",
    "data['crime'] = data['Rate per 100,000 population']\n",
    "data = data.drop(columns=['Rate per 100,000 population'])\n",
    "\n",
    "def normalize(col):\n",
    "    col = ''.join(col.split())\n",
    "    col = ''.join(e for e in col if e.isalnum())\n",
    "    out: str = col.replace(',','_').lower()\n",
    "    if out[0].isdigit():\n",
    "        out = '_' + out\n",
    "    return out\n",
    "\n",
    "data.rename(columns=normalize, inplace=True)\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lga</th>\n",
       "      <th>year</th>\n",
       "      <th>egm</th>\n",
       "      <th>medianhouseprice</th>\n",
       "      <th>traveltimetogpominutes</th>\n",
       "      <th>areakm2</th>\n",
       "      <th>ariamin</th>\n",
       "      <th>ariamax</th>\n",
       "      <th>ariaavg</th>\n",
       "      <th>commercialkm2</th>\n",
       "      <th>...</th>\n",
       "      <th>last2_crime</th>\n",
       "      <th>last_house</th>\n",
       "      <th>last2_house</th>\n",
       "      <th>last3_house</th>\n",
       "      <th>last_egm</th>\n",
       "      <th>last2_egm</th>\n",
       "      <th>last3_egm</th>\n",
       "      <th>last4_egm</th>\n",
       "      <th>last5_egm</th>\n",
       "      <th>crime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>whittlesea</td>\n",
       "      <td>2016</td>\n",
       "      <td>1.116516e+08</td>\n",
       "      <td>4.338032e+05</td>\n",
       "      <td>34.862554</td>\n",
       "      <td>590.075860</td>\n",
       "      <td>0.007974</td>\n",
       "      <td>0.056596</td>\n",
       "      <td>0.022594</td>\n",
       "      <td>0.005186</td>\n",
       "      <td>...</td>\n",
       "      <td>7233.141209</td>\n",
       "      <td>3.864022e+05</td>\n",
       "      <td>3.567570e+05</td>\n",
       "      <td>3.452792e+05</td>\n",
       "      <td>1.091612e+08</td>\n",
       "      <td>1.035006e+08</td>\n",
       "      <td>1.010001e+08</td>\n",
       "      <td>1.115836e+08</td>\n",
       "      <td>1.095429e+08</td>\n",
       "      <td>8048.952467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>northerngrampians</td>\n",
       "      <td>2016</td>\n",
       "      <td>9.050693e+06</td>\n",
       "      <td>1.597500e+05</td>\n",
       "      <td>179.410340</td>\n",
       "      <td>6720.196354</td>\n",
       "      <td>2.135649</td>\n",
       "      <td>2.837918</td>\n",
       "      <td>2.452597</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>...</td>\n",
       "      <td>7947.694659</td>\n",
       "      <td>1.590000e+05</td>\n",
       "      <td>1.587500e+05</td>\n",
       "      <td>1.512500e+05</td>\n",
       "      <td>1.003788e+07</td>\n",
       "      <td>1.035065e+07</td>\n",
       "      <td>1.014142e+07</td>\n",
       "      <td>1.121941e+07</td>\n",
       "      <td>1.071793e+07</td>\n",
       "      <td>11633.535004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>greatergeelong</td>\n",
       "      <td>2016</td>\n",
       "      <td>1.132050e+08</td>\n",
       "      <td>4.470595e+05</td>\n",
       "      <td>61.820207</td>\n",
       "      <td>1389.430557</td>\n",
       "      <td>0.152898</td>\n",
       "      <td>0.224843</td>\n",
       "      <td>0.182097</td>\n",
       "      <td>0.002401</td>\n",
       "      <td>...</td>\n",
       "      <td>8127.107630</td>\n",
       "      <td>4.230712e+05</td>\n",
       "      <td>4.084374e+05</td>\n",
       "      <td>3.872893e+05</td>\n",
       "      <td>1.130210e+08</td>\n",
       "      <td>1.116281e+08</td>\n",
       "      <td>1.097196e+08</td>\n",
       "      <td>1.183161e+08</td>\n",
       "      <td>1.184686e+08</td>\n",
       "      <td>9586.313140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>colacotway</td>\n",
       "      <td>2016</td>\n",
       "      <td>1.016289e+07</td>\n",
       "      <td>4.342500e+05</td>\n",
       "      <td>137.416278</td>\n",
       "      <td>3232.099823</td>\n",
       "      <td>1.273625</td>\n",
       "      <td>1.806754</td>\n",
       "      <td>1.531375</td>\n",
       "      <td>0.000364</td>\n",
       "      <td>...</td>\n",
       "      <td>7259.476598</td>\n",
       "      <td>3.823333e+05</td>\n",
       "      <td>3.684167e+05</td>\n",
       "      <td>3.546667e+05</td>\n",
       "      <td>1.026330e+07</td>\n",
       "      <td>1.007489e+07</td>\n",
       "      <td>1.019461e+07</td>\n",
       "      <td>1.091608e+07</td>\n",
       "      <td>1.105642e+07</td>\n",
       "      <td>9343.694411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>moorabool</td>\n",
       "      <td>2016</td>\n",
       "      <td>1.061337e+07</td>\n",
       "      <td>3.656250e+05</td>\n",
       "      <td>58.368445</td>\n",
       "      <td>2142.863230</td>\n",
       "      <td>0.331739</td>\n",
       "      <td>0.880712</td>\n",
       "      <td>0.598316</td>\n",
       "      <td>0.000394</td>\n",
       "      <td>...</td>\n",
       "      <td>6183.609090</td>\n",
       "      <td>3.560000e+05</td>\n",
       "      <td>3.395000e+05</td>\n",
       "      <td>3.336250e+05</td>\n",
       "      <td>1.057564e+07</td>\n",
       "      <td>1.030988e+07</td>\n",
       "      <td>1.054645e+07</td>\n",
       "      <td>1.116534e+07</td>\n",
       "      <td>1.083741e+07</td>\n",
       "      <td>7755.876592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>maribyrnong</td>\n",
       "      <td>2020</td>\n",
       "      <td>4.224321e+07</td>\n",
       "      <td>8.882343e+05</td>\n",
       "      <td>11.629266</td>\n",
       "      <td>31.347530</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.068430</td>\n",
       "      <td>...</td>\n",
       "      <td>9490.159895</td>\n",
       "      <td>8.490697e+05</td>\n",
       "      <td>9.238878e+05</td>\n",
       "      <td>9.075850e+05</td>\n",
       "      <td>5.725792e+07</td>\n",
       "      <td>5.492496e+07</td>\n",
       "      <td>5.406851e+07</td>\n",
       "      <td>5.373503e+07</td>\n",
       "      <td>5.299402e+07</td>\n",
       "      <td>10239.549084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>stonnington</td>\n",
       "      <td>2020</td>\n",
       "      <td>1.411828e+07</td>\n",
       "      <td>2.841161e+06</td>\n",
       "      <td>9.937739</td>\n",
       "      <td>23.986985</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066525</td>\n",
       "      <td>...</td>\n",
       "      <td>9512.969825</td>\n",
       "      <td>2.535312e+06</td>\n",
       "      <td>2.594971e+06</td>\n",
       "      <td>2.651331e+06</td>\n",
       "      <td>1.986235e+07</td>\n",
       "      <td>2.085283e+07</td>\n",
       "      <td>2.303256e+07</td>\n",
       "      <td>2.344328e+07</td>\n",
       "      <td>2.301997e+07</td>\n",
       "      <td>10291.270757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>gleneira</td>\n",
       "      <td>2020</td>\n",
       "      <td>5.402530e+07</td>\n",
       "      <td>1.516358e+06</td>\n",
       "      <td>15.409791</td>\n",
       "      <td>41.586761</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032422</td>\n",
       "      <td>...</td>\n",
       "      <td>4245.713273</td>\n",
       "      <td>1.430137e+06</td>\n",
       "      <td>1.466053e+06</td>\n",
       "      <td>1.520393e+06</td>\n",
       "      <td>7.424468e+07</td>\n",
       "      <td>7.717147e+07</td>\n",
       "      <td>7.625982e+07</td>\n",
       "      <td>7.621435e+07</td>\n",
       "      <td>7.355592e+07</td>\n",
       "      <td>5086.773226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>bayside</td>\n",
       "      <td>2020</td>\n",
       "      <td>1.022713e+07</td>\n",
       "      <td>1.744736e+06</td>\n",
       "      <td>20.118347</td>\n",
       "      <td>35.882194</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023797</td>\n",
       "      <td>...</td>\n",
       "      <td>4478.938665</td>\n",
       "      <td>1.572118e+06</td>\n",
       "      <td>1.672062e+06</td>\n",
       "      <td>1.732025e+06</td>\n",
       "      <td>1.380787e+07</td>\n",
       "      <td>1.537867e+07</td>\n",
       "      <td>1.471008e+07</td>\n",
       "      <td>1.361502e+07</td>\n",
       "      <td>1.581324e+07</td>\n",
       "      <td>5319.088156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>mooneevalley</td>\n",
       "      <td>2020</td>\n",
       "      <td>5.749777e+07</td>\n",
       "      <td>1.261210e+06</td>\n",
       "      <td>13.016887</td>\n",
       "      <td>50.700036</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.040354</td>\n",
       "      <td>...</td>\n",
       "      <td>6863.659184</td>\n",
       "      <td>1.209735e+06</td>\n",
       "      <td>1.309734e+06</td>\n",
       "      <td>1.219763e+06</td>\n",
       "      <td>7.765076e+07</td>\n",
       "      <td>7.858918e+07</td>\n",
       "      <td>7.567908e+07</td>\n",
       "      <td>7.540108e+07</td>\n",
       "      <td>7.474705e+07</td>\n",
       "      <td>6627.703374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>280 rows Ã— 95 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   lga  year           egm  medianhouseprice  \\\n",
       "0           whittlesea  2016  1.116516e+08      4.338032e+05   \n",
       "1    northerngrampians  2016  9.050693e+06      1.597500e+05   \n",
       "2       greatergeelong  2016  1.132050e+08      4.470595e+05   \n",
       "3           colacotway  2016  1.016289e+07      4.342500e+05   \n",
       "4            moorabool  2016  1.061337e+07      3.656250e+05   \n",
       "..                 ...   ...           ...               ...   \n",
       "275        maribyrnong  2020  4.224321e+07      8.882343e+05   \n",
       "276        stonnington  2020  1.411828e+07      2.841161e+06   \n",
       "277           gleneira  2020  5.402530e+07      1.516358e+06   \n",
       "278            bayside  2020  1.022713e+07      1.744736e+06   \n",
       "279       mooneevalley  2020  5.749777e+07      1.261210e+06   \n",
       "\n",
       "     traveltimetogpominutes      areakm2   ariamin   ariamax   ariaavg  \\\n",
       "0                 34.862554   590.075860  0.007974  0.056596  0.022594   \n",
       "1                179.410340  6720.196354  2.135649  2.837918  2.452597   \n",
       "2                 61.820207  1389.430557  0.152898  0.224843  0.182097   \n",
       "3                137.416278  3232.099823  1.273625  1.806754  1.531375   \n",
       "4                 58.368445  2142.863230  0.331739  0.880712  0.598316   \n",
       "..                      ...          ...       ...       ...       ...   \n",
       "275               11.629266    31.347530  0.000000  0.000000  0.000000   \n",
       "276                9.937739    23.986985  0.000000  0.000000  0.000000   \n",
       "277               15.409791    41.586761  0.000000  0.000000  0.000000   \n",
       "278               20.118347    35.882194  0.000000  0.000000  0.000000   \n",
       "279               13.016887    50.700036  0.000000  0.000000  0.000000   \n",
       "\n",
       "     commercialkm2  ...  last2_crime    last_house   last2_house  \\\n",
       "0         0.005186  ...  7233.141209  3.864022e+05  3.567570e+05   \n",
       "1         0.000128  ...  7947.694659  1.590000e+05  1.587500e+05   \n",
       "2         0.002401  ...  8127.107630  4.230712e+05  4.084374e+05   \n",
       "3         0.000364  ...  7259.476598  3.823333e+05  3.684167e+05   \n",
       "4         0.000394  ...  6183.609090  3.560000e+05  3.395000e+05   \n",
       "..             ...  ...          ...           ...           ...   \n",
       "275       0.068430  ...  9490.159895  8.490697e+05  9.238878e+05   \n",
       "276       0.066525  ...  9512.969825  2.535312e+06  2.594971e+06   \n",
       "277       0.032422  ...  4245.713273  1.430137e+06  1.466053e+06   \n",
       "278       0.023797  ...  4478.938665  1.572118e+06  1.672062e+06   \n",
       "279       0.040354  ...  6863.659184  1.209735e+06  1.309734e+06   \n",
       "\n",
       "      last3_house      last_egm     last2_egm     last3_egm     last4_egm  \\\n",
       "0    3.452792e+05  1.091612e+08  1.035006e+08  1.010001e+08  1.115836e+08   \n",
       "1    1.512500e+05  1.003788e+07  1.035065e+07  1.014142e+07  1.121941e+07   \n",
       "2    3.872893e+05  1.130210e+08  1.116281e+08  1.097196e+08  1.183161e+08   \n",
       "3    3.546667e+05  1.026330e+07  1.007489e+07  1.019461e+07  1.091608e+07   \n",
       "4    3.336250e+05  1.057564e+07  1.030988e+07  1.054645e+07  1.116534e+07   \n",
       "..            ...           ...           ...           ...           ...   \n",
       "275  9.075850e+05  5.725792e+07  5.492496e+07  5.406851e+07  5.373503e+07   \n",
       "276  2.651331e+06  1.986235e+07  2.085283e+07  2.303256e+07  2.344328e+07   \n",
       "277  1.520393e+06  7.424468e+07  7.717147e+07  7.625982e+07  7.621435e+07   \n",
       "278  1.732025e+06  1.380787e+07  1.537867e+07  1.471008e+07  1.361502e+07   \n",
       "279  1.219763e+06  7.765076e+07  7.858918e+07  7.567908e+07  7.540108e+07   \n",
       "\n",
       "        last5_egm         crime  \n",
       "0    1.095429e+08   8048.952467  \n",
       "1    1.071793e+07  11633.535004  \n",
       "2    1.184686e+08   9586.313140  \n",
       "3    1.105642e+07   9343.694411  \n",
       "4    1.083741e+07   7755.876592  \n",
       "..            ...           ...  \n",
       "275  5.299402e+07  10239.549084  \n",
       "276  2.301997e+07  10291.270757  \n",
       "277  7.355592e+07   5086.773226  \n",
       "278  1.581324e+07   5319.088156  \n",
       "279  7.474705e+07   6627.703374  \n",
       "\n",
       "[280 rows x 95 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual = data[data['year'].isin(list(range(2016, 2021)))]\n",
    "actual = actual.copy()\n",
    "\n",
    "# insert last year\n",
    "for i, row in actual.iterrows():\n",
    "    last = data[(data['year'] == row['year']-1) & (data['lga'] == row['lga'])].copy()\n",
    "    distance = np.sqrt(row['locationx'] ** 2 + row['locationy'] ** 2)\n",
    "    actual.loc[i, 'distance'] = distance\n",
    "    last_2 = data[(data['year'] == row['year']-2) & (data['lga'] == row['lga'])].copy()\n",
    "    last_3 = data[(data['year'] == row['year']-3) & (data['lga'] == row['lga'])].copy()\n",
    "    last_4 = data[(data['year'] == row['year']-4) & (data['lga'] == row['lga'])].copy()\n",
    "    last_5 = data[(data['year'] == row['year']-5) & (data['lga'] == row['lga'])].copy()\n",
    "    actual.loc[i, 'last_crime'] = last['crime'].values[0]\n",
    "    actual.loc[i, 'last2_crime'] = last_2['crime'].values[0]\n",
    "    actual.loc[i, 'last_house'] = last['medianhouseprice'].values[0]\n",
    "    actual.loc[i, 'last2_house'] = last_2['medianhouseprice'].values[0]\n",
    "    actual.loc[i, 'last3_house'] = last_3['medianhouseprice'].values[0]\n",
    "    actual.loc[i, 'last_egm'] = last['egm'].values[0]\n",
    "    actual.loc[i, 'last2_egm'] = last_2['egm'].values[0]\n",
    "    actual.loc[i, 'last3_egm'] = last_3['egm'].values[0]\n",
    "    actual.loc[i, 'last4_egm'] = last_4['egm'].values[0]\n",
    "    actual.loc[i, 'last5_egm'] = last_5['egm'].values[0]\n",
    "    \n",
    "actual = actual.dropna(axis=0)\n",
    "\n",
    "actual = actual.reset_index(drop=True)\n",
    "actual = actual.drop(columns=['offencecount'], axis=1)\n",
    "cr = actual.pop('crime')\n",
    "actual.insert(actual.shape[1], \"crime\", cr)\n",
    "actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lga0</th>\n",
       "      <th>lga1</th>\n",
       "      <th>lga2</th>\n",
       "      <th>lga3</th>\n",
       "      <th>lga4</th>\n",
       "      <th>lga5</th>\n",
       "      <th>lga6</th>\n",
       "      <th>lga7</th>\n",
       "      <th>lga8</th>\n",
       "      <th>lga9</th>\n",
       "      <th>...</th>\n",
       "      <th>last2_crime</th>\n",
       "      <th>last_house</th>\n",
       "      <th>last2_house</th>\n",
       "      <th>last3_house</th>\n",
       "      <th>last_egm</th>\n",
       "      <th>last2_egm</th>\n",
       "      <th>last3_egm</th>\n",
       "      <th>last4_egm</th>\n",
       "      <th>last5_egm</th>\n",
       "      <th>crime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7233.141209</td>\n",
       "      <td>3.864022e+05</td>\n",
       "      <td>3.567570e+05</td>\n",
       "      <td>3.452792e+05</td>\n",
       "      <td>1.091612e+08</td>\n",
       "      <td>1.035006e+08</td>\n",
       "      <td>1.010001e+08</td>\n",
       "      <td>1.115836e+08</td>\n",
       "      <td>1.095429e+08</td>\n",
       "      <td>8048.952467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7947.694659</td>\n",
       "      <td>1.590000e+05</td>\n",
       "      <td>1.587500e+05</td>\n",
       "      <td>1.512500e+05</td>\n",
       "      <td>1.003788e+07</td>\n",
       "      <td>1.035065e+07</td>\n",
       "      <td>1.014142e+07</td>\n",
       "      <td>1.121941e+07</td>\n",
       "      <td>1.071793e+07</td>\n",
       "      <td>11633.535004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8127.107630</td>\n",
       "      <td>4.230712e+05</td>\n",
       "      <td>4.084374e+05</td>\n",
       "      <td>3.872893e+05</td>\n",
       "      <td>1.130210e+08</td>\n",
       "      <td>1.116281e+08</td>\n",
       "      <td>1.097196e+08</td>\n",
       "      <td>1.183161e+08</td>\n",
       "      <td>1.184686e+08</td>\n",
       "      <td>9586.313140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7259.476598</td>\n",
       "      <td>3.823333e+05</td>\n",
       "      <td>3.684167e+05</td>\n",
       "      <td>3.546667e+05</td>\n",
       "      <td>1.026330e+07</td>\n",
       "      <td>1.007489e+07</td>\n",
       "      <td>1.019461e+07</td>\n",
       "      <td>1.091608e+07</td>\n",
       "      <td>1.105642e+07</td>\n",
       "      <td>9343.694411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6183.609090</td>\n",
       "      <td>3.560000e+05</td>\n",
       "      <td>3.395000e+05</td>\n",
       "      <td>3.336250e+05</td>\n",
       "      <td>1.057564e+07</td>\n",
       "      <td>1.030988e+07</td>\n",
       "      <td>1.054645e+07</td>\n",
       "      <td>1.116534e+07</td>\n",
       "      <td>1.083741e+07</td>\n",
       "      <td>7755.876592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9490.159895</td>\n",
       "      <td>8.490697e+05</td>\n",
       "      <td>9.238878e+05</td>\n",
       "      <td>9.075850e+05</td>\n",
       "      <td>5.725792e+07</td>\n",
       "      <td>5.492496e+07</td>\n",
       "      <td>5.406851e+07</td>\n",
       "      <td>5.373503e+07</td>\n",
       "      <td>5.299402e+07</td>\n",
       "      <td>10239.549084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9512.969825</td>\n",
       "      <td>2.535312e+06</td>\n",
       "      <td>2.594971e+06</td>\n",
       "      <td>2.651331e+06</td>\n",
       "      <td>1.986235e+07</td>\n",
       "      <td>2.085283e+07</td>\n",
       "      <td>2.303256e+07</td>\n",
       "      <td>2.344328e+07</td>\n",
       "      <td>2.301997e+07</td>\n",
       "      <td>10291.270757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4245.713273</td>\n",
       "      <td>1.430137e+06</td>\n",
       "      <td>1.466053e+06</td>\n",
       "      <td>1.520393e+06</td>\n",
       "      <td>7.424468e+07</td>\n",
       "      <td>7.717147e+07</td>\n",
       "      <td>7.625982e+07</td>\n",
       "      <td>7.621435e+07</td>\n",
       "      <td>7.355592e+07</td>\n",
       "      <td>5086.773226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4478.938665</td>\n",
       "      <td>1.572118e+06</td>\n",
       "      <td>1.672062e+06</td>\n",
       "      <td>1.732025e+06</td>\n",
       "      <td>1.380787e+07</td>\n",
       "      <td>1.537867e+07</td>\n",
       "      <td>1.471008e+07</td>\n",
       "      <td>1.361502e+07</td>\n",
       "      <td>1.581324e+07</td>\n",
       "      <td>5319.088156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6863.659184</td>\n",
       "      <td>1.209735e+06</td>\n",
       "      <td>1.309734e+06</td>\n",
       "      <td>1.219763e+06</td>\n",
       "      <td>7.765076e+07</td>\n",
       "      <td>7.858918e+07</td>\n",
       "      <td>7.567908e+07</td>\n",
       "      <td>7.540108e+07</td>\n",
       "      <td>7.474705e+07</td>\n",
       "      <td>6627.703374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>280 rows Ã— 148 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     lga0  lga1  lga2  lga3  lga4  lga5  lga6  lga7  lga8  lga9  ...  \\\n",
       "0     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "1     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "2     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "3     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "4     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "..    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   \n",
       "275   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "276   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "277   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "278   0.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0  ...   \n",
       "279   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "\n",
       "     last2_crime    last_house   last2_house   last3_house      last_egm  \\\n",
       "0    7233.141209  3.864022e+05  3.567570e+05  3.452792e+05  1.091612e+08   \n",
       "1    7947.694659  1.590000e+05  1.587500e+05  1.512500e+05  1.003788e+07   \n",
       "2    8127.107630  4.230712e+05  4.084374e+05  3.872893e+05  1.130210e+08   \n",
       "3    7259.476598  3.823333e+05  3.684167e+05  3.546667e+05  1.026330e+07   \n",
       "4    6183.609090  3.560000e+05  3.395000e+05  3.336250e+05  1.057564e+07   \n",
       "..           ...           ...           ...           ...           ...   \n",
       "275  9490.159895  8.490697e+05  9.238878e+05  9.075850e+05  5.725792e+07   \n",
       "276  9512.969825  2.535312e+06  2.594971e+06  2.651331e+06  1.986235e+07   \n",
       "277  4245.713273  1.430137e+06  1.466053e+06  1.520393e+06  7.424468e+07   \n",
       "278  4478.938665  1.572118e+06  1.672062e+06  1.732025e+06  1.380787e+07   \n",
       "279  6863.659184  1.209735e+06  1.309734e+06  1.219763e+06  7.765076e+07   \n",
       "\n",
       "        last2_egm     last3_egm     last4_egm     last5_egm         crime  \n",
       "0    1.035006e+08  1.010001e+08  1.115836e+08  1.095429e+08   8048.952467  \n",
       "1    1.035065e+07  1.014142e+07  1.121941e+07  1.071793e+07  11633.535004  \n",
       "2    1.116281e+08  1.097196e+08  1.183161e+08  1.184686e+08   9586.313140  \n",
       "3    1.007489e+07  1.019461e+07  1.091608e+07  1.105642e+07   9343.694411  \n",
       "4    1.030988e+07  1.054645e+07  1.116534e+07  1.083741e+07   7755.876592  \n",
       "..            ...           ...           ...           ...           ...  \n",
       "275  5.492496e+07  5.406851e+07  5.373503e+07  5.299402e+07  10239.549084  \n",
       "276  2.085283e+07  2.303256e+07  2.344328e+07  2.301997e+07  10291.270757  \n",
       "277  7.717147e+07  7.625982e+07  7.621435e+07  7.355592e+07   5086.773226  \n",
       "278  1.537867e+07  1.471008e+07  1.361502e+07  1.581324e+07   5319.088156  \n",
       "279  7.858918e+07  7.567908e+07  7.540108e+07  7.474705e+07   6627.703374  \n",
       "\n",
       "[280 rows x 148 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one hot encode\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "\n",
    "\n",
    "encoder = OneHotEncoder()\n",
    "encoded = actual.copy()\n",
    "encoded = encoded.drop(columns=['egm', 'medianhouseprice'], axis=1)\n",
    "# encoded = encoded[[\n",
    "#     'lga',\n",
    "#     'last_crime',\n",
    "#     'last2_crime',\n",
    "#     'locationx',\n",
    "#     'locationy',\n",
    "#     'distance',\n",
    "#     # check if it is correlated with region\n",
    "#     'last_egm', \n",
    "#     'last2_egm', \n",
    "#     'last3_egm', \n",
    "#     'last_house', \n",
    "#     'last2_house', \n",
    "#     'crime'\n",
    "#   ]]\n",
    "\n",
    "new_ = encoded.select_dtypes(include=[np.number])\n",
    "\n",
    "idx = new_.columns.get_loc('crime')\n",
    "print(idx)\n",
    "# year_idx = new_.columns.get_loc('year')\n",
    "# print(year_idx)\n",
    "last_idx = new_.columns.get_loc('last_crime')\n",
    "\n",
    "# scaler = MinMaxScaler(feature_range=(0,1))\n",
    "# new_[new_.columns] = scaler.fit_transform(new_[new_.columns])\n",
    "# standardize all\n",
    "\n",
    "out = encoder.fit_transform(encoded[['lga']])\n",
    "lga = pd.DataFrame(out.toarray())\n",
    "lga.rename(columns=lambda c: f\"lga{c}\", inplace=True)\n",
    "\n",
    "\n",
    "new = pd.concat([lga, new_], axis=1)\n",
    "# new['crime'] /= 20000\n",
    "new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1377,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['lga0', 'lga1', 'lga2', 'lga3', 'lga4', 'lga5', 'lga6', 'lga7', 'lga8',\n",
      "       'lga9', 'lga10', 'lga11', 'lga12', 'lga13', 'lga14', 'lga15', 'lga16',\n",
      "       'lga17', 'lga18', 'lga19', 'lga20', 'lga21', 'lga22', 'lga23', 'lga24',\n",
      "       'lga25', 'lga26', 'lga27', 'lga28', 'lga29', 'lga30', 'lga31', 'lga32',\n",
      "       'lga33', 'lga34', 'lga35', 'lga36', 'lga37', 'lga38', 'lga39', 'lga40',\n",
      "       'lga41', 'lga42', 'lga43', 'lga44', 'lga45', 'lga46', 'lga47', 'lga48',\n",
      "       'lga49', 'lga50', 'lga51', 'lga52', 'lga53', 'lga54', 'lga55'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(lga.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(196, 147) (196,)\n",
      "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3261e-02, 1.3557e-04, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 5.2168e-01, 0.0000e+00, 9.0599e-01, 0.0000e+00,\n",
      "         1.6109e-01, 3.0094e-01, 3.0561e-01, 0.0000e+00, 7.3805e-01, 1.7203e-02,\n",
      "         0.0000e+00, 2.5751e-01, 8.9708e-01, 4.4885e-02, 6.1593e-01, 1.3465e-01,\n",
      "         6.9302e-01, 1.3465e-01, 6.5330e-01, 7.2649e-01, 7.2039e-01, 1.7845e-01,\n",
      "         2.9352e-01, 3.4187e-01, 5.4010e-02, 0.0000e+00, 5.5784e-01, 2.6931e-01,\n",
      "         3.3979e-02, 4.0275e-01, 0.0000e+00, 3.8076e-01, 8.7413e-01, 6.6272e-02,\n",
      "         1.8211e-01, 4.1452e-01, 1.2552e-01, 0.0000e+00, 1.6701e-01, 2.4932e-01,\n",
      "         9.7004e-03, 2.2255e-02, 1.0000e+00, 5.8359e-01, 9.8770e-01, 9.2377e-01,\n",
      "         3.7146e-01, 3.1563e-01, 8.2838e-02, 4.2237e-01, 9.8730e-01, 8.2657e-02,\n",
      "         3.1473e-01, 4.5911e-01, 1.4551e-01, 5.3181e-01, 4.4875e-01, 4.1358e-01,\n",
      "         1.8370e-02, 4.6338e-01, 3.5504e-01, 3.2623e-01, 1.7505e-01, 3.6802e-02,\n",
      "         1.2103e-01, 2.3906e-01, 2.2348e-02, 3.5132e-02, 5.1347e-01, 3.9973e-01,\n",
      "         3.0094e-01, 5.3910e-01, 1.8176e-01, 0.0000e+00, 1.1669e-02, 2.7465e-01,\n",
      "         2.6245e-01, 8.2989e-01, 6.9631e-01, 6.2310e-01, 1.4590e-01, 1.3562e-01,\n",
      "         1.3267e-01, 1.4491e-01, 1.3655e-01]])\n",
      "tensor([0.5221])\n",
      "Using cuda device\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=147, out_features=64, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=64, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# ml model\n",
    "\n",
    "\n",
    "# one hot encode\n",
    "\n",
    "state = 67458\n",
    "train_data: pd.DataFrame = new.sample(frac=0.7, random_state=state)\n",
    "test_data = new.drop(train_data.index)\n",
    "\n",
    "scaler_x = MinMaxScaler(feature_range=(0,1))\n",
    "# scaler_y = MinMaxScaler(feature_range=(0,1))\n",
    "\n",
    "train_y = train_data['crime'].values\n",
    "train_x = train_data.drop('crime', axis=1).values\n",
    "test_y = test_data['crime'].values\n",
    "test_x = test_data.drop('crime', axis=1).values\n",
    "\n",
    "\n",
    "scaler_x.fit(train_x)\n",
    "# scaler_y.fit(train_y.reshape(-1, 1))\n",
    "\n",
    "train_x = scaler_x.transform(train_x)\n",
    "# train_y = scaler_y.transform(train_y.reshape(-1, 1))\n",
    "train_y = train_y\n",
    "\n",
    "\n",
    "test_y = test_y\n",
    "# test_y = scaler_y.transform(test_y.reshape(-1, 1))\n",
    "test_x = scaler_x.transform(test_x)\n",
    "\n",
    "print(train_x.shape, train_y.shape)\n",
    "\n",
    "batch_size = 1\n",
    "\n",
    "train = data_utils.TensorDataset(torch.Tensor(train_x), torch.Tensor(train_y))\n",
    "test = data_utils.TensorDataset(torch.Tensor(test_x), torch.Tensor(test_y))\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(X)\n",
    "    print(y)\n",
    "    # print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    # print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break\n",
    "\n",
    "\n",
    "# Get cpu, gpu or mps device for training.\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(train_x.shape[1], 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1356,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.005)\n",
    "# optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4)\n",
    "\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # if batch % 10 == 0:\n",
    "            # loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            # print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    # print(f\"Avg loss: {test_loss:>8f} \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse_null 1187.5543436247672 test 2560.84, train 3632.65\n",
      "mse_null 1187.5543436247672 test 2487.01, train 3432.20\n",
      "mse_null 1187.5543436247672 test 2376.50, train 3237.79\n",
      "mse_null 1187.5543436247672 test 2146.13, train 3030.53\n",
      "mse_null 1187.5543436247672 test 1996.73, train 2782.00\n",
      "mse_null 1187.5543436247672 test 2049.56, train 2565.29\n",
      "mse_null 1187.5543436247672 test 1803.62, train 2262.98\n",
      "mse_null 1187.5543436247672 test 1568.07, train 2052.42\n",
      "mse_null 1187.5543436247672 test 1505.02, train 1796.23\n",
      "mse_null 1187.5543436247672 test 1656.90, train 1684.08\n",
      "mse_null 1187.5543436247672 test 1398.56, train 1536.18\n",
      "mse_null 1187.5543436247672 test 1454.21, train 1377.29\n",
      "mse_null 1187.5543436247672 test 1389.41, train 1291.40\n",
      "mse_null 1187.5543436247672 test 1363.12, train 1225.52\n",
      "mse_null 1187.5543436247672 test 1366.74, train 1170.09\n",
      "mse_null 1187.5543436247672 test 1358.44, train 1124.38\n",
      "mse_null 1187.5543436247672 test 1308.07, train 1090.47\n",
      "mse_null 1187.5543436247672 test 1421.05, train 1100.92\n",
      "mse_null 1187.5543436247672 test 1331.64, train 1024.69\n",
      "mse_null 1187.5543436247672 test 1273.61, train 987.33\n",
      "mse_null 1187.5543436247672 test 1267.10, train 961.23\n",
      "mse_null 1187.5543436247672 test 1295.68, train 951.91\n",
      "mse_null 1187.5543436247672 test 1239.22, train 915.08\n",
      "mse_null 1187.5543436247672 test 1246.34, train 900.74\n",
      "mse_null 1187.5543436247672 test 1269.88, train 908.32\n",
      "mse_null 1187.5543436247672 test 1190.37, train 863.73\n",
      "mse_null 1187.5543436247672 test 1197.59, train 845.55\n",
      "mse_null 1187.5543436247672 test 1183.11, train 830.19\n",
      "mse_null 1187.5543436247672 test 1164.08, train 820.10\n",
      "mse_null 1187.5543436247672 test 1152.35, train 817.72\n",
      "mse_null 1187.5543436247672 test 1145.30, train 812.01\n",
      "mse_null 1187.5543436247672 test 1153.39, train 780.77\n",
      "mse_null 1187.5543436247672 test 1143.26, train 771.29\n",
      "mse_null 1187.5543436247672 test 1146.20, train 762.76\n",
      "mse_null 1187.5543436247672 test 1124.27, train 760.12\n",
      "mse_null 1187.5543436247672 test 1138.70, train 815.58\n",
      "mse_null 1187.5543436247672 test 1135.72, train 741.69\n",
      "mse_null 1187.5543436247672 test 1139.98, train 740.97\n",
      "mse_null 1187.5543436247672 test 1105.82, train 737.10\n",
      "mse_null 1187.5543436247672 test 1185.96, train 785.96\n",
      "mse_null 1187.5543436247672 test 1169.52, train 765.39\n",
      "mse_null 1187.5543436247672 test 1103.85, train 705.89\n",
      "mse_null 1187.5543436247672 test 1104.75, train 701.14\n",
      "mse_null 1187.5543436247672 test 1090.01, train 708.80\n",
      "mse_null 1187.5543436247672 test 1087.67, train 711.62\n",
      "mse_null 1187.5543436247672 test 1081.85, train 686.11\n",
      "mse_null 1187.5543436247672 test 1078.86, train 686.61\n",
      "mse_null 1187.5543436247672 test 1076.40, train 684.52\n",
      "mse_null 1187.5543436247672 test 1076.20, train 672.59\n",
      "mse_null 1187.5543436247672 test 1069.90, train 671.23\n",
      "mse_null 1187.5543436247672 test 1071.44, train 664.51\n",
      "mse_null 1187.5543436247672 test 1081.73, train 666.50\n",
      "mse_null 1187.5543436247672 test 1074.66, train 660.37\n",
      "mse_null 1187.5543436247672 test 1065.27, train 679.20\n",
      "mse_null 1187.5543436247672 test 1072.92, train 656.53\n",
      "mse_null 1187.5543436247672 test 1063.90, train 649.75\n",
      "mse_null 1187.5543436247672 test 1058.62, train 647.54\n",
      "mse_null 1187.5543436247672 test 1079.78, train 663.28\n",
      "mse_null 1187.5543436247672 test 1053.04, train 641.09\n",
      "mse_null 1187.5543436247672 test 1050.96, train 642.40\n",
      "mse_null 1187.5543436247672 test 1055.61, train 639.77\n",
      "mse_null 1187.5543436247672 test 1053.11, train 636.43\n",
      "mse_null 1187.5543436247672 test 1050.90, train 633.57\n",
      "mse_null 1187.5543436247672 test 1046.91, train 631.13\n",
      "mse_null 1187.5543436247672 test 1044.83, train 642.02\n",
      "mse_null 1187.5543436247672 test 1044.31, train 626.46\n",
      "mse_null 1187.5543436247672 test 1042.88, train 624.64\n",
      "mse_null 1187.5543436247672 test 1042.25, train 623.76\n",
      "mse_null 1187.5543436247672 test 1041.10, train 621.53\n",
      "mse_null 1187.5543436247672 test 1039.65, train 619.56\n",
      "mse_null 1187.5543436247672 test 1041.57, train 618.93\n",
      "mse_null 1187.5543436247672 test 1041.33, train 637.69\n",
      "mse_null 1187.5543436247672 test 1047.42, train 622.28\n",
      "mse_null 1187.5543436247672 test 1039.53, train 614.93\n",
      "mse_null 1187.5543436247672 test 1049.84, train 623.36\n",
      "mse_null 1187.5543436247672 test 1035.38, train 619.41\n",
      "mse_null 1187.5543436247672 test 1033.08, train 615.70\n",
      "mse_null 1187.5543436247672 test 1046.44, train 621.57\n",
      "mse_null 1187.5543436247672 test 1031.70, train 607.61\n",
      "mse_null 1187.5543436247672 test 1044.59, train 645.43\n",
      "mse_null 1187.5543436247672 test 1030.40, train 610.47\n",
      "mse_null 1187.5543436247672 test 1029.66, train 608.05\n",
      "mse_null 1187.5543436247672 test 1060.94, train 638.42\n",
      "mse_null 1187.5543436247672 test 1049.20, train 623.59\n",
      "mse_null 1187.5543436247672 test 1028.20, train 608.67\n",
      "mse_null 1187.5543436247672 test 1042.87, train 615.84\n",
      "mse_null 1187.5543436247672 test 1026.85, train 608.42\n",
      "mse_null 1187.5543436247672 test 1037.98, train 610.61\n",
      "mse_null 1187.5543436247672 test 1024.48, train 597.69\n",
      "mse_null 1187.5543436247672 test 1025.43, train 596.47\n",
      "mse_null 1187.5543436247672 test 1026.20, train 595.84\n",
      "mse_null 1187.5543436247672 test 1031.97, train 600.54\n",
      "mse_null 1187.5543436247672 test 1023.76, train 601.77\n",
      "mse_null 1187.5543436247672 test 1027.11, train 597.10\n",
      "mse_null 1187.5543436247672 test 1023.07, train 598.15\n",
      "mse_null 1187.5543436247672 test 1032.30, train 601.53\n",
      "mse_null 1187.5543436247672 test 1020.82, train 592.67\n",
      "mse_null 1187.5543436247672 test 1022.97, train 591.78\n",
      "mse_null 1187.5543436247672 test 1095.04, train 690.56\n",
      "mse_null 1187.5543436247672 test 1019.98, train 590.72\n",
      "mse_null 1187.5543436247672 test 1022.74, train 589.80\n",
      "mse_null 1187.5543436247672 test 1022.90, train 588.90\n",
      "mse_null 1187.5543436247672 test 1021.07, train 591.39\n",
      "mse_null 1187.5543436247672 test 1022.52, train 596.17\n",
      "mse_null 1187.5543436247672 test 1050.24, train 626.07\n",
      "mse_null 1187.5543436247672 test 1025.04, train 590.28\n",
      "mse_null 1187.5543436247672 test 1023.35, train 599.77\n",
      "mse_null 1187.5543436247672 test 1049.33, train 624.02\n",
      "mse_null 1187.5543436247672 test 1037.19, train 608.19\n",
      "mse_null 1187.5543436247672 test 1020.93, train 591.61\n",
      "mse_null 1187.5543436247672 test 1018.94, train 586.47\n",
      "mse_null 1187.5543436247672 test 1018.89, train 584.05\n",
      "mse_null 1187.5543436247672 test 1043.34, train 635.77\n",
      "mse_null 1187.5543436247672 test 1019.77, train 586.20\n",
      "mse_null 1187.5543436247672 test 1023.69, train 586.99\n",
      "mse_null 1187.5543436247672 test 1024.55, train 599.94\n",
      "mse_null 1187.5543436247672 test 1025.31, train 600.85\n",
      "mse_null 1187.5543436247672 test 1025.06, train 589.16\n",
      "mse_null 1187.5543436247672 test 1039.95, train 613.28\n",
      "mse_null 1187.5543436247672 test 1019.16, train 588.56\n",
      "mse_null 1187.5543436247672 test 1015.44, train 577.84\n",
      "mse_null 1187.5543436247672 test 1020.69, train 583.43\n",
      "mse_null 1187.5543436247672 test 1014.26, train 578.85\n",
      "mse_null 1187.5543436247672 test 1014.77, train 578.31\n",
      "mse_null 1187.5543436247672 test 1048.62, train 626.65\n",
      "mse_null 1187.5543436247672 test 1025.48, train 599.20\n",
      "mse_null 1187.5543436247672 test 1034.20, train 604.19\n",
      "mse_null 1187.5543436247672 test 1015.64, train 581.79\n",
      "mse_null 1187.5543436247672 test 1026.73, train 591.74\n",
      "mse_null 1187.5543436247672 test 1015.72, train 578.54\n",
      "mse_null 1187.5543436247672 test 1015.88, train 574.64\n",
      "mse_null 1187.5543436247672 test 1015.98, train 579.57\n",
      "mse_null 1187.5543436247672 test 1015.38, train 575.22\n",
      "mse_null 1187.5543436247672 test 1013.55, train 573.09\n",
      "mse_null 1187.5543436247672 test 1017.31, train 576.27\n",
      "mse_null 1187.5543436247672 test 1014.17, train 573.03\n",
      "mse_null 1187.5543436247672 test 1025.14, train 595.78\n",
      "mse_null 1187.5543436247672 test 1014.10, train 571.69\n",
      "mse_null 1187.5543436247672 test 1014.86, train 572.01\n",
      "mse_null 1187.5543436247672 test 1015.20, train 573.31\n",
      "mse_null 1187.5543436247672 test 1023.25, train 586.80\n",
      "mse_null 1187.5543436247672 test 1026.30, train 590.34\n",
      "mse_null 1187.5543436247672 test 1011.33, train 569.59\n",
      "mse_null 1187.5543436247672 test 1011.90, train 570.47\n",
      "mse_null 1187.5543436247672 test 1018.83, train 579.17\n",
      "mse_null 1187.5543436247672 test 1013.26, train 569.72\n",
      "mse_null 1187.5543436247672 test 1042.17, train 617.39\n",
      "mse_null 1187.5543436247672 test 1018.61, train 585.11\n",
      "mse_null 1187.5543436247672 test 1010.67, train 567.70\n",
      "mse_null 1187.5543436247672 test 1015.80, train 578.34\n",
      "mse_null 1187.5543436247672 test 1027.79, train 603.84\n",
      "mse_null 1187.5543436247672 test 1012.35, train 572.14\n",
      "mse_null 1187.5543436247672 test 1027.57, train 594.49\n",
      "mse_null 1187.5543436247672 test 1010.47, train 566.22\n",
      "mse_null 1187.5543436247672 test 1008.90, train 565.91\n",
      "mse_null 1187.5543436247672 test 1009.41, train 565.88\n",
      "mse_null 1187.5543436247672 test 1009.66, train 565.09\n",
      "mse_null 1187.5543436247672 test 1010.06, train 567.92\n",
      "mse_null 1187.5543436247672 test 1013.65, train 574.31\n",
      "mse_null 1187.5543436247672 test 1010.78, train 565.94\n",
      "mse_null 1187.5543436247672 test 1023.80, train 587.65\n",
      "mse_null 1187.5543436247672 test 1009.51, train 564.86\n",
      "mse_null 1187.5543436247672 test 1008.29, train 563.93\n",
      "mse_null 1187.5543436247672 test 1008.29, train 564.22\n",
      "mse_null 1187.5543436247672 test 1009.86, train 567.50\n",
      "mse_null 1187.5543436247672 test 1029.97, train 599.53\n",
      "mse_null 1187.5543436247672 test 1008.25, train 563.61\n",
      "mse_null 1187.5543436247672 test 1007.69, train 562.67\n",
      "mse_null 1187.5543436247672 test 1010.60, train 566.43\n",
      "mse_null 1187.5543436247672 test 1008.17, train 561.88\n",
      "mse_null 1187.5543436247672 test 1008.75, train 563.22\n",
      "mse_null 1187.5543436247672 test 1021.97, train 585.42\n",
      "mse_null 1187.5543436247672 test 1008.61, train 561.40\n",
      "mse_null 1187.5543436247672 test 1008.54, train 560.97\n",
      "mse_null 1187.5543436247672 test 1014.59, train 570.94\n",
      "mse_null 1187.5543436247672 test 1019.23, train 580.07\n",
      "mse_null 1187.5543436247672 test 1009.20, train 560.91\n",
      "mse_null 1187.5543436247672 test 1009.29, train 560.61\n",
      "mse_null 1187.5543436247672 test 1009.81, train 560.83\n",
      "mse_null 1187.5543436247672 test 1024.38, train 587.95\n",
      "mse_null 1187.5543436247672 test 1015.39, train 572.58\n",
      "mse_null 1187.5543436247672 test 1011.17, train 565.27\n",
      "mse_null 1187.5543436247672 test 1008.39, train 560.08\n",
      "mse_null 1187.5543436247672 test 1010.14, train 562.37\n",
      "mse_null 1187.5543436247672 test 1012.38, train 566.60\n",
      "mse_null 1187.5543436247672 test 1015.20, train 573.06\n",
      "mse_null 1187.5543436247672 test 1015.99, train 573.09\n",
      "mse_null 1187.5543436247672 test 1014.05, train 572.11\n",
      "mse_null 1187.5543436247672 test 1017.13, train 577.77\n",
      "mse_null 1187.5543436247672 test 1027.28, train 592.62\n",
      "mse_null 1187.5543436247672 test 1010.01, train 563.67\n",
      "mse_null 1187.5543436247672 test 1023.28, train 586.49\n",
      "mse_null 1187.5543436247672 test 1017.75, train 575.40\n",
      "mse_null 1187.5543436247672 test 1008.39, train 559.73\n",
      "mse_null 1187.5543436247672 test 1018.68, train 578.12\n",
      "mse_null 1187.5543436247672 test 1015.70, train 572.38\n",
      "mse_null 1187.5543436247672 test 1008.57, train 558.26\n",
      "mse_null 1187.5543436247672 test 1021.27, train 583.81\n",
      "mse_null 1187.5543436247672 test 1008.44, train 558.42\n",
      "mse_null 1187.5543436247672 test 1006.28, train 555.86\n",
      "mse_null 1187.5543436247672 test 1006.77, train 556.53\n",
      "mse_null 1187.5543436247672 test 1011.01, train 563.97\n",
      "mse_null 1187.5543436247672 test 1005.64, train 555.09\n",
      "mse_null 1187.5543436247672 test 1014.82, train 571.95\n",
      "mse_null 1187.5543436247672 test 1005.18, train 554.28\n",
      "mse_null 1187.5543436247672 test 1005.62, train 555.43\n",
      "mse_null 1187.5543436247672 test 1005.88, train 555.00\n",
      "mse_null 1187.5543436247672 test 1005.12, train 553.33\n",
      "mse_null 1187.5543436247672 test 1009.62, train 561.86\n",
      "mse_null 1187.5543436247672 test 1006.16, train 554.16\n",
      "mse_null 1187.5543436247672 test 1011.49, train 563.52\n",
      "mse_null 1187.5543436247672 test 1009.73, train 562.01\n",
      "mse_null 1187.5543436247672 test 1007.47, train 557.94\n",
      "mse_null 1187.5543436247672 test 1004.63, train 552.76\n",
      "mse_null 1187.5543436247672 test 1008.56, train 559.74\n",
      "mse_null 1187.5543436247672 test 1003.74, train 551.73\n",
      "mse_null 1187.5543436247672 test 1006.69, train 556.87\n",
      "mse_null 1187.5543436247672 test 1002.97, train 551.28\n",
      "mse_null 1187.5543436247672 test 1003.22, train 553.51\n",
      "mse_null 1187.5543436247672 test 1002.35, train 550.89\n",
      "mse_null 1187.5543436247672 test 1003.87, train 554.62\n",
      "mse_null 1187.5543436247672 test 1007.30, train 560.18\n",
      "mse_null 1187.5543436247672 test 1011.23, train 565.18\n",
      "mse_null 1187.5543436247672 test 1003.56, train 554.12\n",
      "mse_null 1187.5543436247672 test 1018.72, train 582.60\n",
      "mse_null 1187.5543436247672 test 1000.58, train 549.66\n",
      "mse_null 1187.5543436247672 test 1003.49, train 553.49\n",
      "mse_null 1187.5543436247672 test 1001.38, train 551.53\n",
      "mse_null 1187.5543436247672 test 1013.11, train 570.83\n",
      "mse_null 1187.5543436247672 test 1001.45, train 550.04\n",
      "mse_null 1187.5543436247672 test 1003.47, train 551.97\n",
      "mse_null 1187.5543436247672 test 1004.70, train 554.31\n",
      "mse_null 1187.5543436247672 test 1003.83, train 552.01\n",
      "mse_null 1187.5543436247672 test 1002.82, train 551.80\n",
      "mse_null 1187.5543436247672 test 1002.14, train 548.62\n",
      "mse_null 1187.5543436247672 test 1003.00, train 551.03\n",
      "mse_null 1187.5543436247672 test 1001.86, train 549.52\n",
      "mse_null 1187.5543436247672 test 1002.83, train 550.37\n",
      "mse_null 1187.5543436247672 test 1001.21, train 547.03\n",
      "mse_null 1187.5543436247672 test 1002.76, train 553.21\n",
      "mse_null 1187.5543436247672 test 999.87, train 548.46\n",
      "mse_null 1187.5543436247672 test 1000.67, train 549.54\n",
      "mse_null 1187.5543436247672 test 1003.78, train 554.14\n",
      "mse_null 1187.5543436247672 test 1001.46, train 550.23\n",
      "mse_null 1187.5543436247672 test 1004.09, train 555.46\n",
      "mse_null 1187.5543436247672 test 1007.24, train 561.10\n",
      "mse_null 1187.5543436247672 test 1023.57, train 583.54\n",
      "mse_null 1187.5543436247672 test 1015.95, train 571.02\n",
      "mse_null 1187.5543436247672 test 1001.21, train 546.27\n",
      "mse_null 1187.5543436247672 test 999.40, train 545.69\n",
      "mse_null 1187.5543436247672 test 1006.98, train 556.02\n",
      "mse_null 1187.5543436247672 test 1007.25, train 561.67\n",
      "mse_null 1187.5543436247672 test 1000.62, train 547.15\n",
      "mse_null 1187.5543436247672 test 1012.25, train 572.21\n",
      "mse_null 1187.5543436247672 test 1002.76, train 547.87\n",
      "mse_null 1187.5543436247672 test 1001.51, train 546.18\n",
      "mse_null 1187.5543436247672 test 1000.08, train 545.24\n",
      "mse_null 1187.5543436247672 test 1000.45, train 545.07\n",
      "mse_null 1187.5543436247672 test 1000.77, train 546.74\n",
      "mse_null 1187.5543436247672 test 999.56, train 545.17\n",
      "mse_null 1187.5543436247672 test 1000.95, train 545.85\n",
      "mse_null 1187.5543436247672 test 1000.98, train 547.69\n",
      "mse_null 1187.5543436247672 test 1008.88, train 557.05\n",
      "mse_null 1187.5543436247672 test 1006.21, train 553.40\n",
      "mse_null 1187.5543436247672 test 998.78, train 542.29\n",
      "mse_null 1187.5543436247672 test 998.47, train 543.01\n",
      "mse_null 1187.5543436247672 test 998.59, train 542.07\n",
      "mse_null 1187.5543436247672 test 1007.97, train 563.18\n",
      "mse_null 1187.5543436247672 test 998.89, train 544.64\n",
      "mse_null 1187.5543436247672 test 1008.35, train 561.57\n",
      "mse_null 1187.5543436247672 test 1002.62, train 549.19\n",
      "mse_null 1187.5543436247672 test 997.98, train 541.13\n",
      "mse_null 1187.5543436247672 test 998.41, train 541.86\n",
      "mse_null 1187.5543436247672 test 1016.67, train 580.74\n",
      "mse_null 1187.5543436247672 test 1000.06, train 546.75\n",
      "mse_null 1187.5543436247672 test 997.96, train 541.42\n",
      "mse_null 1187.5543436247672 test 998.97, train 543.11\n",
      "mse_null 1187.5543436247672 test 1009.44, train 564.78\n",
      "mse_null 1187.5543436247672 test 1012.21, train 568.83\n",
      "mse_null 1187.5543436247672 test 1001.43, train 546.10\n",
      "mse_null 1187.5543436247672 test 998.08, train 542.28\n",
      "mse_null 1187.5543436247672 test 997.38, train 539.95\n",
      "mse_null 1187.5543436247672 test 1001.62, train 545.01\n",
      "mse_null 1187.5543436247672 test 1002.26, train 549.05\n",
      "mse_null 1187.5543436247672 test 998.56, train 538.74\n",
      "mse_null 1187.5543436247672 test 1021.23, train 573.40\n",
      "mse_null 1187.5543436247672 test 1013.97, train 570.36\n",
      "mse_null 1187.5543436247672 test 1002.14, train 543.45\n",
      "mse_null 1187.5543436247672 test 999.46, train 538.67\n",
      "mse_null 1187.5543436247672 test 998.17, train 538.36\n",
      "mse_null 1187.5543436247672 test 997.94, train 537.83\n",
      "mse_null 1187.5543436247672 test 999.37, train 539.50\n",
      "mse_null 1187.5543436247672 test 999.37, train 539.86\n",
      "mse_null 1187.5543436247672 test 1004.41, train 555.16\n",
      "mse_null 1187.5543436247672 test 1031.19, train 590.67\n",
      "mse_null 1187.5543436247672 test 997.94, train 538.36\n",
      "mse_null 1187.5543436247672 test 997.12, train 539.01\n",
      "mse_null 1187.5543436247672 test 1004.58, train 547.21\n",
      "mse_null 1187.5543436247672 test 995.49, train 536.70\n",
      "mse_null 1187.5543436247672 test 1020.80, train 587.42\n",
      "mse_null 1187.5543436247672 test 997.47, train 541.70\n",
      "mse_null 1187.5543436247672 test 995.75, train 536.63\n",
      "mse_null 1187.5543436247672 test 995.60, train 536.27\n",
      "mse_null 1187.5543436247672 test 999.16, train 541.87\n",
      "mse_null 1187.5543436247672 test 997.36, train 543.12\n",
      "mse_null 1187.5543436247672 test 998.00, train 542.53\n",
      "mse_null 1187.5543436247672 test 994.43, train 535.99\n",
      "mse_null 1187.5543436247672 test 994.17, train 535.54\n",
      "mse_null 1187.5543436247672 test 995.27, train 539.60\n",
      "mse_null 1187.5543436247672 test 996.75, train 536.82\n",
      "mse_null 1187.5543436247672 test 996.01, train 536.06\n",
      "mse_null 1187.5543436247672 test 995.04, train 538.55\n",
      "mse_null 1187.5543436247672 test 997.41, train 543.42\n",
      "mse_null 1187.5543436247672 test 993.91, train 533.98\n",
      "mse_null 1187.5543436247672 test 1006.55, train 549.94\n",
      "mse_null 1187.5543436247672 test 995.48, train 534.37\n",
      "mse_null 1187.5543436247672 test 1001.18, train 543.39\n",
      "mse_null 1187.5543436247672 test 994.21, train 534.11\n",
      "mse_null 1187.5543436247672 test 994.33, train 535.19\n",
      "mse_null 1187.5543436247672 test 993.84, train 535.91\n",
      "mse_null 1187.5543436247672 test 1002.01, train 546.05\n",
      "mse_null 1187.5543436247672 test 995.81, train 534.43\n",
      "mse_null 1187.5543436247672 test 998.10, train 543.12\n",
      "mse_null 1187.5543436247672 test 997.10, train 540.38\n",
      "mse_null 1187.5543436247672 test 995.46, train 537.29\n",
      "mse_null 1187.5543436247672 test 993.92, train 532.27\n",
      "mse_null 1187.5543436247672 test 994.17, train 531.88\n",
      "mse_null 1187.5543436247672 test 995.82, train 532.85\n",
      "mse_null 1187.5543436247672 test 996.78, train 536.98\n",
      "mse_null 1187.5543436247672 test 1003.78, train 552.82\n",
      "mse_null 1187.5543436247672 test 1016.94, train 567.69\n",
      "mse_null 1187.5543436247672 test 995.38, train 537.00\n",
      "mse_null 1187.5543436247672 test 994.58, train 533.31\n",
      "mse_null 1187.5543436247672 test 998.12, train 536.48\n",
      "mse_null 1187.5543436247672 test 1019.76, train 570.05\n",
      "mse_null 1187.5543436247672 test 994.84, train 535.46\n",
      "mse_null 1187.5543436247672 test 995.51, train 532.88\n",
      "mse_null 1187.5543436247672 test 1008.14, train 552.58\n",
      "mse_null 1187.5543436247672 test 1001.43, train 543.88\n",
      "mse_null 1187.5543436247672 test 994.55, train 535.19\n",
      "mse_null 1187.5543436247672 test 992.37, train 530.04\n",
      "mse_null 1187.5543436247672 test 993.71, train 534.69\n",
      "mse_null 1187.5543436247672 test 992.67, train 532.01\n",
      "mse_null 1187.5543436247672 test 992.19, train 529.20\n",
      "mse_null 1187.5543436247672 test 991.78, train 529.06\n",
      "mse_null 1187.5543436247672 test 1006.21, train 561.06\n",
      "mse_null 1187.5543436247672 test 997.64, train 544.53\n",
      "mse_null 1187.5543436247672 test 992.19, train 529.07\n",
      "mse_null 1187.5543436247672 test 991.38, train 528.22\n",
      "mse_null 1187.5543436247672 test 1006.15, train 551.46\n",
      "mse_null 1187.5543436247672 test 992.15, train 531.14\n",
      "mse_null 1187.5543436247672 test 992.57, train 528.09\n",
      "mse_null 1187.5543436247672 test 993.36, train 532.51\n",
      "mse_null 1187.5543436247672 test 992.64, train 529.12\n",
      "mse_null 1187.5543436247672 test 994.57, train 536.00\n",
      "mse_null 1187.5543436247672 test 995.75, train 534.57\n",
      "mse_null 1187.5543436247672 test 994.09, train 529.01\n",
      "mse_null 1187.5543436247672 test 993.26, train 528.44\n",
      "mse_null 1187.5543436247672 test 991.07, train 528.79\n",
      "mse_null 1187.5543436247672 test 994.10, train 530.64\n",
      "mse_null 1187.5543436247672 test 1008.32, train 553.71\n",
      "mse_null 1187.5543436247672 test 997.76, train 536.36\n",
      "mse_null 1187.5543436247672 test 995.62, train 532.56\n",
      "mse_null 1187.5543436247672 test 990.62, train 527.26\n",
      "mse_null 1187.5543436247672 test 993.72, train 531.40\n",
      "mse_null 1187.5543436247672 test 989.90, train 526.10\n",
      "mse_null 1187.5543436247672 test 989.49, train 529.08\n",
      "mse_null 1187.5543436247672 test 990.87, train 528.45\n",
      "mse_null 1187.5543436247672 test 988.86, train 525.97\n",
      "mse_null 1187.5543436247672 test 990.04, train 528.58\n",
      "mse_null 1187.5543436247672 test 1005.63, train 562.18\n",
      "mse_null 1187.5543436247672 test 990.97, train 525.27\n",
      "mse_null 1187.5543436247672 test 999.65, train 549.60\n",
      "mse_null 1187.5543436247672 test 1006.57, train 562.73\n",
      "mse_null 1187.5543436247672 test 993.74, train 530.27\n",
      "mse_null 1187.5543436247672 test 989.52, train 524.65\n",
      "mse_null 1187.5543436247672 test 992.93, train 528.10\n",
      "mse_null 1187.5543436247672 test 995.91, train 531.20\n",
      "mse_null 1187.5543436247672 test 1002.58, train 554.52\n",
      "mse_null 1187.5543436247672 test 989.58, train 523.53\n",
      "mse_null 1187.5543436247672 test 988.32, train 523.28\n",
      "mse_null 1187.5543436247672 test 1003.03, train 542.98\n",
      "mse_null 1187.5543436247672 test 994.79, train 529.93\n",
      "mse_null 1187.5543436247672 test 989.83, train 527.22\n",
      "mse_null 1187.5543436247672 test 989.50, train 523.07\n",
      "mse_null 1187.5543436247672 test 989.25, train 522.49\n",
      "mse_null 1187.5543436247672 test 988.71, train 523.32\n",
      "mse_null 1187.5543436247672 test 994.83, train 530.82\n",
      "mse_null 1187.5543436247672 test 990.44, train 522.92\n",
      "mse_null 1187.5543436247672 test 991.52, train 524.50\n",
      "mse_null 1187.5543436247672 test 992.76, train 527.14\n",
      "mse_null 1187.5543436247672 test 988.21, train 521.52\n",
      "mse_null 1187.5543436247672 test 989.43, train 521.97\n",
      "mse_null 1187.5543436247672 test 988.00, train 521.47\n",
      "mse_null 1187.5543436247672 test 990.67, train 529.74\n",
      "mse_null 1187.5543436247672 test 987.90, train 522.53\n",
      "mse_null 1187.5543436247672 test 988.65, train 525.22\n",
      "mse_null 1187.5543436247672 test 988.04, train 521.39\n",
      "mse_null 1187.5543436247672 test 987.89, train 519.98\n",
      "mse_null 1187.5543436247672 test 989.34, train 524.29\n",
      "mse_null 1187.5543436247672 test 999.79, train 534.99\n",
      "mse_null 1187.5543436247672 test 990.46, train 523.09\n",
      "mse_null 1187.5543436247672 test 992.82, train 527.44\n",
      "mse_null 1187.5543436247672 test 990.74, train 520.85\n",
      "mse_null 1187.5543436247672 test 989.63, train 523.07\n",
      "mse_null 1187.5543436247672 test 990.17, train 520.35\n",
      "mse_null 1187.5543436247672 test 988.34, train 519.43\n",
      "mse_null 1187.5543436247672 test 988.64, train 519.34\n",
      "mse_null 1187.5543436247672 test 987.43, train 518.71\n",
      "mse_null 1187.5543436247672 test 1003.65, train 556.11\n",
      "mse_null 1187.5543436247672 test 1004.50, train 558.17\n",
      "mse_null 1187.5543436247672 test 987.15, train 518.24\n",
      "mse_null 1187.5543436247672 test 998.53, train 533.80\n",
      "mse_null 1187.5543436247672 test 993.32, train 525.84\n",
      "mse_null 1187.5543436247672 test 991.57, train 522.73\n",
      "mse_null 1187.5543436247672 test 989.20, train 518.20\n",
      "mse_null 1187.5543436247672 test 988.20, train 521.26\n",
      "mse_null 1187.5543436247672 test 988.75, train 524.93\n",
      "mse_null 1187.5543436247672 test 999.80, train 537.18\n",
      "mse_null 1187.5543436247672 test 988.43, train 521.32\n",
      "mse_null 1187.5543436247672 test 1000.29, train 535.92\n",
      "mse_null 1187.5543436247672 test 986.55, train 518.98\n",
      "mse_null 1187.5543436247672 test 987.59, train 517.59\n",
      "mse_null 1187.5543436247672 test 985.29, train 516.01\n",
      "mse_null 1187.5543436247672 test 988.58, train 517.69\n",
      "mse_null 1187.5543436247672 test 996.21, train 528.96\n",
      "mse_null 1187.5543436247672 test 1003.00, train 540.48\n",
      "mse_null 1187.5543436247672 test 985.88, train 517.68\n",
      "mse_null 1187.5543436247672 test 985.68, train 515.47\n",
      "mse_null 1187.5543436247672 test 987.76, train 516.51\n",
      "mse_null 1187.5543436247672 test 988.38, train 517.07\n",
      "mse_null 1187.5543436247672 test 987.08, train 518.84\n",
      "mse_null 1187.5543436247672 test 992.44, train 523.96\n",
      "mse_null 1187.5543436247672 test 989.02, train 516.86\n",
      "mse_null 1187.5543436247672 test 988.14, train 515.35\n",
      "mse_null 1187.5543436247672 test 986.78, train 514.96\n",
      "mse_null 1187.5543436247672 test 986.52, train 517.27\n",
      "mse_null 1187.5543436247672 test 986.45, train 515.56\n",
      "mse_null 1187.5543436247672 test 991.65, train 520.30\n",
      "mse_null 1187.5543436247672 test 986.86, train 513.16\n",
      "mse_null 1187.5543436247672 test 1000.35, train 545.81\n",
      "mse_null 1187.5543436247672 test 996.47, train 526.17\n",
      "mse_null 1187.5543436247672 test 987.72, train 516.94\n",
      "mse_null 1187.5543436247672 test 1000.88, train 534.38\n",
      "mse_null 1187.5543436247672 test 997.42, train 527.98\n",
      "mse_null 1187.5543436247672 test 993.56, train 530.80\n",
      "mse_null 1187.5543436247672 test 987.01, train 512.35\n",
      "mse_null 1187.5543436247672 test 987.18, train 511.92\n",
      "mse_null 1187.5543436247672 test 987.26, train 512.21\n",
      "mse_null 1187.5543436247672 test 1003.95, train 538.55\n",
      "mse_null 1187.5543436247672 test 986.70, train 513.63\n",
      "mse_null 1187.5543436247672 test 986.99, train 513.81\n",
      "mse_null 1187.5543436247672 test 1001.36, train 536.46\n",
      "mse_null 1187.5543436247672 test 987.37, train 512.82\n",
      "mse_null 1187.5543436247672 test 987.55, train 515.45\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1357], line 74\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stopping\u001b[38;5;241m.\u001b[39mearly_stop:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;66;03m# print(f\"Epoch {t+1}\\n-------------------------------\")\u001b[39;00m\n\u001b[1;32m     73\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m---> 74\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m     test_val \u001b[38;5;241m=\u001b[39m validate(test_dataloader, model, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     77\u001b[0m     train_val \u001b[38;5;241m=\u001b[39m validate(train_dataloader, model, \u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[1356], line 16\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(dataloader, model, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m     13\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(pred, y)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Backpropagation\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     18\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/miniconda3/envs/dl/lib/python3.10/site-packages/torch/_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    524\u001b[0m     )\n\u001b[0;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dl/lib/python3.10/site-packages/torch/autograd/__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dl/lib/python3.10/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import copy\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, tolerance=5, min_delta=0):\n",
    "\n",
    "        self.tolerance = tolerance\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, train_loss, validation_loss):\n",
    "        if (validation_loss - train_loss) > self.min_delta:\n",
    "            self.counter +=1\n",
    "            if self.counter >= self.tolerance:  \n",
    "                self.early_stop = True\n",
    "\n",
    "null_mse = 0\n",
    "def validate(test_dataloader, model, verbose=False):\n",
    "    global null_mse\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        i = 0\n",
    "        mse = 0\n",
    "        mse_null = 0\n",
    "        for x, y in test_dataloader:\n",
    "            x = x.clone()\n",
    "            y = y.clone()\n",
    "            i += 1\n",
    "            labels = 56\n",
    "            # labels = 0\n",
    "            # old_x = scaler_x.inverse_transform(x)\n",
    "            # year = old_x[:, year_idx]\n",
    "            # crime = old_x[:, idx]\n",
    "            # crime = scaler_y.inverse_transform(y.reshape(-1,1))\n",
    "            crime = y.detach().cpu().numpy() * 20000\n",
    "            old_x = x\n",
    "            x = x.to(device)\n",
    "            pred = model(x)\n",
    "            # print('pred', pred, 'y', y)\n",
    "            pred = pred.detach().cpu().numpy()\n",
    "            old_x = old_x.detach().cpu().numpy()\n",
    "            # out2 = np.hstack((x[:,labels:], pred.reshape(-1,1)))\n",
    "            out2 = scaler_x.inverse_transform(old_x)\n",
    "            # pred = scaler_y.inverse_transform(pred.reshape(-1,1))\n",
    "            pred = pred * 20000\n",
    "\n",
    "            mse += np.sum((pred - crime) ** 2)\n",
    "            mse_null += np.sum((out2[:, last_idx+labels] - crime) ** 2)\n",
    "\n",
    "    if verbose:\n",
    "        # print('mse', np.sqrt(mse/(batch_size*i)), end=' ')\n",
    "        print('mse_null', np.sqrt(mse_null/(batch_size*i)), end=' ')\n",
    "        null_mse = np.sqrt(mse_null/(batch_size*i))\n",
    "    return np.sqrt(mse/(batch_size*i))\n",
    "\n",
    "epochs = []\n",
    "loss = []\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "stopping = EarlyStopping(tolerance=50, min_delta=100)\n",
    "best_val = 1e9\n",
    "best_model = None\n",
    "last = 0\n",
    "epoch = 0\n",
    "while not stopping.early_stop:\n",
    "    # print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    model.train()\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "\n",
    "    test_val = validate(test_dataloader, model, True)\n",
    "    train_val = validate(train_dataloader, model, False)\n",
    "    print(f\"test {test_val:.2f}, train {train_val:.2f}\", end='\\n')\n",
    "\n",
    "    stopping(best_val, test_val)\n",
    "    last = test_val\n",
    "\n",
    "    if test_val < best_val:\n",
    "        best_val = test_val\n",
    "        best_model = copy.deepcopy(model)\n",
    "\n",
    "    epochs.append(epoch)\n",
    "    loss.append(test_val)\n",
    "    epoch += 1\n",
    "    if epoch % 10 == 0:\n",
    "        ax.clear()\n",
    "        ax.plot(epochs, loss)\n",
    "        ax.axhline(y=null_mse, color='r')\n",
    "        ax.set_ylim([best_val, best_val+200])\n",
    "        fig.savefig('loss.png')\n",
    "\n",
    "\n",
    "print(f\"\\nBest loss: {best_val:.2f}\")\n",
    "model = best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.scale_\n",
    "scaler.var_\n",
    "\n",
    "m = scaler.mean_[idx]\n",
    "s = scaler.scale_[idx]\n",
    "m, s\n",
    "\n",
    "y_m = scaler.mean_[year_idx]\n",
    "s_m = scaler.scale_[year_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1])"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = next(iter(test_dataloader))\n",
    "y.reshape(4, -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 5.7707e-02, 0.0000e+00, 4.5917e-01,\n",
      "         2.8705e-01, 6.5267e-01, 6.4742e-01, 6.5627e-01, 5.9151e-04, 1.6346e-03,\n",
      "         1.5562e-03, 8.6199e-01, 1.8667e-01, 1.0964e-02, 8.0049e-02, 6.9897e-01,\n",
      "         0.0000e+00, 1.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         3.3883e-01, 1.0000e+00, 8.0340e-01, 1.0000e+00, 4.1874e-01, 2.8879e-01,\n",
      "         6.7442e-01, 1.0000e+00, 0.0000e+00, 4.0087e-01, 1.0000e+00, 7.2944e-01,\n",
      "         0.0000e+00, 1.0000e+00, 5.0468e-01, 0.0000e+00, 0.0000e+00, 1.5278e-02,\n",
      "         6.0744e-01, 1.2217e-01, 2.5315e-01, 1.2972e-01, 7.1621e-01, 7.2422e-01,\n",
      "         7.2178e-01, 1.0181e-02, 3.5626e-01, 7.1494e-01, 3.3358e-01, 6.1885e-01,\n",
      "         0.0000e+00, 2.0194e-01, 7.8426e-01, 7.4145e-01, 8.5923e-02, 7.7189e-03,\n",
      "         3.7822e-02, 9.1960e-01, 1.4562e-01, 8.1956e-01, 8.7483e-01, 8.3046e-01,\n",
      "         8.7217e-01, 6.9609e-01, 3.0708e-01, 1.2629e-02, 1.2683e-02, 1.6128e-02,\n",
      "         1.0737e-02, 2.6384e-01, 5.5139e-01, 6.2397e-02, 7.5782e-01, 7.6388e-01,\n",
      "         3.2580e-01, 2.1563e-02, 1.0964e-02, 2.2324e-01, 4.3221e-01, 1.0000e+00,\n",
      "         4.6476e-01, 2.1312e-01, 0.0000e+00, 5.7169e-02]], device='cuda:0')\n",
      "Predicted: \"[8890.785]\",\n",
      " Actual: \"[9876.331]\", Last: [4849.3267]\n",
      "Year: \"[2015.]\"\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.1386, 0.0191, 0.4852, 0.4126, 0.5159, 0.6459,\n",
      "         0.5685, 0.0010, 0.0059, 0.0038, 0.4590, 0.6937, 0.1256, 0.2877, 0.2961,\n",
      "         0.1548, 0.1984, 0.0000, 0.3023, 0.0925, 0.3765, 0.1914, 0.2286, 0.2860,\n",
      "         0.1614, 0.2066, 0.6937, 0.4949, 0.3952, 0.0406, 0.7546, 0.7175, 0.3625,\n",
      "         0.1300, 0.2824, 0.2850, 0.4223, 0.0000, 0.1497, 0.5161, 0.1084, 0.2348,\n",
      "         0.0854, 0.4641, 0.6292, 0.7046, 0.1252, 0.4561, 0.4681, 0.2401, 0.5482,\n",
      "         0.3714, 0.3525, 0.7762, 0.7364, 0.2572, 0.0332, 0.0684, 0.8413, 0.3063,\n",
      "         0.6012, 0.5846, 0.6525, 0.7774, 0.7540, 0.3406, 0.1008, 0.0590, 0.0296,\n",
      "         0.0168, 1.0000, 0.9335, 0.7441, 0.5984, 0.6959, 0.8581, 0.1904, 0.1256,\n",
      "         0.8335, 0.1207, 0.5000, 0.4029, 0.2629, 0.0177, 0.1369]],\n",
      "       device='cuda:0')\n",
      "Predicted: \"[10688.268]\",\n",
      " Actual: \"[10182.525]\", Last: [4849.3267]\n",
      "Year: \"[2015.]\"\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.2089, 0.1216, 0.3440, 0.0974, 0.2835, 0.2692,\n",
      "         0.2811, 0.0217, 0.0106, 0.0218, 0.9838, 0.0021, 0.1840, 0.4435, 0.1446,\n",
      "         0.1134, 0.0882, 0.0000, 0.1017, 0.0904, 0.4137, 0.2628, 0.1970, 0.4418,\n",
      "         0.4433, 0.3202, 0.4898, 0.7477, 0.6658, 0.0000, 0.6081, 0.5729, 0.4096,\n",
      "         0.1904, 0.2069, 0.0522, 0.3094, 0.0000, 0.2074, 0.9004, 0.0989, 0.4718,\n",
      "         0.1558, 0.6591, 0.5440, 0.6201, 0.1780, 0.7157, 0.6322, 0.5135, 0.2330,\n",
      "         0.6788, 0.2728, 0.8455, 0.8271, 0.3803, 0.0293, 0.0878, 0.7671, 0.3483,\n",
      "         0.4115, 0.5153, 0.4688, 0.6070, 0.7674, 0.8017, 0.1499, 0.1622, 0.1959,\n",
      "         0.1888, 0.3306, 0.3038, 0.6749, 0.1993, 0.7542, 0.5355, 0.2008, 0.1840,\n",
      "         0.6702, 0.4918, 0.5000, 0.3393, 0.3624, 0.1469, 0.1923]],\n",
      "       device='cuda:0')\n",
      "Predicted: \"[12108.879]\",\n",
      " Actual: \"[11862.488]\", Last: [4849.3267]\n",
      "Year: \"[2015.]\"\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0333, 0.0501, 0.3176, 0.1529, 0.4460, 0.5155,\n",
      "         0.4741, 0.0010, 0.0067, 0.0081, 0.8717, 0.1651, 0.0744, 0.0758, 0.4359,\n",
      "         0.0000, 0.3001, 0.0000, 0.2435, 0.7719, 0.4158, 0.1761, 0.1782, 0.4716,\n",
      "         0.1188, 0.2208, 0.4330, 0.4642, 0.5912, 0.0000, 1.0000, 0.6453, 0.7626,\n",
      "         0.1914, 0.4158, 0.4196, 0.0000, 0.4372, 0.0901, 0.3510, 0.0257, 0.0747,\n",
      "         0.0226, 0.3801, 0.6385, 0.6986, 0.0771, 0.2511, 0.4764, 0.0605, 0.7462,\n",
      "         0.3116, 0.4918, 0.7643, 0.7335, 0.2319, 0.0205, 0.1263, 0.8442, 0.0677,\n",
      "         0.8223, 0.5191, 0.6069, 0.7446, 0.7963, 0.1761, 0.1104, 0.0510, 0.0374,\n",
      "         0.0193, 0.3585, 0.3074, 0.1878, 0.4801, 0.8279, 0.5612, 0.1341, 0.0744,\n",
      "         0.6850, 0.0000, 0.5000, 0.2720, 0.0496, 0.0501, 0.0299]],\n",
      "       device='cuda:0')\n",
      "Predicted: \"[5519.821]\",\n",
      " Actual: \"[4666.273]\", Last: [4849.3267]\n",
      "Year: \"[2015.]\"\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0541, 0.0379, 0.6204, 0.1506, 0.9109, 0.7730,\n",
      "         0.8453, 0.0026, 0.0067, 0.0054, 0.9317, 0.0917, 0.0333, 0.0881, 0.2337,\n",
      "         0.0000, 0.4930, 0.0000, 0.5795, 0.2191, 0.8916, 0.1133, 0.5413, 0.6355,\n",
      "         0.3821, 0.6763, 0.4855, 0.6056, 0.7842, 0.0000, 0.7148, 0.3087, 0.4502,\n",
      "         0.0000, 0.6687, 0.1687, 1.0000, 0.0000, 0.0420, 0.8647, 0.0883, 0.3531,\n",
      "         0.1697, 0.7456, 0.5608, 0.5199, 0.0326, 0.4946, 0.5968, 0.5449, 0.1228,\n",
      "         0.6426, 0.4395, 0.8274, 0.6897, 0.0748, 0.0650, 0.1217, 0.8147, 0.0000,\n",
      "         0.8496, 0.5839, 0.9144, 0.7469, 0.8420, 0.3218, 0.0000, 0.0224, 0.0271,\n",
      "         0.0043, 0.4202, 0.2891, 0.9238, 0.1766, 0.7752, 0.9104, 0.0390, 0.0333,\n",
      "         0.0867, 0.4447, 1.0000, 0.6325, 0.3925, 0.0305, 0.0511]],\n",
      "       device='cuda:0')\n",
      "Predicted: \"[13529.122]\",\n",
      " Actual: \"[15374.899]\", Last: [4849.3267]\n",
      "Year: \"[2015.]\"\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0808, 0.1025, 0.2297, 0.2061, 0.2210, 0.3385,\n",
      "         0.2902, 0.0013, 0.0027, 0.0122, 0.5084, 0.6228, 0.1545, 0.3917, 0.0836,\n",
      "         0.1311, 0.1046, 0.0000, 0.1373, 0.1828, 0.2392, 0.1418, 0.1936, 0.3004,\n",
      "         0.0683, 0.1311, 0.1938, 0.3379, 0.3405, 0.2292, 0.5753, 0.6948, 0.4913,\n",
      "         0.2202, 0.2392, 0.0604, 0.3577, 0.0000, 0.1760, 0.8581, 0.0427, 0.1709,\n",
      "         0.0573, 0.4766, 0.4692, 0.6612, 0.1603, 0.3611, 0.3916, 0.1775, 0.6198,\n",
      "         0.5152, 0.5195, 0.8312, 0.8116, 0.3864, 0.0657, 0.1329, 0.7978, 0.2776,\n",
      "         0.5855, 0.4000, 0.4409, 0.7401, 0.8739, 0.1893, 0.0865, 0.0424, 0.0287,\n",
      "         0.0109, 0.4976, 0.3453, 0.6747, 0.2100, 0.6965, 0.7187, 0.1732, 0.1545,\n",
      "         0.6932, 0.1194, 0.5000, 0.2227, 0.2228, 0.0982, 0.0734]],\n",
      "       device='cuda:0')\n",
      "Predicted: \"[7773.0835]\",\n",
      " Actual: \"[7883.0195]\", Last: [4849.3267]\n",
      "Year: \"[2015.]\"\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0442, 0.0421, 0.4282, 0.1362, 0.3815, 0.4535,\n",
      "         0.4210, 0.0013, 0.0064, 0.0084, 0.6708, 0.4196, 0.0602, 0.1746, 0.1672,\n",
      "         0.2622, 0.5911, 0.0000, 0.4300, 0.1045, 0.3189, 0.2431, 0.3872, 0.2698,\n",
      "         0.4100, 0.7307, 0.4030, 0.7537, 0.7262, 0.0000, 0.4474, 0.5954, 0.2897,\n",
      "         0.2202, 0.9566, 0.1207, 0.7153, 0.0000, 0.0761, 0.8583, 0.0788, 0.3778,\n",
      "         0.1407, 0.7175, 0.6177, 0.6169, 0.0613, 0.5436, 0.5101, 0.4393, 0.4683,\n",
      "         0.6939, 0.4123, 0.8209, 0.7639, 0.5022, 0.0367, 0.1408, 0.8306, 0.2354,\n",
      "         0.6509, 0.5383, 0.7750, 0.8526, 0.8213, 0.2134, 0.0469, 0.0477, 0.0564,\n",
      "         0.0285, 0.3953, 0.2710, 0.8603, 0.1659, 0.7560, 0.9289, 0.0733, 0.0602,\n",
      "         0.7675, 0.5171, 0.5000, 0.4394, 0.2597, 0.0386, 0.0394]],\n",
      "       device='cuda:0')\n",
      "Predicted: \"[9019.276]\",\n",
      " Actual: \"[8563.408]\", Last: [4849.3267]\n",
      "Year: \"[2015.]\"\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.0000, 0.0000, 0.0000, 0.2068, 0.3165, 0.0042, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 1.0000, 0.1488, 0.5964, 0.0000, 0.3732, 0.2505, 0.3091, 0.0554,\n",
      "         0.3476, 0.1442, 0.0000, 0.2538, 0.6579, 0.1057, 0.3492, 0.1057, 0.7332,\n",
      "         0.8833, 0.8145, 1.0000, 0.1019, 0.1199, 0.1025, 0.3601, 0.1569, 0.2874,\n",
      "         0.1459, 0.1585, 0.0400, 0.0000, 0.0000, 0.3142, 0.9145, 0.1034, 1.0000,\n",
      "         0.5456, 0.2145, 0.1004, 0.2292, 0.1982, 0.4519, 0.1384, 1.0000, 0.0890,\n",
      "         0.8734, 0.5952, 0.2590, 0.1323, 0.3235, 0.4206, 0.9978, 0.1313, 0.4363,\n",
      "         0.4692, 0.2401, 0.2421, 0.3608, 0.3498, 0.0803, 0.4590, 0.3525, 0.3784,\n",
      "         0.4102, 0.0429, 0.0431, 0.3654, 0.0148, 0.4438, 0.6793, 0.3187, 0.2505,\n",
      "         0.5348, 0.1956, 0.0000, 0.0035, 0.5104, 0.2998, 0.1973]],\n",
      "       device='cuda:0')\n",
      "Predicted: \"[14583.163]\",\n",
      " Actual: \"[14405.659]\", Last: [4849.3267]\n",
      "Year: \"[2015.]\"\n",
      "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 2.0000e-01, 5.0714e-02, 2.7963e-04, 4.5917e-01,\n",
      "         2.8705e-01, 6.5267e-01, 6.4742e-01, 6.5627e-01, 5.9151e-04, 1.6346e-03,\n",
      "         1.5562e-03, 8.6199e-01, 1.8667e-01, 1.0964e-02, 8.0049e-02, 6.9897e-01,\n",
      "         0.0000e+00, 1.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         3.3883e-01, 1.0000e+00, 8.0340e-01, 1.0000e+00, 4.1874e-01, 2.8879e-01,\n",
      "         6.7442e-01, 1.0000e+00, 0.0000e+00, 4.0087e-01, 1.0000e+00, 7.2944e-01,\n",
      "         0.0000e+00, 1.0000e+00, 5.0468e-01, 0.0000e+00, 0.0000e+00, 1.5278e-02,\n",
      "         6.0744e-01, 1.2217e-01, 2.5315e-01, 1.2972e-01, 7.1621e-01, 7.2422e-01,\n",
      "         7.2178e-01, 1.0181e-02, 3.5626e-01, 7.1494e-01, 3.3358e-01, 6.1885e-01,\n",
      "         0.0000e+00, 2.0194e-01, 7.8426e-01, 7.4145e-01, 8.5923e-02, 7.7189e-03,\n",
      "         3.7822e-02, 9.1960e-01, 1.4562e-01, 8.1956e-01, 8.7483e-01, 8.3046e-01,\n",
      "         8.7217e-01, 6.9609e-01, 3.0708e-01, 1.2629e-02, 1.2683e-02, 1.6128e-02,\n",
      "         1.0737e-02, 2.6384e-01, 5.5139e-01, 6.2397e-02, 7.5782e-01, 7.6388e-01,\n",
      "         3.2580e-01, 2.1563e-02, 1.0964e-02, 2.2324e-01, 4.3221e-01, 1.0000e+00,\n",
      "         4.6476e-01, 2.9750e-01, 1.0030e-04, 5.4947e-02]], device='cuda:0')\n",
      "Predicted: \"[8593.391]\",\n",
      " Actual: \"[11633.535]\", Last: [4849.3267]\n",
      "Year: \"[2016.]\"\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.2000, 0.0586, 0.1026, 0.3487, 0.1376, 0.3892, 0.4122,\n",
      "         0.4098, 0.0024, 0.0026, 0.0062, 0.6771, 0.4152, 0.0400, 0.1160, 0.4254,\n",
      "         0.0000, 0.1377, 0.0000, 0.3861, 0.3988, 0.4057, 0.2062, 0.7245, 0.4031,\n",
      "         0.3478, 0.3551, 0.2380, 0.7144, 0.8892, 0.0000, 0.7319, 0.6278, 0.3995,\n",
      "         0.5603, 0.6086, 0.7679, 0.9102, 0.0000, 0.0478, 0.4745, 0.0598, 0.2251,\n",
      "         0.0973, 0.5681, 0.6108, 0.6282, 0.0369, 0.3980, 0.4828, 0.3779, 0.3644,\n",
      "         0.3749, 0.3293, 0.7814, 0.7206, 0.2722, 0.0118, 0.0805, 0.8613, 0.1101,\n",
      "         0.6446, 0.6526, 0.7816, 0.7820, 0.8299, 0.1852, 0.0392, 0.0250, 0.0279,\n",
      "         0.0256, 0.3195, 0.6599, 0.0000, 0.9223, 1.0000, 0.4108, 0.0675, 0.0400,\n",
      "         0.3350, 0.0154, 0.5000, 0.3066, 0.2110, 0.0897, 0.0565]],\n",
      "       device='cuda:0')\n",
      "Predicted: \"[8092.0864]\",\n",
      " Actual: \"[9343.694]\", Last: [4849.3267]\n",
      "Year: \"[2016.]\"\n",
      "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 2.0000e-01, 1.5407e-01, 7.0830e-02, 7.0305e-01,\n",
      "         9.1186e-01, 9.0775e-01, 1.0000e+00, 1.0000e+00, 1.5658e-04, 6.9182e-04,\n",
      "         3.1752e-03, 2.1984e-01, 1.0000e+00, 1.3755e-01, 2.4048e-01, 3.6737e-01,\n",
      "         0.0000e+00, 7.1795e-01, 6.9628e-01, 3.5527e-01, 8.6101e-02, 6.1318e-01,\n",
      "         1.7808e-01, 2.7530e-01, 6.2053e-01, 2.2525e-01, 2.7897e-01, 4.7189e-01,\n",
      "         8.5736e-01, 5.7264e-01, 4.6582e-01, 6.3207e-01, 7.2771e-01, 3.2953e-01,\n",
      "         7.2579e-01, 2.6279e-01, 5.3050e-01, 3.9300e-01, 0.0000e+00, 1.7506e-01,\n",
      "         5.6296e-01, 9.3165e-02, 2.4613e-01, 8.0349e-02, 5.5988e-01, 7.4483e-01,\n",
      "         7.6789e-01, 1.4573e-01, 3.8387e-01, 3.5256e-01, 1.4830e-01, 3.7967e-01,\n",
      "         2.5265e-01, 3.1277e-01, 6.6858e-01, 5.9494e-01, 3.7081e-01, 1.1892e-02,\n",
      "         1.0416e-01, 8.7524e-01, 2.6427e-01, 7.2143e-01, 6.8491e-01, 7.6757e-01,\n",
      "         8.6254e-01, 6.1164e-01, 7.0835e-01, 1.1331e-01, 4.9540e-02, 3.3464e-02,\n",
      "         1.3906e-02, 8.3070e-01, 7.3103e-01, 7.0804e-01, 6.6507e-01, 6.0554e-01,\n",
      "         6.6143e-01, 2.1479e-01, 1.3755e-01, 1.0000e+00, 2.1516e-01, 1.0000e+00,\n",
      "         6.1760e-01, 2.7426e-01, 7.1044e-02, 1.4238e-01]], device='cuda:0')\n",
      "Predicted: \"[8990.975]\",\n",
      " Actual: \"[9118.421]\", Last: [4849.3267]\n",
      "Year: \"[2016.]\"\n",
      "tensor([[0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.2000, 0.1022, 0.0724, 0.2665, 0.0283, 0.4080, 0.3296,\n",
      "         0.3704, 0.0101, 0.0048, 0.0828, 0.8998, 0.0437, 0.0891, 0.1058, 0.1280,\n",
      "         0.0000, 0.1692, 0.0000, 0.3555, 0.3599, 0.2441, 0.0931, 0.1046, 0.0615,\n",
      "         0.0000, 0.1353, 0.3463, 0.4741, 0.8388, 0.0000, 0.2936, 0.2545, 0.0408,\n",
      "         0.3371, 0.3662, 0.2772, 0.0000, 0.7700, 0.1127, 0.0000, 0.0224, 0.0498,\n",
      "         0.0345, 0.2464, 0.6752, 0.6586, 0.0878, 0.3910, 0.6282, 0.3681, 0.7420,\n",
      "         0.2751, 0.3943, 0.6025, 0.5059, 0.2621, 0.0102, 0.1333, 0.7876, 0.1021,\n",
      "         0.5588, 0.5974, 0.8533, 0.8173, 0.7239, 0.1651, 0.1927, 0.0776, 0.0574,\n",
      "         0.0349, 0.5991, 0.4406, 0.7257, 0.2666, 0.6911, 0.4732, 0.2448, 0.0891,\n",
      "         0.5966, 0.0122, 0.5000, 0.1904, 0.2396, 0.0710, 0.0963]],\n",
      "       device='cuda:0')\n",
      "Predicted: \"[7677.3193]\",\n",
      " Actual: \"[8809.467]\", Last: [4849.3267]\n",
      "Year: \"[2016.]\"\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.2000, 0.0905, 0.1177, 0.2297, 0.2061, 0.2210, 0.3385,\n",
      "         0.2902, 0.0013, 0.0027, 0.0122, 0.5084, 0.6228, 0.1545, 0.3917, 0.0836,\n",
      "         0.1311, 0.1046, 0.0000, 0.1373, 0.1828, 0.2392, 0.1418, 0.1936, 0.3004,\n",
      "         0.0683, 0.1311, 0.1938, 0.3379, 0.3405, 0.2292, 0.5753, 0.6948, 0.4913,\n",
      "         0.2202, 0.2392, 0.0604, 0.3577, 0.0000, 0.1760, 0.8581, 0.0427, 0.1709,\n",
      "         0.0573, 0.4766, 0.4692, 0.6612, 0.1603, 0.3611, 0.3916, 0.1775, 0.6198,\n",
      "         0.5152, 0.5195, 0.8312, 0.8116, 0.3864, 0.0657, 0.1329, 0.7978, 0.2776,\n",
      "         0.5855, 0.4000, 0.4409, 0.7401, 0.8739, 0.1893, 0.0865, 0.0424, 0.0287,\n",
      "         0.0109, 0.4976, 0.3453, 0.6747, 0.2100, 0.6965, 0.7187, 0.1732, 0.1545,\n",
      "         0.6932, 0.1194, 0.5000, 0.2227, 0.2103, 0.1104, 0.0781]],\n",
      "       device='cuda:0')\n",
      "Predicted: \"[7522.3267]\",\n",
      " Actual: \"[8404.333]\", Last: [4849.3267]\n",
      "Year: \"[2016.]\"\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.2000, 0.5840, 0.2749, 0.0254, 0.0011, 0.0000, 0.0000,\n",
      "         0.0000, 0.2276, 0.2602, 0.8584, 0.0000, 0.1732, 0.4259, 0.4215, 0.0000,\n",
      "         0.0538, 0.0827, 0.0000, 0.0766, 0.1928, 0.1961, 0.1661, 0.1261, 0.3574,\n",
      "         0.2382, 0.1976, 0.5921, 0.4308, 0.5300, 0.5474, 0.3800, 0.1642, 0.1758,\n",
      "         0.1806, 0.1961, 0.0247, 0.2933, 0.0000, 0.5083, 0.9520, 0.0319, 0.4311,\n",
      "         0.3921, 0.5909, 0.4076, 0.6390, 0.3960, 0.6508, 0.5407, 0.9964, 0.3939,\n",
      "         0.5362, 0.4310, 0.5066, 0.3466, 0.3713, 0.3158, 0.5404, 0.3894, 0.4929,\n",
      "         0.2111, 0.6052, 0.5640, 0.5925, 0.5918, 0.1861, 0.5659, 0.5513, 0.6465,\n",
      "         0.5279, 0.1125, 0.0715, 0.4319, 0.0438, 0.3091, 0.3989, 0.4842, 0.4259,\n",
      "         0.5422, 0.2059, 0.0000, 0.0172, 0.3070, 0.2515, 0.5795]],\n",
      "       device='cuda:0')\n",
      "Predicted: \"[9364.324]\",\n",
      " Actual: \"[10864.071]\", Last: [4849.3267]\n",
      "Year: \"[2016.]\"\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.2000, 0.5096, 0.2146, 0.0655, 0.0041, 0.0000, 0.0000,\n",
      "         0.0000, 0.2840, 0.2166, 0.6089, 0.0753, 0.3667, 0.5233, 0.5743, 0.0566,\n",
      "         0.1775, 0.0241, 0.0000, 0.1143, 0.2917, 0.0270, 0.1988, 0.0848, 0.1842,\n",
      "         0.0809, 0.1567, 0.1777, 0.4567, 0.4733, 0.3490, 0.4110, 0.1821, 0.0912,\n",
      "         0.1490, 0.1619, 0.0409, 0.1211, 0.0000, 0.5781, 1.0000, 0.0396, 0.1563,\n",
      "         0.0655, 0.2361, 0.2198, 0.6279, 0.5523, 0.4422, 0.3744, 0.9016, 0.7637,\n",
      "         0.7443, 0.7613, 0.7620, 0.7963, 0.3884, 0.1698, 0.2871, 0.5612, 0.3099,\n",
      "         0.3236, 0.3126, 0.2682, 0.5451, 0.8486, 0.0596, 0.4497, 0.3615, 0.3419,\n",
      "         0.1748, 0.0783, 0.0792, 0.4049, 0.0464, 0.7111, 0.4308, 0.5202, 0.5233,\n",
      "         0.5770, 0.1764, 0.0000, 0.0599, 0.1444, 0.2080, 0.5049]],\n",
      "       device='cuda:0')\n",
      "Predicted: \"[5841.993]\",\n",
      " Actual: \"[7565.808]\", Last: [4849.3267]\n",
      "Year: \"[2016.]\"\n",
      "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 4.0000e-01, 5.1102e-02, 2.7963e-03, 4.5917e-01,\n",
      "         2.8705e-01, 6.5267e-01, 6.4742e-01, 6.5627e-01, 5.9151e-04, 1.6346e-03,\n",
      "         1.5562e-03, 8.6199e-01, 1.8667e-01, 1.0964e-02, 8.0049e-02, 6.9897e-01,\n",
      "         0.0000e+00, 1.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         3.3883e-01, 1.0000e+00, 8.0340e-01, 1.0000e+00, 4.1874e-01, 2.8879e-01,\n",
      "         6.7442e-01, 1.0000e+00, 0.0000e+00, 4.0087e-01, 1.0000e+00, 7.2944e-01,\n",
      "         0.0000e+00, 1.0000e+00, 5.0468e-01, 0.0000e+00, 0.0000e+00, 1.5278e-02,\n",
      "         6.0744e-01, 1.2217e-01, 2.5315e-01, 1.2972e-01, 7.1621e-01, 7.2422e-01,\n",
      "         7.2178e-01, 1.0181e-02, 3.5626e-01, 7.1494e-01, 3.3358e-01, 6.1885e-01,\n",
      "         0.0000e+00, 2.0194e-01, 7.8426e-01, 7.4145e-01, 8.5923e-02, 7.7189e-03,\n",
      "         3.7822e-02, 9.1960e-01, 1.4562e-01, 8.1956e-01, 8.7483e-01, 8.3046e-01,\n",
      "         8.7217e-01, 6.9609e-01, 3.0708e-01, 1.2629e-02, 1.2683e-02, 1.6128e-02,\n",
      "         1.0737e-02, 2.6384e-01, 5.5139e-01, 6.2397e-02, 7.5782e-01, 7.6388e-01,\n",
      "         3.2580e-01, 2.1563e-02, 1.0964e-02, 2.2324e-01, 4.3221e-01, 1.0000e+00,\n",
      "         4.6476e-01, 3.7438e-01, 4.0119e-04, 4.7933e-02]], device='cuda:0')\n",
      "Predicted: \"[8620.789]\",\n",
      " Actual: \"[9093.262]\", Last: [4849.3267]\n",
      "Year: \"[2017.]\"\n",
      "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 4.0000e-01, 5.7999e-02, 4.3249e-02, 3.7148e-01,\n",
      "         9.7939e-02, 4.0034e-01, 4.3609e-01, 4.2668e-01, 7.9540e-04, 1.7527e-02,\n",
      "         4.6557e-03, 7.8284e-01, 2.7778e-01, 1.3286e-02, 4.0540e-02, 3.3239e-01,\n",
      "         0.0000e+00, 4.6660e-01, 0.0000e+00, 4.8928e-01, 1.0387e-01, 3.1702e-01,\n",
      "         3.2225e-01, 3.1702e-01, 3.8855e-01, 5.4347e-01, 1.9619e-01, 8.1492e-01,\n",
      "         7.1497e-01, 8.0821e-01, 0.0000e+00, 2.5417e-01, 3.9392e-01, 2.8734e-01,\n",
      "         4.3778e-01, 9.5107e-01, 2.3999e-01, 0.0000e+00, 1.0000e+00, 1.9044e-02,\n",
      "         7.8875e-01, 5.3321e-02, 4.4544e-01, 1.5174e-01, 7.6410e-01, 7.1584e-01,\n",
      "         7.0081e-01, 1.3806e-02, 5.4669e-01, 6.6299e-01, 3.8019e-01, 1.4144e-01,\n",
      "         3.1861e-01, 2.8707e-01, 6.8505e-01, 8.0500e-01, 4.2234e-01, 7.9389e-03,\n",
      "         1.0846e-01, 9.2507e-01, 3.0326e-01, 7.5230e-01, 6.3433e-01, 8.2556e-01,\n",
      "         9.4114e-01, 6.6638e-01, 2.5719e-01, 4.9967e-02, 4.3825e-02, 3.2756e-02,\n",
      "         1.1688e-02, 1.4598e-01, 8.9814e-02, 1.9750e-01, 3.8331e-01, 7.5925e-01,\n",
      "         5.6626e-01, 1.7318e-02, 1.3286e-02, 7.2923e-01, 4.6452e-01, 5.0000e-01,\n",
      "         3.6791e-01, 3.6731e-01, 3.7411e-02, 6.0390e-02]], device='cuda:0')\n",
      "Predicted: \"[9748.096]\",\n",
      " Actual: \"[9210.62]\", Last: [4849.3267]\n",
      "Year: \"[2017.]\"\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.4000, 0.1412, 0.0261, 0.4852, 0.4126, 0.5159, 0.6459,\n",
      "         0.5685, 0.0010, 0.0059, 0.0038, 0.4590, 0.6937, 0.1256, 0.2877, 0.2961,\n",
      "         0.1548, 0.1984, 0.0000, 0.3023, 0.0925, 0.3765, 0.1914, 0.2286, 0.2860,\n",
      "         0.1614, 0.2066, 0.6937, 0.4949, 0.3952, 0.0406, 0.7546, 0.7175, 0.3625,\n",
      "         0.1300, 0.2824, 0.2850, 0.4223, 0.0000, 0.1497, 0.5161, 0.1084, 0.2348,\n",
      "         0.0854, 0.4641, 0.6292, 0.7046, 0.1252, 0.4561, 0.4681, 0.2401, 0.5482,\n",
      "         0.3714, 0.3525, 0.7762, 0.7364, 0.2572, 0.0332, 0.0684, 0.8413, 0.3063,\n",
      "         0.6012, 0.5846, 0.6525, 0.7774, 0.7540, 0.3406, 0.1008, 0.0590, 0.0296,\n",
      "         0.0168, 1.0000, 0.9335, 0.7441, 0.5984, 0.6959, 0.8581, 0.1904, 0.1256,\n",
      "         0.8335, 0.1207, 0.5000, 0.4029, 0.3425, 0.0261, 0.1381]],\n",
      "       device='cuda:0')\n",
      "Predicted: \"[10828.8955]\",\n",
      " Actual: \"[8356.127]\", Last: [4849.3267]\n",
      "Year: \"[2017.]\"\n",
      "tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.4000, 0.3732, 0.2125, 0.1964, 0.0272, 0.0683, 0.0848,\n",
      "         0.0798, 0.0272, 0.0701, 0.1233, 0.8114, 0.0831, 0.3705, 0.3879, 0.0779,\n",
      "         0.1222, 0.0964, 0.0000, 0.1754, 0.3045, 0.5576, 0.1606, 0.3398, 0.1512,\n",
      "         0.4460, 0.3584, 0.2584, 0.4675, 0.1579, 0.8468, 0.4917, 0.2904, 0.2625,\n",
      "         0.3080, 0.2230, 0.0281, 0.1668, 0.0000, 0.4508, 0.9248, 0.1132, 0.4798,\n",
      "         0.1860, 0.5876, 0.5308, 0.6039, 0.3554, 0.9793, 0.6150, 0.7183, 0.5661,\n",
      "         0.4089, 0.4111, 0.7690, 0.7264, 0.2526, 0.2482, 0.2494, 0.6483, 0.4232,\n",
      "         0.4580, 0.5426, 0.6469, 0.6768, 0.8506, 0.2742, 0.0566, 0.0468, 0.0483,\n",
      "         0.0231, 0.1139, 0.0665, 0.7244, 0.0444, 0.8597, 0.8164, 0.4351, 0.3705,\n",
      "         0.3670, 0.2820, 0.5000, 0.2303, 0.3764, 0.2127, 0.3717]],\n",
      "       device='cuda:0')\n",
      "Predicted: \"[11078.875]\",\n",
      " Actual: \"[10973.842]\", Last: [4849.3267]\n",
      "Year: \"[2017.]\"\n",
      "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 4.0000e-01, 1.5288e-01, 8.0523e-02, 7.0305e-01,\n",
      "         9.1186e-01, 9.0775e-01, 1.0000e+00, 1.0000e+00, 1.5658e-04, 6.9182e-04,\n",
      "         3.1752e-03, 2.1984e-01, 1.0000e+00, 1.3755e-01, 2.4048e-01, 3.6737e-01,\n",
      "         0.0000e+00, 7.1795e-01, 6.9628e-01, 3.5527e-01, 8.6101e-02, 6.1318e-01,\n",
      "         1.7808e-01, 2.7530e-01, 6.2053e-01, 2.2525e-01, 2.7897e-01, 4.7189e-01,\n",
      "         8.5736e-01, 5.7264e-01, 4.6582e-01, 6.3207e-01, 7.2771e-01, 3.2953e-01,\n",
      "         7.2579e-01, 2.6279e-01, 5.3050e-01, 3.9300e-01, 0.0000e+00, 1.7506e-01,\n",
      "         5.6296e-01, 9.3165e-02, 2.4613e-01, 8.0349e-02, 5.5988e-01, 7.4483e-01,\n",
      "         7.6789e-01, 1.4573e-01, 3.8387e-01, 3.5256e-01, 1.4830e-01, 3.7967e-01,\n",
      "         2.5265e-01, 3.1277e-01, 6.6858e-01, 5.9494e-01, 3.7081e-01, 1.1892e-02,\n",
      "         1.0416e-01, 8.7524e-01, 2.6427e-01, 7.2143e-01, 6.8491e-01, 7.6757e-01,\n",
      "         8.6254e-01, 6.1164e-01, 7.0835e-01, 1.1331e-01, 4.9540e-02, 3.3464e-02,\n",
      "         1.3906e-02, 8.3070e-01, 7.3103e-01, 7.0804e-01, 6.6507e-01, 6.0554e-01,\n",
      "         6.6143e-01, 2.1479e-01, 1.3755e-01, 1.0000e+00, 2.1516e-01, 1.0000e+00,\n",
      "         6.1760e-01, 2.6434e-01, 7.6317e-02, 1.5159e-01]], device='cuda:0')\n",
      "Predicted: \"[9189.622]\",\n",
      " Actual: \"[8576.56]\", Last: [4849.3267]\n",
      "Year: \"[2017.]\"\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.4000, 0.0483, 0.0414, 0.4282, 0.1362, 0.3815, 0.4535,\n",
      "         0.4210, 0.0013, 0.0064, 0.0084, 0.6708, 0.4196, 0.0602, 0.1746, 0.1672,\n",
      "         0.2622, 0.5911, 0.0000, 0.4300, 0.1045, 0.3189, 0.2431, 0.3872, 0.2698,\n",
      "         0.4100, 0.7307, 0.4030, 0.7537, 0.7262, 0.0000, 0.4474, 0.5954, 0.2897,\n",
      "         0.2202, 0.9566, 0.1207, 0.7153, 0.0000, 0.0761, 0.8583, 0.0788, 0.3778,\n",
      "         0.1407, 0.7175, 0.6177, 0.6169, 0.0613, 0.5436, 0.5101, 0.4393, 0.4683,\n",
      "         0.6939, 0.4123, 0.8209, 0.7639, 0.5022, 0.0367, 0.1408, 0.8306, 0.2354,\n",
      "         0.6509, 0.5383, 0.7750, 0.8526, 0.8213, 0.2134, 0.0469, 0.0477, 0.0564,\n",
      "         0.0285, 0.3953, 0.2710, 0.8603, 0.1659, 0.7560, 0.9289, 0.0733, 0.0602,\n",
      "         0.7675, 0.5171, 0.5000, 0.4394, 0.2623, 0.0448, 0.0421]],\n",
      "       device='cuda:0')\n",
      "Predicted: \"[8623.827]\",\n",
      " Actual: \"[8103.347]\", Last: [4849.3267]\n",
      "Year: \"[2017.]\"\n",
      "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 4.0000e-01, 5.5583e-01, 4.8358e-01, 0.0000e+00,\n",
      "         5.6319e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.7029e-01, 2.2329e-01,\n",
      "         2.8481e-01, 0.0000e+00, 8.3024e-01, 3.8628e-01, 3.6571e-01, 3.0006e-01,\n",
      "         1.0000e+00, 6.4829e-02, 0.0000e+00, 3.3888e-01, 7.0327e-01, 2.8619e-01,\n",
      "         1.0000e+00, 2.2487e-01, 9.3318e-01, 6.8993e-01, 1.0000e+00, 7.6963e-01,\n",
      "         3.6851e-01, 5.3267e-01, 0.0000e+00, 1.7209e-01, 0.0000e+00, 3.8406e-01,\n",
      "         4.9401e-02, 3.2197e-01, 2.7082e-02, 1.6050e-01, 0.0000e+00, 4.8010e-01,\n",
      "         8.3855e-01, 6.3090e-01, 5.6549e-01, 1.0000e+00, 0.0000e+00, 2.6095e-01,\n",
      "         4.4940e-01, 2.5980e-01, 1.5317e-01, 0.0000e+00, 9.9304e-01, 4.1677e-01,\n",
      "         8.3632e-01, 6.0445e-01, 0.0000e+00, 0.0000e+00, 4.0811e-01, 1.0000e+00,\n",
      "         1.0000e+00, 0.0000e+00, 1.0000e+00, 4.2122e-01, 0.0000e+00, 7.8786e-02,\n",
      "         0.0000e+00, 0.0000e+00, 3.1256e-02, 7.7636e-01, 6.9941e-01, 5.9688e-01,\n",
      "         3.1750e-01, 9.9332e-03, 0.0000e+00, 3.4999e-01, 0.0000e+00, 3.1255e-01,\n",
      "         6.7628e-01, 5.4762e-01, 3.8628e-01, 5.2926e-01, 1.9403e-01, 0.0000e+00,\n",
      "         0.0000e+00, 1.0000e+00, 4.3511e-01, 5.5041e-01]], device='cuda:0')\n",
      "Predicted: \"[24103.158]\",\n",
      " Actual: \"[23392.494]\", Last: [4849.3267]\n",
      "Year: \"[2017.]\"\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.4000, 0.5612, 0.3206, 0.0254, 0.0011, 0.0000, 0.0000,\n",
      "         0.0000, 0.2276, 0.2602, 0.8584, 0.0000, 0.1732, 0.4259, 0.4215, 0.0000,\n",
      "         0.0538, 0.0827, 0.0000, 0.0766, 0.1928, 0.1961, 0.1661, 0.1261, 0.3574,\n",
      "         0.2382, 0.1976, 0.5921, 0.4308, 0.5300, 0.5474, 0.3800, 0.1642, 0.1758,\n",
      "         0.1806, 0.1961, 0.0247, 0.2933, 0.0000, 0.5083, 0.9520, 0.0319, 0.4311,\n",
      "         0.3921, 0.5909, 0.4076, 0.6390, 0.3960, 0.6508, 0.5407, 0.9964, 0.3939,\n",
      "         0.5362, 0.4310, 0.5066, 0.3466, 0.3713, 0.3158, 0.5404, 0.3894, 0.4929,\n",
      "         0.2111, 0.6052, 0.5640, 0.5925, 0.5918, 0.1861, 0.5659, 0.5513, 0.6465,\n",
      "         0.5279, 0.1125, 0.0715, 0.4319, 0.0438, 0.3091, 0.3989, 0.4842, 0.4259,\n",
      "         0.5422, 0.2059, 0.0000, 0.0172, 0.3407, 0.2959, 0.5828]],\n",
      "       device='cuda:0')\n",
      "Predicted: \"[9139.212]\",\n",
      " Actual: \"[9449.608]\", Last: [4849.3267]\n",
      "Year: \"[2017.]\"\n",
      "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 4.0000e-01, 3.7036e-01, 3.9294e-01, 5.4152e-02,\n",
      "         4.4621e-03, 7.1957e-05, 6.4264e-03, 2.2249e-03, 3.0368e-02, 4.7332e-03,\n",
      "         6.1998e-01, 2.9458e-01, 1.9804e-01, 4.0195e-01, 5.3043e-01, 0.0000e+00,\n",
      "         1.1342e-01, 6.1887e-02, 0.0000e+00, 7.6910e-02, 2.4860e-01, 6.8977e-02,\n",
      "         3.2428e-01, 5.9123e-02, 2.1709e-01, 4.4342e-02, 1.2581e-01, 1.5815e-01,\n",
      "         4.6771e-01, 4.1339e-01, 5.8243e-01, 4.2859e-01, 1.2608e-01, 1.4814e-01,\n",
      "         4.7626e-02, 2.0693e-01, 0.0000e+00, 1.5473e-01, 0.0000e+00, 4.3038e-01,\n",
      "         9.6048e-01, 3.1567e-02, 5.5781e-03, 5.4949e-02, 2.2595e-01, 1.8073e-01,\n",
      "         7.3759e-01, 4.2818e-01, 1.0991e-01, 9.5451e-02, 8.5175e-01, 9.9062e-01,\n",
      "         8.7305e-01, 8.8339e-01, 7.0381e-01, 7.9151e-01, 1.4110e-01, 2.6754e-01,\n",
      "         5.6001e-01, 3.9579e-01, 2.6923e-01, 3.7004e-01, 3.3487e-01, 3.4886e-01,\n",
      "         6.9711e-01, 8.1409e-01, 4.7716e-03, 5.9606e-01, 5.5832e-01, 6.1120e-01,\n",
      "         3.6805e-01, 1.4455e-01, 1.2593e-01, 2.7327e-01, 5.8287e-02, 5.2228e-01,\n",
      "         2.1687e-01, 3.9387e-01, 4.0195e-01, 5.6612e-01, 2.0728e-01, 0.0000e+00,\n",
      "         4.5989e-02, 4.4362e-02, 3.7408e-01, 3.8344e-01]], device='cuda:0')\n",
      "Predicted: \"[3480.1826]\",\n",
      " Actual: \"[3950.0183]\", Last: [4849.3267]\n",
      "Year: \"[2017.]\"\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.4000, 0.4479, 0.2779, 0.0623, 0.0019, 0.0000, 0.0000,\n",
      "         0.0000, 0.1559, 0.2569, 0.8470, 0.0573, 0.1276, 0.3517, 0.3546, 0.0409,\n",
      "         0.1923, 0.1019, 0.0000, 0.0811, 0.2171, 0.0390, 0.2278, 0.1615, 0.1992,\n",
      "         0.0835, 0.1756, 0.4558, 0.7015, 0.6443, 1.0000, 0.5156, 0.1432, 0.2808,\n",
      "         0.1615, 0.1169, 0.0295, 0.1749, 0.0000, 0.4025, 0.9788, 0.0586, 0.1840,\n",
      "         0.1163, 0.2775, 0.2307, 0.5188, 0.3597, 0.5758, 0.4276, 0.9043, 0.7849,\n",
      "         0.8370, 0.7423, 0.7722, 0.7146, 0.4293, 0.1604, 0.3279, 0.5424, 0.2243,\n",
      "         0.4111, 0.3554, 0.4538, 0.6142, 0.8823, 0.0583, 0.3099, 0.2114, 0.1940,\n",
      "         0.1435, 0.0609, 0.1514, 0.3958, 0.0223, 0.7587, 0.2969, 0.3687, 0.3517,\n",
      "         0.5773, 0.1919, 0.0000, 0.0585, 0.2160, 0.2522, 0.4468]],\n",
      "       device='cuda:0')\n",
      "Predicted: \"[6842.985]\",\n",
      " Actual: \"[7131.1187]\", Last: [4849.3267]\n",
      "Year: \"[2017.]\"\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.4000, 0.5184, 0.2538, 0.0655, 0.0041, 0.0000, 0.0000,\n",
      "         0.0000, 0.2840, 0.2166, 0.6089, 0.0753, 0.3667, 0.5233, 0.5743, 0.0566,\n",
      "         0.1775, 0.0241, 0.0000, 0.1143, 0.2917, 0.0270, 0.1988, 0.0848, 0.1842,\n",
      "         0.0809, 0.1567, 0.1777, 0.4567, 0.4733, 0.3490, 0.4110, 0.1821, 0.0912,\n",
      "         0.1490, 0.1619, 0.0409, 0.1211, 0.0000, 0.5781, 1.0000, 0.0396, 0.1563,\n",
      "         0.0655, 0.2361, 0.2198, 0.6279, 0.5523, 0.4422, 0.3744, 0.9016, 0.7637,\n",
      "         0.7443, 0.7613, 0.7620, 0.7963, 0.3884, 0.1698, 0.2871, 0.5612, 0.3099,\n",
      "         0.3236, 0.3126, 0.2682, 0.5451, 0.8486, 0.0596, 0.4497, 0.3615, 0.3419,\n",
      "         0.1748, 0.0783, 0.0792, 0.4049, 0.0464, 0.7111, 0.4308, 0.5202, 0.5233,\n",
      "         0.5770, 0.1764, 0.0000, 0.0599, 0.1964, 0.2310, 0.5082]],\n",
      "       device='cuda:0')\n",
      "Predicted: \"[6257.7847]\",\n",
      " Actual: \"[6982.2007]\", Last: [4849.3267]\n",
      "Year: \"[2017.]\"\n",
      "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 4.0000e-01, 1.8118e-01, 5.9536e-01, 1.0480e-02,\n",
      "         1.5144e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.7466e-01, 2.1512e-01,\n",
      "         5.0346e-01, 0.0000e+00, 5.3062e-01, 2.6713e-01, 2.9248e-01, 0.0000e+00,\n",
      "         8.2086e-02, 9.7202e-02, 0.0000e+00, 1.7570e-01, 9.1595e-01, 3.4945e-01,\n",
      "         3.4252e-01, 1.4263e-01, 5.2733e-01, 5.1347e-01, 4.0059e-01, 8.4104e-01,\n",
      "         0.0000e+00, 1.7454e-01, 2.2242e-01, 3.2019e-01, 1.9296e-02, 7.5857e-02,\n",
      "         1.3787e-01, 2.9953e-01, 3.7791e-02, 0.0000e+00, 0.0000e+00, 3.6166e-01,\n",
      "         8.4507e-01, 3.4153e-02, 3.0257e-01, 4.5220e-01, 1.4968e-01, 2.4898e-03,\n",
      "         0.0000e+00, 2.1260e-01, 1.0616e-01, 2.2933e-01, 9.7433e-01, 6.7922e-01,\n",
      "         8.2215e-01, 8.3625e-01, 2.4775e-01, 5.0539e-02, 1.3469e-01, 2.7720e-01,\n",
      "         9.5611e-01, 1.0538e-01, 3.3072e-01, 3.9870e-01, 1.3737e-01, 2.9330e-01,\n",
      "         3.2827e-01, 3.5896e-01, 3.0995e-02, 4.6149e-01, 2.8406e-01, 2.8118e-01,\n",
      "         1.6095e-01, 2.9875e-02, 1.0613e-01, 3.3972e-01, 1.8902e-02, 0.0000e+00,\n",
      "         5.3506e-01, 3.9360e-01, 2.6713e-01, 5.3246e-01, 1.7991e-01, 0.0000e+00,\n",
      "         8.7350e-03, 4.1321e-01, 5.8336e-01, 1.8325e-01]], device='cuda:0')\n",
      "Predicted: \"[11572.795]\",\n",
      " Actual: \"[11421.345]\", Last: [4849.3267]\n",
      "Year: \"[2017.]\"\n",
      "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 4.0000e-01, 8.8699e-01, 1.6146e-01, 8.7568e-02,\n",
      "         1.9216e-02, 9.8097e-04, 4.9574e-03, 2.5007e-03, 4.9608e-02, 3.6235e-02,\n",
      "         3.3831e-01, 3.1775e-01, 4.7357e-01, 1.0000e+00, 1.0000e+00, 3.0498e-02,\n",
      "         9.5659e-02, 1.6247e-02, 0.0000e+00, 5.5417e-03, 1.1437e-01, 1.4544e-02,\n",
      "         1.4414e-01, 4.3632e-02, 1.7105e-01, 3.1166e-02, 4.0659e-02, 1.1273e-01,\n",
      "         3.6699e-01, 9.3590e-02, 6.8981e-02, 3.4982e-01, 1.1915e-01, 1.2556e-01,\n",
      "         2.4101e-01, 1.3090e-01, 2.2020e-02, 1.3050e-01, 0.0000e+00, 1.0000e+00,\n",
      "         9.9898e-01, 2.1340e-02, 2.1709e-01, 5.4034e-02, 2.4089e-01, 2.8147e-01,\n",
      "         6.8863e-01, 1.0000e+00, 5.1055e-01, 4.4560e-01, 5.8564e-01, 6.9047e-01,\n",
      "         5.2432e-01, 5.5964e-01, 9.0840e-01, 8.3820e-01, 4.4546e-01, 1.1011e-01,\n",
      "         1.2890e-01, 5.2900e-01, 4.4375e-01, 9.9120e-02, 2.9155e-01, 8.2482e-02,\n",
      "         3.7868e-01, 8.4671e-01, 1.0569e-01, 5.7674e-01, 4.9293e-01, 4.7548e-01,\n",
      "         2.8062e-01, 1.0689e-01, 1.3144e-01, 3.9658e-01, 8.2991e-02, 6.5854e-01,\n",
      "         4.1902e-01, 8.9713e-01, 1.0000e+00, 5.8135e-01, 1.2526e-01, 0.0000e+00,\n",
      "         8.9571e-02, 2.0216e-01, 1.3901e-01, 8.7049e-01]], device='cuda:0')\n",
      "Predicted: \"[6494.49]\",\n",
      " Actual: \"[6531.239]\", Last: [4849.3267]\n",
      "Year: \"[2017.]\"\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.4000, 0.7359, 0.2102, 0.0492, 0.0248, 0.0073, 0.0084,\n",
      "         0.0079, 0.1282, 0.1017, 0.1140, 0.6062, 0.3244, 0.6263, 0.7493, 0.0955,\n",
      "         0.0374, 0.1046, 0.0000, 0.0850, 0.0448, 0.1366, 0.1331, 0.0325, 0.2697,\n",
      "         0.0195, 0.1596, 0.2235, 0.1733, 0.0814, 0.0082, 0.2282, 0.1355, 0.1744,\n",
      "         0.1887, 0.3416, 0.0345, 0.1022, 0.0000, 0.6107, 0.9915, 0.0284, 0.3725,\n",
      "         0.1099, 0.3729, 0.4234, 0.9007, 0.6130, 0.7640, 0.6063, 0.7410, 0.5517,\n",
      "         0.1816, 0.2918, 0.8600, 0.8282, 0.4063, 0.1257, 0.0883, 0.5598, 0.5282,\n",
      "         0.0303, 0.4623, 0.0627, 0.5490, 0.7128, 0.1265, 0.5222, 0.5209, 0.6663,\n",
      "         0.4824, 0.0889, 0.1809, 0.4538, 0.1415, 0.3512, 0.3369, 0.5558, 0.6263,\n",
      "         0.5165, 0.2334, 0.0000, 0.0413, 0.3650, 0.1901, 0.7371]],\n",
      "       device='cuda:0')\n",
      "Predicted: \"[9780.481]\",\n",
      " Actual: \"[9348.482]\", Last: [4849.3267]\n",
      "Year: \"[2017.]\"\n",
      "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 4.0000e-01, 6.7918e-01, 1.2173e-01, 5.7697e-02,\n",
      "         2.1277e-02, 6.3064e-04, 2.1001e-03, 1.4870e-03, 2.8227e-02, 2.1167e-01,\n",
      "         1.9435e-01, 4.7706e-01, 3.7509e-01, 6.3936e-01, 6.3901e-01, 2.3414e-02,\n",
      "         7.3440e-02, 0.0000e+00, 0.0000e+00, 2.4950e-03, 1.0975e-01, 2.2332e-02,\n",
      "         1.0782e-01, 3.1902e-02, 8.0349e-02, 3.8283e-02, 3.3914e-02, 7.6768e-02,\n",
      "         1.5443e-01, 3.0555e-02, 0.0000e+00, 2.2380e-01, 4.7780e-02, 1.1239e-01,\n",
      "         4.0090e-01, 6.6995e-02, 1.6905e-02, 1.0019e-01, 0.0000e+00, 6.1806e-01,\n",
      "         9.5704e-01, 5.7822e-02, 1.1648e-01, 7.6775e-02, 2.2456e-01, 2.0791e-01,\n",
      "         5.3645e-01, 5.9935e-01, 5.9443e-01, 4.0313e-01, 6.4725e-01, 7.3613e-01,\n",
      "         6.2751e-01, 5.8651e-01, 8.1919e-01, 6.1285e-01, 1.9804e-01, 1.3443e-01,\n",
      "         2.5021e-01, 3.8916e-01, 5.3370e-01, 6.0359e-02, 1.4568e-01, 0.0000e+00,\n",
      "         2.6698e-01, 8.1711e-01, 1.3610e-01, 5.4507e-01, 4.6415e-01, 4.8787e-01,\n",
      "         2.7237e-01, 4.0400e-01, 1.0619e-01, 4.5437e-01, 2.4211e-01, 4.8409e-01,\n",
      "         8.5992e-01, 5.7167e-01, 6.3936e-01, 4.8955e-01, 1.7574e-01, 0.0000e+00,\n",
      "         5.3780e-02, 1.6181e-01, 9.9363e-02, 6.7557e-01]], device='cuda:0')\n",
      "Predicted: \"[6035.764]\",\n",
      " Actual: \"[5890.145]\", Last: [4849.3267]\n",
      "Year: \"[2017.]\"\n",
      "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 4.0000e-01, 1.4977e-01, 9.2922e-01, 1.3261e-02,\n",
      "         1.3557e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.2168e-01, 0.0000e+00,\n",
      "         9.0599e-01, 0.0000e+00, 1.6109e-01, 3.0094e-01, 3.0561e-01, 0.0000e+00,\n",
      "         7.3805e-01, 1.7203e-02, 0.0000e+00, 2.5751e-01, 8.9708e-01, 4.4885e-02,\n",
      "         6.1593e-01, 1.3465e-01, 6.9302e-01, 1.3465e-01, 6.5330e-01, 7.2649e-01,\n",
      "         7.2039e-01, 1.7845e-01, 2.9352e-01, 3.4187e-01, 5.4010e-02, 0.0000e+00,\n",
      "         5.5784e-01, 2.6931e-01, 3.3979e-02, 4.0275e-01, 0.0000e+00, 3.8076e-01,\n",
      "         8.7413e-01, 6.6272e-02, 1.8211e-01, 4.1452e-01, 1.2552e-01, 0.0000e+00,\n",
      "         1.6701e-01, 2.4932e-01, 9.7004e-03, 2.2255e-02, 1.0000e+00, 5.8359e-01,\n",
      "         9.8770e-01, 9.2377e-01, 3.7146e-01, 3.1563e-01, 8.2838e-02, 4.2237e-01,\n",
      "         9.8730e-01, 8.2657e-02, 3.1473e-01, 4.5911e-01, 1.4551e-01, 5.3181e-01,\n",
      "         4.4875e-01, 4.1358e-01, 1.8370e-02, 4.6338e-01, 3.5504e-01, 3.2623e-01,\n",
      "         1.7505e-01, 3.6802e-02, 1.2103e-01, 2.3906e-01, 2.2348e-02, 3.5132e-02,\n",
      "         5.1347e-01, 3.9973e-01, 3.0094e-01, 5.3910e-01, 1.8176e-01, 0.0000e+00,\n",
      "         1.1669e-02, 3.2221e-01, 9.4244e-01, 1.5020e-01]], device='cuda:0')\n",
      "Predicted: \"[9575.248]\",\n",
      " Actual: \"[8810.887]\", Last: [4849.3267]\n",
      "Year: \"[2017.]\"\n",
      "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 4.0000e-01, 9.0807e-02, 5.8648e-01, 4.0048e-02,\n",
      "         6.4525e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.8635e-01, 2.1787e-02,\n",
      "         9.5643e-01, 0.0000e+00, 1.5580e-01, 3.0261e-01, 3.1067e-01, 4.6827e-02,\n",
      "         3.6720e-01, 5.1101e-02, 0.0000e+00, 2.2942e-01, 5.4144e-01, 4.4663e-02,\n",
      "         3.5184e-01, 1.4037e-01, 3.1162e-01, 5.7423e-02, 2.5785e-01, 6.8237e-01,\n",
      "         1.0000e+00, 6.5027e-01, 5.1032e-01, 5.1922e-01, 1.3128e-01, 5.5910e-02,\n",
      "         1.8503e-01, 2.6798e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.3469e-01,\n",
      "         9.2121e-01, 6.3508e-02, 1.9649e-01, 1.3245e-01, 2.0877e-01, 5.3695e-02,\n",
      "         4.0019e-01, 2.9857e-01, 2.3431e-01, 2.3678e-01, 9.6425e-01, 7.4763e-01,\n",
      "         9.2365e-01, 9.5705e-01, 8.9117e-01, 7.0973e-01, 0.0000e+00, 2.2636e-01,\n",
      "         7.0416e-01, 2.4299e-01, 5.8944e-02, 4.6831e-01, 3.0804e-01, 7.8143e-01,\n",
      "         6.5872e-01, 8.8931e-01, 8.9217e-03, 3.8433e-01, 2.1784e-01, 2.1794e-01,\n",
      "         9.7111e-02, 2.1648e-02, 1.0740e-02, 3.5719e-01, 1.1301e-02, 7.6928e-01,\n",
      "         5.2753e-01, 3.2656e-01, 3.0261e-01, 5.4090e-01, 1.5846e-01, 0.0000e+00,\n",
      "         3.1817e-02, 9.4749e-02, 5.5591e-01, 8.0363e-02]], device='cuda:0')\n",
      "Predicted: \"[4520.101]\",\n",
      " Actual: \"[4592.678]\", Last: [4849.3267]\n",
      "Year: \"[2017.]\"\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.6000, 0.0616, 0.0220, 0.3287, 0.0984, 0.3200, 0.4438,\n",
      "         0.3733, 0.0016, 0.0111, 0.0078, 0.8440, 0.1988, 0.0226, 0.0000, 0.8333,\n",
      "         0.0000, 0.7913, 0.0000, 0.2547, 0.1736, 0.2649, 0.4040, 0.1892, 1.0000,\n",
      "         0.6813, 0.5955, 0.1691, 0.4578, 0.6921, 0.5712, 0.6372, 0.7783, 0.2215,\n",
      "         0.3659, 0.0000, 0.6017, 0.0000, 0.0000, 0.0337, 0.7644, 0.0488, 0.2620,\n",
      "         0.1215, 1.0000, 1.0000, 0.9312, 0.0226, 0.6607, 0.5862, 0.3563, 0.2532,\n",
      "         0.0422, 0.0416, 0.6343, 0.6771, 0.1420, 0.0157, 0.0000, 1.0000, 0.2959,\n",
      "         0.6546, 1.0000, 1.0000, 1.0000, 0.5886, 0.2420, 0.0628, 0.0150, 0.0070,\n",
      "         0.0000, 0.1347, 0.1801, 0.0992, 0.7179, 0.7545, 0.2819, 0.0344, 0.0226,\n",
      "         0.3506, 0.4057, 0.5000, 0.3117, 0.3467, 0.0111, 0.0557]],\n",
      "       device='cuda:0')\n",
      "Predicted: \"[9782.325]\",\n",
      " Actual: \"[9707.427]\", Last: [4849.3267]\n",
      "Year: \"[2018.]\"\n",
      "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 6.0000e-01, 6.3278e-02, 4.3062e-02, 3.7148e-01,\n",
      "         9.7939e-02, 4.0034e-01, 4.3609e-01, 4.2668e-01, 7.9540e-04, 1.7527e-02,\n",
      "         4.6557e-03, 7.8284e-01, 2.7778e-01, 1.3286e-02, 4.0540e-02, 3.3239e-01,\n",
      "         0.0000e+00, 4.6660e-01, 0.0000e+00, 4.8928e-01, 1.0387e-01, 3.1702e-01,\n",
      "         3.2225e-01, 3.1702e-01, 3.8855e-01, 5.4347e-01, 1.9619e-01, 8.1492e-01,\n",
      "         7.1497e-01, 8.0821e-01, 0.0000e+00, 2.5417e-01, 3.9392e-01, 2.8734e-01,\n",
      "         4.3778e-01, 9.5107e-01, 2.3999e-01, 0.0000e+00, 1.0000e+00, 1.9044e-02,\n",
      "         7.8875e-01, 5.3321e-02, 4.4544e-01, 1.5174e-01, 7.6410e-01, 7.1584e-01,\n",
      "         7.0081e-01, 1.3806e-02, 5.4669e-01, 6.6299e-01, 3.8019e-01, 1.4144e-01,\n",
      "         3.1861e-01, 2.8707e-01, 6.8505e-01, 8.0500e-01, 4.2234e-01, 7.9389e-03,\n",
      "         1.0846e-01, 9.2507e-01, 3.0326e-01, 7.5230e-01, 6.3433e-01, 8.2556e-01,\n",
      "         9.4114e-01, 6.6638e-01, 2.5719e-01, 4.9967e-02, 4.3825e-02, 3.2756e-02,\n",
      "         1.1688e-02, 1.4598e-01, 8.9814e-02, 1.9750e-01, 3.8331e-01, 7.5925e-01,\n",
      "         5.6626e-01, 1.7318e-02, 1.3286e-02, 7.2923e-01, 4.6452e-01, 5.0000e-01,\n",
      "         3.6791e-01, 2.6837e-01, 4.6638e-02, 5.5239e-02]], device='cuda:0')\n",
      "Predicted: \"[9576.547]\",\n",
      " Actual: \"[8412.205]\", Last: [4849.3267]\n",
      "Year: \"[2018.]\"\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.6000, 0.1372, 0.0312, 0.4852, 0.4126, 0.5159, 0.6459,\n",
      "         0.5685, 0.0010, 0.0059, 0.0038, 0.4590, 0.6937, 0.1256, 0.2877, 0.2961,\n",
      "         0.1548, 0.1984, 0.0000, 0.3023, 0.0925, 0.3765, 0.1914, 0.2286, 0.2860,\n",
      "         0.1614, 0.2066, 0.6937, 0.4949, 0.3952, 0.0406, 0.7546, 0.7175, 0.3625,\n",
      "         0.1300, 0.2824, 0.2850, 0.4223, 0.0000, 0.1497, 0.5161, 0.1084, 0.2348,\n",
      "         0.0854, 0.4641, 0.6292, 0.7046, 0.1252, 0.4561, 0.4681, 0.2401, 0.5482,\n",
      "         0.3714, 0.3525, 0.7762, 0.7364, 0.2572, 0.0332, 0.0684, 0.8413, 0.3063,\n",
      "         0.6012, 0.5846, 0.6525, 0.7774, 0.7540, 0.3406, 0.1008, 0.0590, 0.0296,\n",
      "         0.0168, 1.0000, 0.9335, 0.7441, 0.5984, 0.6959, 0.8581, 0.1904, 0.1256,\n",
      "         0.8335, 0.1207, 0.5000, 0.4029, 0.2310, 0.0282, 0.1387]],\n",
      "       device='cuda:0')\n",
      "Predicted: \"[10375.573]\",\n",
      " Actual: \"[9052.065]\", Last: [4849.3267]\n",
      "Year: \"[2018.]\"\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.6000, 0.0416, 0.1329, 0.5530, 0.0415, 0.2058, 0.2256,\n",
      "         0.2127, 0.0117, 0.0455, 0.0489, 0.7731, 0.2278, 0.1133, 0.1729, 0.1069,\n",
      "         0.3354, 0.2164, 0.0000, 0.1681, 0.1003, 0.7140, 0.2592, 0.3934, 0.3283,\n",
      "         0.5246, 0.4640, 0.2410, 0.5054, 0.2080, 0.0000, 0.4498, 0.2503, 0.2734,\n",
      "         0.5634, 0.3060, 0.0000, 0.4576, 0.0000, 0.1275, 0.9429, 0.1838, 0.7118,\n",
      "         0.1245, 0.4629, 0.4068, 0.5072, 0.1109, 0.7895, 0.5827, 0.4622, 0.0232,\n",
      "         0.7736, 0.3880, 0.9375, 0.7833, 1.0000, 0.1043, 0.1189, 0.7302, 0.3513,\n",
      "         0.4847, 0.4231, 0.3185, 0.6229, 0.9197, 0.4064, 0.0734, 0.0638, 0.0517,\n",
      "         0.0220, 0.2063, 0.1336, 0.9296, 0.0843, 0.6366, 0.9107, 0.1160, 0.1133,\n",
      "         0.8381, 0.6141, 0.5000, 0.5714, 0.2185, 0.1292, 0.0370]],\n",
      "       device='cuda:0')\n",
      "Predicted: \"[7567.6396]\",\n",
      " Actual: \"[7720.0835]\", Last: [4849.3267]\n",
      "Year: \"[2018.]\"\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.6000, 0.0091, 0.2933, 0.2357, 0.0699, 0.1566, 0.1607,\n",
      "         0.1623, 0.0011, 0.0017, 0.0182, 0.7629, 0.2934, 0.0488, 0.0892, 0.3800,\n",
      "         0.0000, 0.3977, 0.0000, 0.2638, 0.3563, 0.0000, 0.0921, 0.0777, 0.2672,\n",
      "         0.0000, 0.1206, 0.1812, 0.3568, 0.2559, 0.0000, 0.4359, 0.2360, 0.1157,\n",
      "         0.2503, 0.0000, 0.1372, 0.0000, 0.0000, 0.0457, 0.2522, 0.0445, 0.0000,\n",
      "         0.0000, 0.0385, 0.2520, 0.5205, 0.0449, 0.1109, 0.2990, 0.3281, 0.9672,\n",
      "         0.7108, 0.8480, 0.9536, 0.6988, 0.1268, 0.1193, 0.3935, 0.4828, 0.0370,\n",
      "         0.6239, 0.1647, 0.2293, 0.6184, 1.0000, 0.1142, 0.1171, 0.0402, 0.0359,\n",
      "         0.0062, 0.4124, 0.6962, 0.2084, 0.4587, 0.7877, 0.5158, 0.0841, 0.0488,\n",
      "         0.4031, 0.0441, 0.5000, 0.2177, 0.0271, 0.2770, 0.0044]],\n",
      "       device='cuda:0')\n",
      "Predicted: \"[3421.233]\",\n",
      " Actual: \"[3618.3208]\", Last: [4849.3267]\n",
      "Year: \"[2018.]\"\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.6000, 0.0312, 0.0705, 0.3176, 0.1529, 0.4460, 0.5155,\n",
      "         0.4741, 0.0010, 0.0067, 0.0081, 0.8717, 0.1651, 0.0744, 0.0758, 0.4359,\n",
      "         0.0000, 0.3001, 0.0000, 0.2435, 0.7719, 0.4158, 0.1761, 0.1782, 0.4716,\n",
      "         0.1188, 0.2208, 0.4330, 0.4642, 0.5912, 0.0000, 1.0000, 0.6453, 0.7626,\n",
      "         0.1914, 0.4158, 0.4196, 0.0000, 0.4372, 0.0901, 0.3510, 0.0257, 0.0747,\n",
      "         0.0226, 0.3801, 0.6385, 0.6986, 0.0771, 0.2511, 0.4764, 0.0605, 0.7462,\n",
      "         0.3116, 0.4918, 0.7643, 0.7335, 0.2319, 0.0205, 0.1263, 0.8442, 0.0677,\n",
      "         0.8223, 0.5191, 0.6069, 0.7446, 0.7963, 0.1761, 0.1104, 0.0510, 0.0374,\n",
      "         0.0193, 0.3585, 0.3074, 0.1878, 0.4801, 0.8279, 0.5612, 0.1341, 0.0744,\n",
      "         0.6850, 0.0000, 0.5000, 0.2720, 0.0803, 0.0649, 0.0303]],\n",
      "       device='cuda:0')\n",
      "Predicted: \"[4808.0464]\",\n",
      " Actual: \"[4881.097]\", Last: [4849.3267]\n",
      "Year: \"[2018.]\"\n",
      "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 6.0000e-01, 5.8164e-01, 4.8769e-01, 0.0000e+00,\n",
      "         5.6319e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.7029e-01, 2.2329e-01,\n",
      "         2.8481e-01, 0.0000e+00, 8.3024e-01, 3.8628e-01, 3.6571e-01, 3.0006e-01,\n",
      "         1.0000e+00, 6.4829e-02, 0.0000e+00, 3.3888e-01, 7.0327e-01, 2.8619e-01,\n",
      "         1.0000e+00, 2.2487e-01, 9.3318e-01, 6.8993e-01, 1.0000e+00, 7.6963e-01,\n",
      "         3.6851e-01, 5.3267e-01, 0.0000e+00, 1.7209e-01, 0.0000e+00, 3.8406e-01,\n",
      "         4.9401e-02, 3.2197e-01, 2.7082e-02, 1.6050e-01, 0.0000e+00, 4.8010e-01,\n",
      "         8.3855e-01, 6.3090e-01, 5.6549e-01, 1.0000e+00, 0.0000e+00, 2.6095e-01,\n",
      "         4.4940e-01, 2.5980e-01, 1.5317e-01, 0.0000e+00, 9.9304e-01, 4.1677e-01,\n",
      "         8.3632e-01, 6.0445e-01, 0.0000e+00, 0.0000e+00, 4.0811e-01, 1.0000e+00,\n",
      "         1.0000e+00, 0.0000e+00, 1.0000e+00, 4.2122e-01, 0.0000e+00, 7.8786e-02,\n",
      "         0.0000e+00, 0.0000e+00, 3.1256e-02, 7.7636e-01, 6.9941e-01, 5.9688e-01,\n",
      "         3.1750e-01, 9.9332e-03, 0.0000e+00, 3.4999e-01, 0.0000e+00, 3.1255e-01,\n",
      "         6.7628e-01, 5.4762e-01, 3.8628e-01, 5.2926e-01, 1.9403e-01, 0.0000e+00,\n",
      "         0.0000e+00, 8.8888e-01, 5.2046e-01, 5.5453e-01]], device='cuda:0')\n",
      "Predicted: \"[22553.947]\",\n",
      " Actual: \"[22141.488]\", Last: [4849.3267]\n",
      "Year: \"[2018.]\"\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.6000, 0.9749, 0.1913, 0.0382, 0.0046, 0.0000, 0.0000,\n",
      "         0.0000, 0.1294, 0.8232, 0.5841, 0.0769, 0.2005, 0.6841, 0.7051, 0.0220,\n",
      "         0.1377, 0.0788, 0.0000, 0.1174, 0.0480, 0.0209, 0.1117, 0.0628, 0.2946,\n",
      "         0.0538, 0.0669, 0.4017, 0.3544, 0.0872, 0.0451, 0.3442, 0.1807, 0.1513,\n",
      "         0.0289, 0.1885, 0.0317, 0.0000, 0.0000, 0.7114, 0.9868, 0.0081, 0.2406,\n",
      "         0.2023, 0.6155, 0.4989, 0.9743, 0.6733, 0.9923, 0.6860, 0.8386, 0.5202,\n",
      "         0.0891, 0.1378, 0.6284, 0.6434, 0.3553, 0.1740, 0.1571, 0.5032, 0.8163,\n",
      "         0.0000, 0.5536, 0.1642, 0.5293, 0.5689, 0.0703, 0.8154, 0.8397, 0.9356,\n",
      "         0.8186, 0.0822, 0.0501, 0.4327, 0.1429, 0.3112, 0.6064, 0.6452, 0.6841,\n",
      "         0.5081, 0.2103, 0.0000, 0.0320, 0.2293, 0.1985, 0.9367]],\n",
      "       device='cuda:0')\n",
      "Predicted: \"[8867.54]\",\n",
      " Actual: \"[9204.404]\", Last: [4849.3267]\n",
      "Year: \"[2018.]\"\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.6000, 0.5817, 0.2730, 0.1572, 0.0430, 0.0020, 0.0368,\n",
      "         0.0281, 0.0130, 0.0163, 0.2023, 0.5770, 0.3128, 0.5885, 0.6754, 0.0760,\n",
      "         0.1192, 0.0382, 0.0000, 0.1148, 0.2374, 0.0000, 0.2087, 0.0518, 0.2716,\n",
      "         0.0518, 0.0726, 0.4452, 0.5289, 0.4803, 0.1805, 0.4067, 0.1907, 0.1003,\n",
      "         0.1668, 0.1449, 0.0549, 0.3251, 0.0000, 0.6787, 0.3502, 0.0635, 0.0893,\n",
      "         0.0405, 0.2184, 0.4202, 0.5897, 0.5985, 0.4885, 0.4868, 0.4254, 0.7316,\n",
      "         0.6776, 0.6322, 0.7701, 0.6399, 0.2871, 0.0646, 0.1896, 0.6561, 0.1514,\n",
      "         0.3936, 0.3907, 0.6443, 0.6596, 0.8202, 0.1394, 0.2414, 0.0738, 0.0602,\n",
      "         0.0213, 0.3085, 0.4257, 0.4441, 0.1284, 0.7746, 0.1184, 0.9317, 0.5885,\n",
      "         0.5392, 0.0556, 0.0000, 0.1286, 0.1562, 0.2613, 0.5703]],\n",
      "       device='cuda:0')\n",
      "Predicted: \"[5961.402]\",\n",
      " Actual: \"[6482.193]\", Last: [4849.3267]\n",
      "Year: \"[2018.]\"\n",
      "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 6.0000e-01, 9.5544e-02, 5.6412e-01, 4.0048e-02,\n",
      "         6.4525e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.8635e-01, 2.1787e-02,\n",
      "         9.5643e-01, 0.0000e+00, 1.5580e-01, 3.0261e-01, 3.1067e-01, 4.6827e-02,\n",
      "         3.6720e-01, 5.1101e-02, 0.0000e+00, 2.2942e-01, 5.4144e-01, 4.4663e-02,\n",
      "         3.5184e-01, 1.4037e-01, 3.1162e-01, 5.7423e-02, 2.5785e-01, 6.8237e-01,\n",
      "         1.0000e+00, 6.5027e-01, 5.1032e-01, 5.1922e-01, 1.3128e-01, 5.5910e-02,\n",
      "         1.8503e-01, 2.6798e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.3469e-01,\n",
      "         9.2121e-01, 6.3508e-02, 1.9649e-01, 1.3245e-01, 2.0877e-01, 5.3695e-02,\n",
      "         4.0019e-01, 2.9857e-01, 2.3431e-01, 2.3678e-01, 9.6425e-01, 7.4763e-01,\n",
      "         9.2365e-01, 9.5705e-01, 8.9117e-01, 7.0973e-01, 0.0000e+00, 2.2636e-01,\n",
      "         7.0416e-01, 2.4299e-01, 5.8944e-02, 4.6831e-01, 3.0804e-01, 7.8143e-01,\n",
      "         6.5872e-01, 8.8931e-01, 8.9217e-03, 3.8433e-01, 2.1784e-01, 2.1794e-01,\n",
      "         9.7111e-02, 2.1648e-02, 1.0740e-02, 3.5719e-01, 1.1301e-02, 7.6928e-01,\n",
      "         5.2753e-01, 3.2656e-01, 3.0261e-01, 5.4090e-01, 1.5846e-01, 0.0000e+00,\n",
      "         3.1817e-02, 6.6325e-02, 6.3118e-01, 8.8144e-02]], device='cuda:0')\n",
      "Predicted: \"[4692.634]\",\n",
      " Actual: \"[4478.939]\", Last: [4849.3267]\n",
      "Year: \"[2018.]\"\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.8000, 0.0606, 0.0284, 0.3287, 0.0984, 0.3200, 0.4438,\n",
      "         0.3733, 0.0016, 0.0111, 0.0078, 0.8440, 0.1988, 0.0226, 0.0000, 0.8333,\n",
      "         0.0000, 0.7913, 0.0000, 0.2547, 0.1736, 0.2649, 0.4040, 0.1892, 1.0000,\n",
      "         0.6813, 0.5955, 0.1691, 0.4578, 0.6921, 0.5712, 0.6372, 0.7783, 0.2215,\n",
      "         0.3659, 0.0000, 0.6017, 0.0000, 0.0000, 0.0337, 0.7644, 0.0488, 0.2620,\n",
      "         0.1215, 1.0000, 1.0000, 0.9312, 0.0226, 0.6607, 0.5862, 0.3563, 0.2532,\n",
      "         0.0422, 0.0416, 0.6343, 0.6771, 0.1420, 0.0157, 0.0000, 1.0000, 0.2959,\n",
      "         0.6546, 1.0000, 1.0000, 1.0000, 0.5886, 0.2420, 0.0628, 0.0150, 0.0070,\n",
      "         0.0000, 0.1347, 0.1801, 0.0992, 0.7179, 0.7545, 0.2819, 0.0344, 0.0226,\n",
      "         0.3506, 0.4057, 0.5000, 0.3117, 0.2901, 0.0238, 0.0589]],\n",
      "       device='cuda:0')\n",
      "Predicted: \"[9355.198]\",\n",
      " Actual: \"[10570.08]\", Last: [4849.3267]\n",
      "Year: \"[2019.]\"\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.8000, 0.1419, 0.1039, 0.1538, 0.1194, 0.1578, 0.1878,\n",
      "         0.1762, 0.0025, 0.0053, 0.0170, 0.7652, 0.2903, 0.0979, 0.1446, 0.2388,\n",
      "         0.0000, 0.3305, 0.0000, 0.1687, 0.1493, 0.2278, 0.1737, 0.1139, 0.2611,\n",
      "         0.4393, 0.1216, 0.2038, 0.2575, 0.2240, 0.0000, 0.5479, 0.3456, 0.3185,\n",
      "         0.4718, 0.0000, 0.1724, 0.0000, 0.7185, 0.0991, 0.8951, 0.0875, 0.2917,\n",
      "         0.0674, 0.4191, 0.3937, 0.6619, 0.0941, 0.6491, 0.6274, 0.2483, 0.7071,\n",
      "         0.4638, 0.4933, 0.9205, 0.8533, 0.3225, 0.0536, 0.0551, 0.7337, 0.2993,\n",
      "         0.3828, 0.3606, 0.2362, 0.5601, 0.8515, 0.2536, 0.0967, 0.0655, 0.0726,\n",
      "         0.0275, 0.3662, 0.2499, 0.2383, 0.4196, 0.6756, 0.0941, 0.0939, 0.0979,\n",
      "         0.5358, 0.3439, 0.5000, 0.1434, 0.2890, 0.1164, 0.1393]],\n",
      "       device='cuda:0')\n",
      "Predicted: \"[10514.855]\",\n",
      " Actual: \"[10391.822]\", Last: [4849.3267]\n",
      "Year: \"[2019.]\"\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.8000, 0.0407, 0.1268, 0.5530, 0.0415, 0.2058, 0.2256,\n",
      "         0.2127, 0.0117, 0.0455, 0.0489, 0.7731, 0.2278, 0.1133, 0.1729, 0.1069,\n",
      "         0.3354, 0.2164, 0.0000, 0.1681, 0.1003, 0.7140, 0.2592, 0.3934, 0.3283,\n",
      "         0.5246, 0.4640, 0.2410, 0.5054, 0.2080, 0.0000, 0.4498, 0.2503, 0.2734,\n",
      "         0.5634, 0.3060, 0.0000, 0.4576, 0.0000, 0.1275, 0.9429, 0.1838, 0.7118,\n",
      "         0.1245, 0.4629, 0.4068, 0.5072, 0.1109, 0.7895, 0.5827, 0.4622, 0.0232,\n",
      "         0.7736, 0.3880, 0.9375, 0.7833, 1.0000, 0.1043, 0.1189, 0.7302, 0.3513,\n",
      "         0.4847, 0.4231, 0.3185, 0.6229, 0.9197, 0.4064, 0.0734, 0.0638, 0.0517,\n",
      "         0.0220, 0.2063, 0.1336, 0.9296, 0.0843, 0.6366, 0.9107, 0.1160, 0.1133,\n",
      "         0.8381, 0.6141, 0.5000, 0.5714, 0.2032, 0.1431, 0.0388]],\n",
      "       device='cuda:0')\n",
      "Predicted: \"[7838.7896]\",\n",
      " Actual: \"[8898.869]\", Last: [4849.3267]\n",
      "Year: \"[2019.]\"\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.8000, 0.0467, 0.0346, 0.7652, 0.2431, 1.0000, 0.9234,\n",
      "         0.9787, 0.0016, 0.0018, 0.0016, 0.9983, 0.0134, 0.0447, 0.0310, 1.0000,\n",
      "         0.0000, 0.8560, 0.0000, 0.4201, 1.0000, 0.5723, 0.0970, 0.4088, 0.7317,\n",
      "         0.6540, 0.9276, 0.7068, 0.4894, 0.5848, 0.0000, 0.8412, 0.5855, 0.6101,\n",
      "         0.7903, 0.5723, 0.4332, 0.8558, 0.0000, 0.0506, 0.8213, 0.0821, 0.5016,\n",
      "         0.1741, 0.8321, 0.6656, 0.6811, 0.0405, 0.4544, 0.4597, 0.3434, 0.4380,\n",
      "         0.2136, 0.2409, 0.8170, 0.6999, 0.3584, 0.0000, 0.0250, 0.8544, 0.2920,\n",
      "         0.6380, 0.5640, 0.5472, 0.6957, 0.7328, 1.0000, 0.1163, 0.1444, 0.1752,\n",
      "         0.1650, 0.2248, 0.7350, 1.0000, 0.4415, 0.5318, 0.9288, 0.0503, 0.0447,\n",
      "         0.3122, 0.9174, 1.0000, 0.7523, 0.3857, 0.0325, 0.0410]],\n",
      "       device='cuda:0')\n",
      "Predicted: \"[11964.365]\",\n",
      " Actual: \"[12262.345]\", Last: [4849.3267]\n",
      "Year: \"[2019.]\"\n",
      "tensor([[0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.8000, 0.1114, 0.1141, 0.2665, 0.0283, 0.4080, 0.3296,\n",
      "         0.3704, 0.0101, 0.0048, 0.0828, 0.8998, 0.0437, 0.0891, 0.1058, 0.1280,\n",
      "         0.0000, 0.1692, 0.0000, 0.3555, 0.3599, 0.2441, 0.0931, 0.1046, 0.0615,\n",
      "         0.0000, 0.1353, 0.3463, 0.4741, 0.8388, 0.0000, 0.2936, 0.2545, 0.0408,\n",
      "         0.3371, 0.3662, 0.2772, 0.0000, 0.7700, 0.1127, 0.0000, 0.0224, 0.0498,\n",
      "         0.0345, 0.2464, 0.6752, 0.6586, 0.0878, 0.3910, 0.6282, 0.3681, 0.7420,\n",
      "         0.2751, 0.3943, 0.6025, 0.5059, 0.2621, 0.0102, 0.1333, 0.7876, 0.1021,\n",
      "         0.5588, 0.5974, 0.8533, 0.8173, 0.7239, 0.1651, 0.1927, 0.0776, 0.0574,\n",
      "         0.0349, 0.5991, 0.4406, 0.7257, 0.2666, 0.6911, 0.4732, 0.2448, 0.0891,\n",
      "         0.5966, 0.0122, 0.5000, 0.1904, 0.1335, 0.1187, 0.1092]],\n",
      "       device='cuda:0')\n",
      "Predicted: \"[6465.024]\",\n",
      " Actual: \"[6672.0083]\", Last: [4849.3267]\n",
      "Year: \"[2019.]\"\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.8000, 0.3129, 0.0550, 0.2880, 0.0312, 0.2626, 0.2148,\n",
      "         0.2388, 0.0208, 0.0901, 0.0739, 0.7189, 0.2504, 0.2040, 0.8584, 0.0662,\n",
      "         0.1038, 0.1756, 0.0000, 0.1185, 0.2069, 0.4421, 0.2247, 0.2436, 0.4830,\n",
      "         0.2706, 0.2875, 0.5343, 0.5772, 0.7735, 0.4039, 0.6835, 0.4078, 0.2857,\n",
      "         0.0000, 0.3789, 0.0478, 0.5666, 0.0000, 0.2515, 0.8926, 0.0838, 0.5301,\n",
      "         0.2115, 0.6425, 0.5893, 0.7075, 0.2046, 0.9791, 0.9039, 0.6685, 0.0000,\n",
      "         0.5590, 0.1740, 0.7731, 0.7089, 0.4523, 0.0901, 0.0673, 0.8177, 0.8030,\n",
      "         0.3431, 0.6891, 0.5579, 0.6938, 0.7992, 0.3619, 0.1705, 0.1233, 0.1047,\n",
      "         0.0585, 0.3055, 0.2057, 0.6979, 0.1271, 0.5672, 0.8101, 0.2473, 0.2040,\n",
      "         0.7527, 0.0759, 0.5000, 0.3108, 0.7107, 0.0540, 0.3010]],\n",
      "       device='cuda:0')\n",
      "Predicted: \"[18189.014]\",\n",
      " Actual: \"[18397.027]\", Last: [4849.3267]\n",
      "Year: \"[2019.]\"\n",
      "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 8.0000e-01, 3.6062e-01, 3.6433e-01, 4.0594e-02,\n",
      "         1.8456e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.5416e-01, 1.4067e-01,\n",
      "         8.9548e-01, 1.2727e-08, 1.6978e-01, 5.0863e-01, 5.0215e-01, 5.8106e-02,\n",
      "         2.7339e-01, 4.1027e-03, 0.0000e+00, 1.8347e-01, 3.8132e-01, 2.2168e-01,\n",
      "         3.1688e-01, 1.5834e-01, 2.1633e-01, 1.1876e-01, 1.9757e-01, 4.3282e-01,\n",
      "         4.8274e-01, 6.2065e-01, 5.4562e-01, 4.1101e-01, 1.4079e-01, 2.0183e-01,\n",
      "         1.5306e-01, 4.1565e-01, 2.0977e-02, 2.4864e-01, 0.0000e+00, 5.8406e-01,\n",
      "         9.6025e-01, 7.6904e-02, 1.5388e-01, 2.0661e-01, 3.2366e-01, 3.0668e-01,\n",
      "         6.7389e-01, 4.9988e-01, 3.5562e-01, 3.2180e-01, 1.0000e+00, 8.2154e-01,\n",
      "         7.3610e-01, 7.5802e-01, 6.9136e-01, 6.0548e-01, 2.9340e-01, 3.7556e-01,\n",
      "         6.2761e-01, 3.3101e-01, 3.4885e-01, 4.6212e-01, 3.3237e-01, 6.6227e-01,\n",
      "         6.0138e-01, 7.5403e-01, 2.1315e-02, 5.7579e-01, 5.3564e-01, 5.1418e-01,\n",
      "         3.7086e-01, 3.9913e-02, 4.3573e-02, 2.6449e-01, 2.5457e-02, 5.2236e-01,\n",
      "         1.1643e-01, 5.4291e-01, 5.0863e-01, 5.5890e-01, 1.8880e-01, 0.0000e+00,\n",
      "         3.4270e-02, 7.0888e-02, 4.1472e-01, 3.6448e-01]], device='cuda:0')\n",
      "Predicted: \"[4490.]\",\n",
      " Actual: \"[5243.8843]\", Last: [4849.3267]\n",
      "Year: \"[2019.]\"\n",
      "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 8.0000e-01, 3.8587e-01, 3.4649e-01, 5.4152e-02,\n",
      "         4.4621e-03, 7.1957e-05, 6.4264e-03, 2.2249e-03, 3.0368e-02, 4.7332e-03,\n",
      "         6.1998e-01, 2.9458e-01, 1.9804e-01, 4.0195e-01, 5.3043e-01, 0.0000e+00,\n",
      "         1.1342e-01, 6.1887e-02, 0.0000e+00, 7.6910e-02, 2.4860e-01, 6.8977e-02,\n",
      "         3.2428e-01, 5.9123e-02, 2.1709e-01, 4.4342e-02, 1.2581e-01, 1.5815e-01,\n",
      "         4.6771e-01, 4.1339e-01, 5.8243e-01, 4.2859e-01, 1.2608e-01, 1.4814e-01,\n",
      "         4.7626e-02, 2.0693e-01, 0.0000e+00, 1.5473e-01, 0.0000e+00, 4.3038e-01,\n",
      "         9.6048e-01, 3.1567e-02, 5.5781e-03, 5.4949e-02, 2.2595e-01, 1.8073e-01,\n",
      "         7.3759e-01, 4.2818e-01, 1.0991e-01, 9.5451e-02, 8.5175e-01, 9.9062e-01,\n",
      "         8.7305e-01, 8.8339e-01, 7.0381e-01, 7.9151e-01, 1.4110e-01, 2.6754e-01,\n",
      "         5.6001e-01, 3.9579e-01, 2.6923e-01, 3.7004e-01, 3.3487e-01, 3.4886e-01,\n",
      "         6.9711e-01, 8.1409e-01, 4.7716e-03, 5.9606e-01, 5.5832e-01, 6.1120e-01,\n",
      "         3.6805e-01, 1.4455e-01, 1.2593e-01, 2.7327e-01, 5.8287e-02, 5.2228e-01,\n",
      "         2.1687e-01, 3.9387e-01, 4.0195e-01, 5.6612e-01, 2.0728e-01, 0.0000e+00,\n",
      "         4.5989e-02, 1.7950e-02, 3.9474e-01, 3.9848e-01]], device='cuda:0')\n",
      "Predicted: \"[3712.8972]\",\n",
      " Actual: \"[4049.719]\", Last: [4849.3267]\n",
      "Year: \"[2019.]\"\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.8000, 0.4319, 0.2544, 0.0623, 0.0019, 0.0000, 0.0000,\n",
      "         0.0000, 0.1559, 0.2569, 0.8470, 0.0573, 0.1276, 0.3517, 0.3546, 0.0409,\n",
      "         0.1923, 0.1019, 0.0000, 0.0811, 0.2171, 0.0390, 0.2278, 0.1615, 0.1992,\n",
      "         0.0835, 0.1756, 0.4558, 0.7015, 0.6443, 1.0000, 0.5156, 0.1432, 0.2808,\n",
      "         0.1615, 0.1169, 0.0295, 0.1749, 0.0000, 0.4025, 0.9788, 0.0586, 0.1840,\n",
      "         0.1163, 0.2775, 0.2307, 0.5188, 0.3597, 0.5758, 0.4276, 0.9043, 0.7849,\n",
      "         0.8370, 0.7423, 0.7722, 0.7146, 0.4293, 0.1604, 0.3279, 0.5424, 0.2243,\n",
      "         0.4111, 0.3554, 0.4538, 0.6142, 0.8823, 0.0583, 0.3099, 0.2114, 0.1940,\n",
      "         0.1435, 0.0609, 0.1514, 0.3958, 0.0223, 0.7587, 0.2969, 0.3687, 0.3517,\n",
      "         0.5773, 0.1919, 0.0000, 0.0585, 0.1681, 0.2899, 0.4478]],\n",
      "       device='cuda:0')\n",
      "Predicted: \"[6681.318]\",\n",
      " Actual: \"[6919.8486]\", Last: [4849.3267]\n",
      "Year: \"[2019.]\"\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.8000, 0.7674, 0.3779, 0.0373, 0.0027, 0.0000, 0.0000,\n",
      "         0.0000, 0.1644, 0.1606, 0.8078, 0.0000, 0.2781, 0.6022, 0.5879, 0.0248,\n",
      "         0.3886, 0.0551, 0.0000, 0.1072, 0.2013, 0.0236, 0.3003, 0.1114, 0.3517,\n",
      "         0.0506, 0.1683, 0.5120, 0.4272, 0.6104, 0.1648, 0.3316, 0.1260, 0.2750,\n",
      "         0.0653, 0.3545, 0.0358, 0.1060, 0.0000, 0.6631, 0.9728, 0.1020, 0.1527,\n",
      "         0.1814, 0.2982, 0.3176, 0.8340, 0.5944, 0.2742, 0.2832, 0.9960, 0.8638,\n",
      "         0.7326, 0.7254, 0.5615, 0.6005, 0.3234, 0.4603, 0.6055, 0.3194, 0.5136,\n",
      "         0.3270, 0.3577, 0.4351, 0.5479, 0.6439, 0.0144, 0.7930, 0.7699, 0.7471,\n",
      "         0.4510, 0.0683, 0.0388, 0.2358, 0.0280, 0.5141, 0.2849, 0.6058, 0.6022,\n",
      "         0.5558, 0.1708, 0.0000, 0.0357, 0.0937, 0.4275, 0.7790]],\n",
      "       device='cuda:0')\n",
      "Predicted: \"[5132.3755]\",\n",
      " Actual: \"[5851.4634]\", Last: [4849.3267]\n",
      "Year: \"[2019.]\"\n",
      "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 8.0000e-01, 1.8798e-01, 5.7233e-01, 1.0480e-02,\n",
      "         1.5144e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.7466e-01, 2.1512e-01,\n",
      "         5.0346e-01, 0.0000e+00, 5.3062e-01, 2.6713e-01, 2.9248e-01, 0.0000e+00,\n",
      "         8.2086e-02, 9.7202e-02, 0.0000e+00, 1.7570e-01, 9.1595e-01, 3.4945e-01,\n",
      "         3.4252e-01, 1.4263e-01, 5.2733e-01, 5.1347e-01, 4.0059e-01, 8.4104e-01,\n",
      "         0.0000e+00, 1.7454e-01, 2.2242e-01, 3.2019e-01, 1.9296e-02, 7.5857e-02,\n",
      "         1.3787e-01, 2.9953e-01, 3.7791e-02, 0.0000e+00, 0.0000e+00, 3.6166e-01,\n",
      "         8.4507e-01, 3.4153e-02, 3.0257e-01, 4.5220e-01, 1.4968e-01, 2.4898e-03,\n",
      "         0.0000e+00, 2.1260e-01, 1.0616e-01, 2.2933e-01, 9.7433e-01, 6.7922e-01,\n",
      "         8.2215e-01, 8.3625e-01, 2.4775e-01, 5.0539e-02, 1.3469e-01, 2.7720e-01,\n",
      "         9.5611e-01, 1.0538e-01, 3.3072e-01, 3.9870e-01, 1.3737e-01, 2.9330e-01,\n",
      "         3.2827e-01, 3.5896e-01, 3.0995e-02, 4.6149e-01, 2.8406e-01, 2.8118e-01,\n",
      "         1.6095e-01, 2.9875e-02, 1.0613e-01, 3.3972e-01, 1.8902e-02, 0.0000e+00,\n",
      "         5.3506e-01, 3.9360e-01, 2.6713e-01, 5.3246e-01, 1.7991e-01, 0.0000e+00,\n",
      "         8.7350e-03, 3.8287e-01, 6.2211e-01, 1.7900e-01]], device='cuda:0')\n",
      "Predicted: \"[11800.833]\",\n",
      " Actual: \"[11226.315]\", Last: [4849.3267]\n",
      "Year: \"[2019.]\"\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.8000, 0.5937, 0.3109, 0.0639, 0.0033, 0.0000, 0.0000,\n",
      "         0.0000, 0.2552, 0.4519, 0.5158, 0.0645, 0.4059, 0.4875, 0.5573, 0.0605,\n",
      "         0.0948, 0.1809, 0.0000, 0.1474, 0.2551, 0.0865, 0.2564, 0.1565, 0.2229,\n",
      "         0.0618, 0.1481, 0.4875, 0.5291, 0.6642, 0.4455, 0.3236, 0.1569, 0.1417,\n",
      "         0.1593, 0.1730, 0.0218, 0.1294, 0.0000, 0.5624, 0.9541, 0.0468, 0.1219,\n",
      "         0.1705, 0.3859, 0.2760, 0.5325, 0.4894, 0.4339, 0.3124, 0.9772, 0.8663,\n",
      "         0.6170, 0.7157, 0.6770, 0.5892, 0.2961, 0.1756, 0.3692, 0.4562, 0.2515,\n",
      "         0.2570, 0.3786, 0.5616, 0.5583, 0.7793, 0.0374, 0.4900, 0.3925, 0.3955,\n",
      "         0.2496, 0.1631, 0.1081, 0.3623, 0.0691, 0.6368, 0.3530, 0.5326, 0.4875,\n",
      "         0.5496, 0.1417, 0.0000, 0.0513, 0.1632, 0.3538, 0.5967]],\n",
      "       device='cuda:0')\n",
      "Predicted: \"[6543.1733]\",\n",
      " Actual: \"[7419.5054]\", Last: [4849.3267]\n",
      "Year: \"[2019.]\"\n",
      "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 8.0000e-01, 5.1258e-01, 4.7392e-01, 2.7659e-02,\n",
      "         8.8968e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.5404e-01, 2.0166e-02,\n",
      "         1.0000e+00, 0.0000e+00, 9.4834e-02, 4.8744e-01, 5.0859e-01, 9.0700e-02,\n",
      "         4.7415e-01, 2.6957e-02, 0.0000e+00, 1.9658e-01, 2.9288e-01, 5.7672e-02,\n",
      "         2.4914e-01, 1.1122e-01, 4.2206e-01, 4.9433e-02, 2.6863e-01, 5.8849e-01,\n",
      "         5.9467e-01, 3.8823e-01, 7.0455e-01, 2.7743e-01, 9.2262e-02, 1.7818e-01,\n",
      "         3.1856e-01, 1.7302e-01, 0.0000e+00, 2.5874e-01, 0.0000e+00, 5.7920e-01,\n",
      "         9.4089e-01, 4.2007e-02, 3.9033e-02, 2.7824e-01, 2.6376e-01, 1.7438e-01,\n",
      "         3.9932e-01, 4.5499e-01, 1.8925e-01, 1.1461e-01, 1.0000e+00, 9.7619e-01,\n",
      "         7.6164e-01, 8.5579e-01, 6.5535e-01, 5.2994e-01, 1.7829e-01, 3.2388e-01,\n",
      "         7.5931e-01, 2.0354e-01, 3.1408e-01, 3.8407e-01, 2.9396e-01, 6.0242e-01,\n",
      "         5.9177e-01, 7.0781e-01, 1.1412e-02, 5.8187e-01, 4.9276e-01, 4.7977e-01,\n",
      "         2.3561e-01, 0.0000e+00, 1.0360e-01, 2.4394e-01, 5.5775e-02, 4.2262e-01,\n",
      "         4.1509e-01, 5.5909e-01, 4.8744e-01, 5.4128e-01, 1.7171e-01, 0.0000e+00,\n",
      "         2.0841e-02, 5.1144e-02, 5.2448e-01, 5.3195e-01]], device='cuda:0')\n",
      "Predicted: \"[4188.656]\",\n",
      " Actual: \"[4799.397]\", Last: [4849.3267]\n",
      "Year: \"[2019.]\"\n",
      "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 8.0000e-01, 8.4416e-02, 5.2686e-01, 4.0048e-02,\n",
      "         6.4525e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.8635e-01, 2.1787e-02,\n",
      "         9.5643e-01, 0.0000e+00, 1.5580e-01, 3.0261e-01, 3.1067e-01, 4.6827e-02,\n",
      "         3.6720e-01, 5.1101e-02, 0.0000e+00, 2.2942e-01, 5.4144e-01, 4.4663e-02,\n",
      "         3.5184e-01, 1.4037e-01, 3.1162e-01, 5.7423e-02, 2.5785e-01, 6.8237e-01,\n",
      "         1.0000e+00, 6.5027e-01, 5.1032e-01, 5.1922e-01, 1.3128e-01, 5.5910e-02,\n",
      "         1.8503e-01, 2.6798e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.3469e-01,\n",
      "         9.2121e-01, 6.3508e-02, 1.9649e-01, 1.3245e-01, 2.0877e-01, 5.3695e-02,\n",
      "         4.0019e-01, 2.9857e-01, 2.3431e-01, 2.3678e-01, 9.6425e-01, 7.4763e-01,\n",
      "         9.2365e-01, 9.5705e-01, 8.9117e-01, 7.0973e-01, 0.0000e+00, 2.2636e-01,\n",
      "         7.0416e-01, 2.4299e-01, 5.8944e-02, 4.6831e-01, 3.0804e-01, 7.8143e-01,\n",
      "         6.5872e-01, 8.8931e-01, 8.9217e-03, 3.8433e-01, 2.1784e-01, 2.1794e-01,\n",
      "         9.7111e-02, 2.1648e-02, 1.0740e-02, 3.5719e-01, 1.1301e-02, 7.6928e-01,\n",
      "         5.2753e-01, 3.2656e-01, 3.0261e-01, 5.4090e-01, 1.5846e-01, 0.0000e+00,\n",
      "         3.1817e-02, 6.1348e-02, 6.0713e-01, 9.2894e-02]], device='cuda:0')\n",
      "Predicted: \"[4927.9146]\",\n",
      " Actual: \"[4849.3267]\", Last: [4849.3267]\n",
      "Year: \"[2019.]\"\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 1.0000, 0.6318, 0.1708, 0.0788, 0.0244, 0.0024, 0.0129,\n",
      "         0.0060, 0.0403, 0.0460, 0.1627, 0.5640, 0.3586, 0.5436, 0.4549, 0.0273,\n",
      "         0.0000, 0.0823, 0.0000, 0.0592, 0.1194, 0.0521, 0.1191, 0.0298, 0.2199,\n",
      "         0.0223, 0.0509, 0.0927, 0.4748, 0.1920, 0.0655, 0.2400, 0.1144, 0.1498,\n",
      "         0.1078, 0.0781, 0.0197, 0.0000, 0.0821, 0.5288, 0.9780, 0.0087, 0.1541,\n",
      "         0.0847, 0.4350, 0.3463, 0.7900, 0.5393, 0.5779, 0.3249, 0.7337, 0.7277,\n",
      "         0.5769, 0.4677, 0.7532, 0.6320, 0.2909, 0.1214, 0.1279, 0.5014, 0.3442,\n",
      "         0.0021, 0.4153, 0.0422, 0.4591, 0.7329, 0.1381, 0.5146, 0.5305, 0.6614,\n",
      "         0.4597, 0.2293, 0.1504, 0.4906, 0.0942, 0.2990, 0.2431, 0.4763, 0.5436,\n",
      "         0.5583, 0.2354, 0.0000, 0.0525, 0.1842, 0.1721, 0.8413]],\n",
      "       device='cuda:0')\n",
      "Predicted: \"[6947.733]\",\n",
      " Actual: \"[7268.006]\", Last: [4849.3267]\n",
      "Year: \"[2020.]\"\n",
      "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.0000e+00, 5.9653e-02, 5.9728e-02, 7.6545e-01,\n",
      "         2.6220e-01, 8.7650e-01, 8.2276e-01, 8.5768e-01, 1.2959e-04, 3.3148e-03,\n",
      "         0.0000e+00, 7.9075e-01, 2.7830e-01, 0.0000e+00, 3.0834e-02, 9.2333e-01,\n",
      "         0.0000e+00, 3.1884e-01, 1.0000e+00, 1.6714e-01, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 6.2502e-01, 1.8871e-01, 2.0724e-01, 4.7599e-01,\n",
      "         5.4999e-01, 9.2390e-01, 0.0000e+00, 1.7651e-01, 9.0766e-01, 1.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         7.0018e-01, 5.7694e-02, 4.3089e-02, 1.7136e-02, 6.3883e-01, 6.4024e-01,\n",
      "         7.8725e-01, 0.0000e+00, 1.6441e-02, 3.0711e-01, 0.0000e+00, 7.8738e-01,\n",
      "         1.6062e-01, 4.2501e-01, 7.8400e-01, 1.0000e+00, 2.9032e-01, 8.0827e-03,\n",
      "         2.5325e-02, 9.8980e-01, 1.2516e-01, 1.0000e+00, 5.6651e-01, 6.4567e-01,\n",
      "         7.2900e-01, 7.3836e-01, 5.2918e-01, 2.3072e-02, 0.0000e+00, 0.0000e+00,\n",
      "         1.3039e-02, 3.3243e-01, 3.9314e-01, 4.5244e-02, 6.8755e-01, 7.6651e-01,\n",
      "         4.7004e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.9186e-01, 1.0000e+00,\n",
      "         6.9871e-01, 2.3174e-01, 4.2506e-02, 7.7975e-02]], device='cuda:0')\n",
      "Predicted: \"[7786.9478]\",\n",
      " Actual: \"[8371.977]\", Last: [4849.3267]\n",
      "Year: \"[2020.]\"\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 1.0000, 0.0289, 0.0382, 0.7652, 0.2431, 1.0000, 0.9234,\n",
      "         0.9787, 0.0016, 0.0018, 0.0016, 0.9983, 0.0134, 0.0447, 0.0310, 1.0000,\n",
      "         0.0000, 0.8560, 0.0000, 0.4201, 1.0000, 0.5723, 0.0970, 0.4088, 0.7317,\n",
      "         0.6540, 0.9276, 0.7068, 0.4894, 0.5848, 0.0000, 0.8412, 0.5855, 0.6101,\n",
      "         0.7903, 0.5723, 0.4332, 0.8558, 0.0000, 0.0506, 0.8213, 0.0821, 0.5016,\n",
      "         0.1741, 0.8321, 0.6656, 0.6811, 0.0405, 0.4544, 0.4597, 0.3434, 0.4380,\n",
      "         0.2136, 0.2409, 0.8170, 0.6999, 0.3584, 0.0000, 0.0250, 0.8544, 0.2920,\n",
      "         0.6380, 0.5640, 0.5472, 0.6957, 0.7328, 1.0000, 0.1163, 0.1444, 0.1752,\n",
      "         0.1650, 0.2248, 0.7350, 1.0000, 0.4415, 0.5318, 0.9288, 0.0503, 0.0447,\n",
      "         0.3122, 0.9174, 1.0000, 0.7523, 0.4019, 0.0373, 0.0439]],\n",
      "       device='cuda:0')\n",
      "Predicted: \"[12155.63]\",\n",
      " Actual: \"[11586.586]\", Last: [4849.3267]\n",
      "Year: \"[2020.]\"\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 1.0000, 0.1636, 0.2491, 0.3440, 0.0974, 0.2835, 0.2692,\n",
      "         0.2811, 0.0217, 0.0106, 0.0218, 0.9838, 0.0021, 0.1840, 0.4435, 0.1446,\n",
      "         0.1134, 0.0882, 0.0000, 0.1017, 0.0904, 0.4137, 0.2628, 0.1970, 0.4418,\n",
      "         0.4433, 0.3202, 0.4898, 0.7477, 0.6658, 0.0000, 0.6081, 0.5729, 0.4096,\n",
      "         0.1904, 0.2069, 0.0522, 0.3094, 0.0000, 0.2074, 0.9004, 0.0989, 0.4718,\n",
      "         0.1558, 0.6591, 0.5440, 0.6201, 0.1780, 0.7157, 0.6322, 0.5135, 0.2330,\n",
      "         0.6788, 0.2728, 0.8455, 0.8271, 0.3803, 0.0293, 0.0878, 0.7671, 0.3483,\n",
      "         0.4115, 0.5153, 0.4688, 0.6070, 0.7674, 0.8017, 0.1499, 0.1622, 0.1959,\n",
      "         0.1888, 0.3306, 0.3038, 0.6749, 0.1993, 0.7542, 0.5355, 0.2008, 0.1840,\n",
      "         0.6702, 0.4918, 0.5000, 0.3393, 0.4362, 0.2406, 0.2263]],\n",
      "       device='cuda:0')\n",
      "Predicted: \"[12681.762]\",\n",
      " Actual: \"[13377.34]\", Last: [4849.3267]\n",
      "Year: \"[2020.]\"\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 1.0000, 0.0760, 0.1613, 0.2297, 0.2061, 0.2210, 0.3385,\n",
      "         0.2902, 0.0013, 0.0027, 0.0122, 0.5084, 0.6228, 0.1545, 0.3917, 0.0836,\n",
      "         0.1311, 0.1046, 0.0000, 0.1373, 0.1828, 0.2392, 0.1418, 0.1936, 0.3004,\n",
      "         0.0683, 0.1311, 0.1938, 0.3379, 0.3405, 0.2292, 0.5753, 0.6948, 0.4913,\n",
      "         0.2202, 0.2392, 0.0604, 0.3577, 0.0000, 0.1760, 0.8581, 0.0427, 0.1709,\n",
      "         0.0573, 0.4766, 0.4692, 0.6612, 0.1603, 0.3611, 0.3916, 0.1775, 0.6198,\n",
      "         0.5152, 0.5195, 0.8312, 0.8116, 0.3864, 0.0657, 0.1329, 0.7978, 0.2776,\n",
      "         0.5855, 0.4000, 0.4409, 0.7401, 0.8739, 0.1893, 0.0865, 0.0424, 0.0287,\n",
      "         0.0109, 0.4976, 0.3453, 0.6747, 0.2100, 0.6965, 0.7187, 0.1732, 0.1545,\n",
      "         0.6932, 0.1194, 0.5000, 0.2227, 0.2508, 0.1505, 0.1057]],\n",
      "       device='cuda:0')\n",
      "Predicted: \"[8421.764]\",\n",
      " Actual: \"[9116.998]\", Last: [4849.3267]\n",
      "Year: \"[2020.]\"\n",
      "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.0000e+00, 4.1557e-01, 4.7650e-01, 0.0000e+00,\n",
      "         5.6319e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.7029e-01, 2.2329e-01,\n",
      "         2.8481e-01, 0.0000e+00, 8.3024e-01, 3.8628e-01, 3.6571e-01, 3.0006e-01,\n",
      "         1.0000e+00, 6.4829e-02, 0.0000e+00, 3.3888e-01, 7.0327e-01, 2.8619e-01,\n",
      "         1.0000e+00, 2.2487e-01, 9.3318e-01, 6.8993e-01, 1.0000e+00, 7.6963e-01,\n",
      "         3.6851e-01, 5.3267e-01, 0.0000e+00, 1.7209e-01, 0.0000e+00, 3.8406e-01,\n",
      "         4.9401e-02, 3.2197e-01, 2.7082e-02, 1.6050e-01, 0.0000e+00, 4.8010e-01,\n",
      "         8.3855e-01, 6.3090e-01, 5.6549e-01, 1.0000e+00, 0.0000e+00, 2.6095e-01,\n",
      "         4.4940e-01, 2.5980e-01, 1.5317e-01, 0.0000e+00, 9.9304e-01, 4.1677e-01,\n",
      "         8.3632e-01, 6.0445e-01, 0.0000e+00, 0.0000e+00, 4.0811e-01, 1.0000e+00,\n",
      "         1.0000e+00, 0.0000e+00, 1.0000e+00, 4.2122e-01, 0.0000e+00, 7.8786e-02,\n",
      "         0.0000e+00, 0.0000e+00, 3.1256e-02, 7.7636e-01, 6.9941e-01, 5.9688e-01,\n",
      "         3.1750e-01, 9.9332e-03, 0.0000e+00, 3.4999e-01, 0.0000e+00, 3.1255e-01,\n",
      "         6.7628e-01, 5.4762e-01, 3.8628e-01, 5.2926e-01, 1.9403e-01, 0.0000e+00,\n",
      "         0.0000e+00, 8.0663e-01, 4.5066e-01, 5.8406e-01]], device='cuda:0')\n",
      "Predicted: \"[21158.002]\",\n",
      " Actual: \"[21397.629]\", Last: [4849.3267]\n",
      "Year: \"[2020.]\"\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 1.0000, 0.3071, 0.3419, 0.0209, 0.0013, 0.0000, 0.0000,\n",
      "         0.0000, 0.2585, 0.2309, 0.8498, 0.0000, 0.1881, 0.5034, 0.4815, 0.0000,\n",
      "         0.2300, 0.1110, 0.0000, 0.1329, 0.3208, 0.0839, 0.2062, 0.0999, 0.4459,\n",
      "         0.1439, 0.2411, 0.7335, 0.6205, 0.6424, 0.2875, 0.3477, 0.1429, 0.1341,\n",
      "         0.1159, 0.1679, 0.0212, 0.1255, 0.0000, 0.5904, 0.9517, 0.0381, 0.2128,\n",
      "         0.3835, 0.5416, 0.3727, 0.6323, 0.4612, 0.4912, 0.3208, 0.9891, 0.6484,\n",
      "         0.4921, 0.4976, 0.4987, 0.3551, 0.4121, 0.3236, 0.5374, 0.3760, 0.4904,\n",
      "         0.2198, 0.6001, 0.5667, 0.5845, 0.5300, 0.0745, 0.5691, 0.5529, 0.6584,\n",
      "         0.4828, 0.0948, 0.0973, 0.4620, 0.0640, 0.2893, 0.4628, 0.5648, 0.5034,\n",
      "         0.5280, 0.2130, 0.0000, 0.0177, 0.2159, 0.3299, 0.4351]],\n",
      "       device='cuda:0')\n",
      "Predicted: \"[7992.202]\",\n",
      " Actual: \"[7647.6143]\", Last: [4849.3267]\n",
      "Year: \"[2020.]\"\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 1.0000, 0.5572, 0.4017, 0.0373, 0.0027, 0.0000, 0.0000,\n",
      "         0.0000, 0.1644, 0.1606, 0.8078, 0.0000, 0.2781, 0.6022, 0.5879, 0.0248,\n",
      "         0.3886, 0.0551, 0.0000, 0.1072, 0.2013, 0.0236, 0.3003, 0.1114, 0.3517,\n",
      "         0.0506, 0.1683, 0.5120, 0.4272, 0.6104, 0.1648, 0.3316, 0.1260, 0.2750,\n",
      "         0.0653, 0.3545, 0.0358, 0.1060, 0.0000, 0.6631, 0.9728, 0.1020, 0.1527,\n",
      "         0.1814, 0.2982, 0.3176, 0.8340, 0.5944, 0.2742, 0.2832, 0.9960, 0.8638,\n",
      "         0.7326, 0.7254, 0.5615, 0.6005, 0.3234, 0.4603, 0.6055, 0.3194, 0.5136,\n",
      "         0.3270, 0.3577, 0.4351, 0.5479, 0.6439, 0.0144, 0.7930, 0.7699, 0.7471,\n",
      "         0.4510, 0.0683, 0.0388, 0.2358, 0.0280, 0.5141, 0.2849, 0.6058, 0.6022,\n",
      "         0.5558, 0.1708, 0.0000, 0.0357, 0.1214, 0.4067, 0.7667]],\n",
      "       device='cuda:0')\n",
      "Predicted: \"[5455.324]\",\n",
      " Actual: \"[6387.7363]\", Last: [4849.3267]\n",
      "Year: \"[2020.]\"\n",
      "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.0000e+00, 5.2328e-01, 1.4933e-01, 5.7697e-02,\n",
      "         2.1277e-02, 6.3064e-04, 2.1001e-03, 1.4870e-03, 2.8227e-02, 2.1167e-01,\n",
      "         1.9435e-01, 4.7706e-01, 3.7509e-01, 6.3936e-01, 6.3901e-01, 2.3414e-02,\n",
      "         7.3440e-02, 0.0000e+00, 0.0000e+00, 2.4950e-03, 1.0975e-01, 2.2332e-02,\n",
      "         1.0782e-01, 3.1902e-02, 8.0349e-02, 3.8283e-02, 3.3914e-02, 7.6768e-02,\n",
      "         1.5443e-01, 3.0555e-02, 0.0000e+00, 2.2380e-01, 4.7780e-02, 1.1239e-01,\n",
      "         4.0090e-01, 6.6995e-02, 1.6905e-02, 1.0019e-01, 0.0000e+00, 6.1806e-01,\n",
      "         9.5704e-01, 5.7822e-02, 1.1648e-01, 7.6775e-02, 2.2456e-01, 2.0791e-01,\n",
      "         5.3645e-01, 5.9935e-01, 5.9443e-01, 4.0313e-01, 6.4725e-01, 7.3613e-01,\n",
      "         6.2751e-01, 5.8651e-01, 8.1919e-01, 6.1285e-01, 1.9804e-01, 1.3443e-01,\n",
      "         2.5021e-01, 3.8916e-01, 5.3370e-01, 6.0359e-02, 1.4568e-01, 0.0000e+00,\n",
      "         2.6698e-01, 8.1711e-01, 1.3610e-01, 5.4507e-01, 4.6415e-01, 4.8787e-01,\n",
      "         2.7237e-01, 4.0400e-01, 1.0619e-01, 4.5437e-01, 2.4211e-01, 4.8409e-01,\n",
      "         8.5992e-01, 5.7167e-01, 6.3936e-01, 4.8955e-01, 1.7574e-01, 0.0000e+00,\n",
      "         5.3780e-02, 1.3371e-01, 1.4354e-01, 7.3719e-01]], device='cuda:0')\n",
      "Predicted: \"[6478.863]\",\n",
      " Actual: \"[6356.9473]\", Last: [4849.3267]\n",
      "Year: \"[2020.]\"\n",
      "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.0000e+00, 2.8587e-01, 2.7188e-01, 1.7712e-02,\n",
      "         4.5095e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.3663e-01, 4.4134e-01,\n",
      "         6.1610e-01, 0.0000e+00, 3.2751e-01, 2.4762e-01, 2.6540e-01, 1.6790e-01,\n",
      "         2.6331e-01, 2.6798e-01, 0.0000e+00, 3.2027e-01, 3.4978e-01, 5.3379e-01,\n",
      "         3.2555e-01, 1.9064e-01, 6.6095e-01, 1.8301e-01, 2.7697e-01, 8.7299e-01,\n",
      "         5.3586e-01, 2.6362e-01, 2.1481e-01, 3.4237e-01, 1.0603e-01, 2.2396e-01,\n",
      "         0.0000e+00, 4.8041e-01, 4.0409e-02, 2.3948e-01, 0.0000e+00, 2.8322e-01,\n",
      "         9.3466e-01, 4.7264e-02, 4.9441e-01, 3.8932e-01, 4.2829e-01, 3.4018e-01,\n",
      "         5.8521e-01, 2.1800e-01, 6.8783e-01, 4.8100e-01, 9.7062e-01, 5.7086e-01,\n",
      "         3.9757e-01, 3.9054e-01, 4.4735e-01, 3.0119e-01, 4.7000e-01, 3.3950e-01,\n",
      "         5.5036e-01, 2.8382e-01, 7.1758e-01, 1.7766e-01, 3.6474e-01, 3.4213e-01,\n",
      "         3.7059e-01, 5.7048e-01, 7.3623e-02, 6.6814e-01, 6.3288e-01, 6.9236e-01,\n",
      "         6.3243e-01, 5.0513e-03, 9.0835e-02, 5.0445e-01, 6.5907e-02, 3.7349e-01,\n",
      "         7.5148e-01, 2.7560e-01, 2.4762e-01, 5.1839e-01, 1.9544e-01, 0.0000e+00,\n",
      "         1.3858e-02, 3.0071e-01, 2.7695e-01, 3.9046e-01]], device='cuda:0')\n",
      "Predicted: \"[9581.204]\",\n",
      " Actual: \"[10239.549]\", Last: [4849.3267]\n",
      "Year: \"[2020.]\"\n",
      "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.0000e+00, 5.9048e-02, 5.9122e-01, 4.0048e-02,\n",
      "         6.4525e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.8635e-01, 2.1787e-02,\n",
      "         9.5643e-01, 0.0000e+00, 1.5580e-01, 3.0261e-01, 3.1067e-01, 4.6827e-02,\n",
      "         3.6720e-01, 5.1101e-02, 0.0000e+00, 2.2942e-01, 5.4144e-01, 4.4663e-02,\n",
      "         3.5184e-01, 1.4037e-01, 3.1162e-01, 5.7423e-02, 2.5785e-01, 6.8237e-01,\n",
      "         1.0000e+00, 6.5027e-01, 5.1032e-01, 5.1922e-01, 1.3128e-01, 5.5910e-02,\n",
      "         1.8503e-01, 2.6798e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.3469e-01,\n",
      "         9.2121e-01, 6.3508e-02, 1.9649e-01, 1.3245e-01, 2.0877e-01, 5.3695e-02,\n",
      "         4.0019e-01, 2.9857e-01, 2.3431e-01, 2.3678e-01, 9.6425e-01, 7.4763e-01,\n",
      "         9.2365e-01, 9.5705e-01, 8.9117e-01, 7.0973e-01, 0.0000e+00, 2.2636e-01,\n",
      "         7.0416e-01, 2.4299e-01, 5.8944e-02, 4.6831e-01, 3.0804e-01, 7.8143e-01,\n",
      "         6.5872e-01, 8.8931e-01, 8.9217e-03, 3.8433e-01, 2.1784e-01, 2.1794e-01,\n",
      "         9.7111e-02, 2.1648e-02, 1.0740e-02, 3.5719e-01, 1.1301e-02, 7.6928e-01,\n",
      "         5.2753e-01, 3.2656e-01, 3.0261e-01, 5.4090e-01, 1.5846e-01, 0.0000e+00,\n",
      "         3.1817e-02, 7.7554e-02, 5.6703e-01, 8.1734e-02]], device='cuda:0')\n",
      "Predicted: \"[5150.3457]\",\n",
      " Actual: \"[5319.0884]\", Last: [4849.3267]\n",
      "Year: \"[2020.]\"\n",
      "[827.4951]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    i = 0\n",
    "    target = 10\n",
    "    mse = 0\n",
    "    for x, y in test_dataloader:\n",
    "        i += 1\n",
    "        # if i > target:\n",
    "        #     break\n",
    "\n",
    "        out = np.hstack((x[:,56:], y.reshape(-1,1)))\n",
    "        old_x = scaler.inverse_transform(out)\n",
    "        # print(old_x)\n",
    "        year = old_x[:, year_idx]\n",
    "        crime = old_x[:, idx]\n",
    "        # y = y * s + m\n",
    "\n",
    "        # year = x[:,0] * s_m + y_m\n",
    "        # print(encoder.inverse_transform(x[:,:56]))\n",
    "        x = x.to(device)\n",
    "        print(x)\n",
    "\n",
    "\n",
    "        \n",
    "        pred = model(x)\n",
    "        pred = pred.detach().cpu().numpy()\n",
    "        x = x.detach().cpu().numpy()\n",
    "        out = np.hstack((x[:,56:], pred.reshape(-1,1)))\n",
    "        out = scaler.inverse_transform(out)\n",
    "        pred = out[:, idx]\n",
    "        last = out2[:, last_idx]\n",
    "\n",
    "        print(f'Predicted: \"{pred}\",\\n Actual: \"{crime}\", Last: {last}')\n",
    "        print(f'Year: \"{year}\"')\n",
    "\n",
    "        mse += (pred - crime) ** 2\n",
    "\n",
    "    print(np.sqrt(mse / i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1235,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = best_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGA: greatergeelong, Year: 2016\n",
      "NN: 8594.08, NULL: 8944.57, Actual: 9586.31\n",
      "LGA: moorabool, Year: 2016\n",
      "NN: 6400.34, NULL: 6961.83, Actual: 7755.88\n",
      "LGA: centralgoldfields, Year: 2016\n",
      "NN: 10002.66, NULL: 9711.90, Actual: 11515.24\n",
      "LGA: benalla, Year: 2016\n",
      "NN: 9103.52, NULL: 8290.30, Actual: 11471.89\n",
      "LGA: campaspe, Year: 2016\n",
      "NN: 9429.74, NULL: 8230.76, Actual: 10240.72\n",
      "LGA: wellington, Year: 2016\n",
      "NN: 9611.36, NULL: 10111.51, Actual: 10905.12\n",
      "LGA: wodonga, Year: 2016\n",
      "NN: 9094.30, NULL: 9049.26, Actual: 8254.36\n",
      "LGA: swanhill, Year: 2016\n",
      "NN: 12061.31, NULL: 10748.74, Actual: 10643.19\n",
      "LGA: southgippsland, Year: 2016\n",
      "NN: 5292.40, NULL: 4886.74, Actual: 5161.05\n",
      "LGA: macedonranges, Year: 2016\n",
      "NN: 5213.97, NULL: 4809.35, Actual: 5172.70\n",
      "LGA: horsham, Year: 2016\n",
      "NN: 11937.96, NULL: 15029.51, Actual: 14202.37\n",
      "LGA: boroondara, Year: 2016\n",
      "NN: 4163.50, NULL: 4508.72, Actual: 4736.68\n",
      "LGA: whitehorse, Year: 2016\n",
      "NN: 5141.68, NULL: 5218.20, Actual: 4708.77\n",
      "LGA: banyule, Year: 2016\n",
      "NN: 7602.05, NULL: 7397.51, Actual: 7903.68\n",
      "LGA: maroondah, Year: 2016\n",
      "NN: 7038.68, NULL: 6986.02, Actual: 8013.07\n",
      "LGA: kingston, Year: 2016\n",
      "NN: 6914.02, NULL: 7150.45, Actual: 7278.17\n",
      "LGA: greaterdandenong, Year: 2016\n",
      "NN: 11717.32, NULL: 12288.55, Actual: 12879.01\n",
      "LGA: yarra, Year: 2016\n",
      "NN: 14554.42, NULL: 14111.49, Actual: 15075.25\n",
      "LGA: stonnington, Year: 2016\n",
      "NN: 9590.01, NULL: 9326.82, Actual: 10441.16\n",
      "LGA: gleneira, Year: 2016\n",
      "NN: 4582.25, NULL: 4678.25, Actual: 5061.82\n",
      "LGA: whittlesea, Year: 2017\n",
      "NN: 7659.90, NULL: 8090.68, Actual: 7265.91\n",
      "LGA: northerngrampians, Year: 2017\n",
      "NN: 10804.11, NULL: 11485.85, Actual: 9093.26\n",
      "LGA: greatergeelong, Year: 2017\n",
      "NN: 8532.17, NULL: 9546.80, Actual: 9313.10\n",
      "LGA: benalla, Year: 2017\n",
      "NN: 9301.06, NULL: 11332.74, Actual: 9210.62\n",
      "LGA: wodonga, Year: 2017\n",
      "NN: 8932.44, NULL: 8285.23, Actual: 8071.11\n",
      "LGA: swanhill, Year: 2017\n",
      "NN: 11929.90, NULL: 10547.83, Actual: 11457.59\n",
      "LGA: eastgippsland, Year: 2017\n",
      "NN: 9864.95, NULL: 9103.63, Actual: 8576.56\n",
      "LGA: macedonranges, Year: 2017\n",
      "NN: 5084.64, NULL: 5366.41, Actual: 4395.33\n",
      "LGA: portphillip, Year: 2017\n",
      "NN: 12391.56, NULL: 12326.25, Actual: 11421.35\n",
      "LGA: cardinia, Year: 2017\n",
      "NN: 6815.65, NULL: 7484.36, Actual: 5687.57\n",
      "LGA: yarraranges, Year: 2017\n",
      "NN: 5528.67, NULL: 5908.02, Actual: 5238.81\n",
      "LGA: melton, Year: 2017\n",
      "NN: 8132.47, NULL: 8539.52, Actual: 7148.77\n",
      "LGA: wyndham, Year: 2017\n",
      "NN: 6631.39, NULL: 6884.13, Actual: 5890.15\n",
      "LGA: morningtonpeninsula, Year: 2017\n",
      "NN: 7186.58, NULL: 7507.05, Actual: 6647.87\n",
      "LGA: maribyrnong, Year: 2017\n",
      "NN: 10476.23, NULL: 10423.20, Actual: 9103.50\n",
      "LGA: bayside, Year: 2017\n",
      "NN: 4893.73, NULL: 5432.37, Actual: 4592.68\n",
      "LGA: mooneevalley, Year: 2017\n",
      "NN: 7254.67, NULL: 7881.14, Actual: 6921.60\n",
      "LGA: northerngrampians, Year: 2018\n",
      "NN: 10644.52, NULL: 9079.80, Actual: 8492.35\n",
      "LGA: colacotway, Year: 2018\n",
      "NN: 8349.64, NULL: 8107.47, Actual: 7313.38\n",
      "LGA: campaspe, Year: 2018\n",
      "NN: 9748.01, NULL: 8929.05, Actual: 10032.15\n",
      "LGA: glenelg, Year: 2018\n",
      "NN: 8421.26, NULL: 8306.62, Actual: 6751.12\n",
      "LGA: wodonga, Year: 2018\n",
      "NN: 8726.16, NULL: 8111.67, Actual: 7720.08\n",
      "LGA: greatershepparton, Year: 2018\n",
      "NN: 12795.43, NULL: 12021.65, Actual: 13084.73\n",
      "LGA: mildura, Year: 2018\n",
      "NN: 12029.11, NULL: 11566.46, Actual: 13049.83\n",
      "LGA: basscoast, Year: 2018\n",
      "NN: 7649.58, NULL: 7483.23, Actual: 6127.54\n",
      "LGA: horsham, Year: 2018\n",
      "NN: 11688.25, NULL: 11812.84, Actual: 15056.82\n",
      "LGA: darebin, Year: 2018\n",
      "NN: 9758.56, NULL: 9417.32, Actual: 9698.10\n",
      "LGA: whitehorse, Year: 2018\n",
      "NN: 5005.03, NULL: 5027.66, Actual: 4696.99\n",
      "LGA: banyule, Year: 2018\n",
      "NN: 7386.31, NULL: 7574.78, Actual: 7252.88\n",
      "LGA: kingston, Year: 2018\n",
      "NN: 6750.00, NULL: 6800.95, Actual: 6806.44\n",
      "LGA: greaterdandenong, Year: 2018\n",
      "NN: 11375.76, NULL: 10985.41, Actual: 11092.51\n",
      "LGA: frankston, Year: 2018\n",
      "NN: 10731.78, NULL: 10084.07, Actual: 10507.24\n",
      "LGA: wyndham, Year: 2018\n",
      "NN: 6430.80, NULL: 6045.94, Actual: 5627.02\n",
      "LGA: morningtonpeninsula, Year: 2018\n",
      "NN: 6909.78, NULL: 6763.63, Actual: 6482.19\n",
      "LGA: maribyrnong, Year: 2018\n",
      "NN: 10142.11, NULL: 9089.50, Actual: 9490.16\n",
      "LGA: centralgoldfields, Year: 2019\n",
      "NN: 9575.57, NULL: 9661.52, Actual: 10570.08\n",
      "LGA: alpine, Year: 2019\n",
      "NN: 3946.15, NULL: 4744.10, Actual: 4417.23\n",
      "LGA: benalla, Year: 2019\n",
      "NN: 8987.75, NULL: 8434.73, Actual: 9194.35\n",
      "LGA: horsham, Year: 2019\n",
      "NN: 11812.68, NULL: 14728.24, Actual: 9658.42\n",
      "LGA: maroondah, Year: 2019\n",
      "NN: 6960.33, NULL: 7019.72, Actual: 6919.85\n",
      "LGA: monash, Year: 2019\n",
      "NN: 5735.44, NULL: 5409.24, Actual: 5851.46\n",
      "LGA: portphillip, Year: 2019\n",
      "NN: 12048.74, NULL: 11669.61, Actual: 11226.32\n",
      "LGA: kingston, Year: 2019\n",
      "NN: 6735.08, NULL: 6913.82, Actual: 7419.51\n",
      "LGA: casey, Year: 2019\n",
      "NN: 6375.48, NULL: 6356.12, Actual: 6401.03\n",
      "LGA: cardinia, Year: 2019\n",
      "NN: 6245.70, NULL: 5823.45, Actual: 5926.68\n",
      "LGA: hume, Year: 2019\n",
      "NN: 9374.15, NULL: 9161.42, Actual: 9098.87\n",
      "LGA: hobsonsbay, Year: 2019\n",
      "NN: 6315.60, NULL: 6674.59, Actual: 6496.69\n",
      "LGA: gleneira, Year: 2019\n",
      "NN: 4577.49, NULL: 4488.40, Actual: 4799.40\n",
      "LGA: whittlesea, Year: 2020\n",
      "NN: 7109.86, NULL: 7368.20, Actual: 7268.01\n",
      "LGA: greatergeelong, Year: 2020\n",
      "NN: 8079.95, NULL: 8369.92, Actual: 8630.79\n",
      "LGA: moorabool, Year: 2020\n",
      "NN: 6474.01, NULL: 6095.53, Actual: 7281.29\n",
      "LGA: alpine, Year: 2020\n",
      "NN: 4050.39, NULL: 4650.86, Actual: 4458.40\n",
      "LGA: greaterbendigo, Year: 2020\n",
      "NN: 9198.85, NULL: 9643.46, Actual: 9221.56\n",
      "LGA: ballarat, Year: 2020\n",
      "NN: 10564.88, NULL: 10598.44, Actual: 8745.58\n",
      "LGA: macedonranges, Year: 2020\n",
      "NN: 4767.39, NULL: 5081.80, Actual: 5371.95\n",
      "LGA: horsham, Year: 2020\n",
      "NN: 11624.35, NULL: 9615.09, Actual: 12160.90\n",
      "LGA: wangaratta, Year: 2020\n",
      "NN: 8594.81, NULL: 8578.01, Actual: 10444.83\n",
      "LGA: banyule, Year: 2020\n",
      "NN: 7262.68, NULL: 7366.57, Actual: 7257.43\n",
      "LGA: maroondah, Year: 2020\n",
      "NN: 7026.50, NULL: 7021.24, Actual: 6771.21\n",
      "LGA: frankston, Year: 2020\n",
      "NN: 10448.09, NULL: 10421.65, Actual: 10397.28\n",
      "LGA: yarraranges, Year: 2020\n",
      "NN: 5507.79, NULL: 5943.13, Actual: 5513.10\n",
      "LGA: hobsonsbay, Year: 2020\n",
      "NN: 6347.73, NULL: 6620.44, Actual: 6119.15\n",
      "LGA: yarra, Year: 2020\n",
      "NN: 13687.78, NULL: 13715.33, Actual: 14692.43\n",
      "LGA: stonnington, Year: 2020\n",
      "NN: 9570.82, NULL: 10248.24, Actual: 10291.27\n",
      "null 1172.7395801830223 nn 985.2910192840595 all 983.3150767137583\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.formula.api import ols\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "model = best_model\n",
    "\n",
    "def null_model(train_set, test_set):\n",
    "    text = f\"crime ~ last_crime\"\n",
    "    model = ols(text, data=train_set).fit()\n",
    "    pred = model.predict(test_set)\n",
    "    mse = mean_squared_error(test_set['crime'], pred)\n",
    "    return np.sqrt(mse), model\n",
    "\n",
    "\n",
    "def all_model(train_set, test_set):\n",
    "    text = f'crime ~ C(lga) + last_crime + last_house + last_egm + last2_crime + last2_house + last3_house + last2_egm + last3_egm + last4_egm + last5_egm'\n",
    "    model = ols(text, data=train_set).fit()\n",
    "    pred = model.predict(test_set)\n",
    "    mse = mean_squared_error(test_set['crime'], pred)\n",
    "\n",
    "    return np.sqrt(mse), model\n",
    "\n",
    "train_set = actual.loc[train_data.index]\n",
    "test_set = actual.loc[test_data.index]\n",
    "mse, null = null_model(train_set, test_set)\n",
    "mse, cheating = all_model(train_set, test_set)\n",
    "# print(mse)\n",
    "\n",
    "mse = {\n",
    "    'null': 0,\n",
    "    'nn': 0,\n",
    "    'cheating': 0\n",
    "}\n",
    "\n",
    "model.eval()\n",
    "size = len(test_data.index)\n",
    "for i in test_data.index:\n",
    "    x = test_data.loc[i].copy()\n",
    "    row = actual.loc[i]\n",
    "\n",
    "    crime = actual.loc[i]['crime']\n",
    "    features = x.drop(labels=['crime'], axis=0).values\n",
    "    features = scaler_x.transform(features.reshape(1,-1))\n",
    "    features = torch.tensor(features).to(device).to(torch.float)\n",
    "    pred = model(features)\n",
    "\n",
    "    pred = pred.detach().cpu().numpy()\n",
    "    features = features.detach().cpu().numpy()\n",
    "    # result = np.hstack((features[:,56:], pred.reshape(-1,1)))\n",
    "    # result = scaler.inverse_transform(result)\n",
    "    pred = (pred * 20000).item()\n",
    "    # pred = result[:, idx].item()\n",
    "    null_result = null.predict(actual.loc[[i]].drop(columns=['crime'], axis=1)).values[0]\n",
    "    cheating_result =cheating.predict(actual.loc[[i]].drop(columns=['crime'], axis=1)).values[0] \n",
    "    print(f'LGA: {row[\"lga\"]}, Year: {row[\"year\"]}')\n",
    "    print(f\"NN: {pred:.2f}, NULL: {null_result:.2f}, Actual: {crime:.2f}\")\n",
    "    mse['null'] += (null_result-crime)**2\n",
    "    mse['nn'] += (pred - crime)**2\n",
    "    mse['cheating'] += (cheating_result - crime)**2\n",
    "\n",
    "print('null', np.sqrt(mse['null']/size), 'nn', np.sqrt(mse['nn']/size), 'all', np.sqrt(mse['cheating']/size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:~/miniconda3/lib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "progress 0.05\n",
      ", model null      , RMSE: 829.02\n",
      ", model all       , RMSE: 699.48\n",
      ", model svm       , RMSE: 3153.25\n",
      "progress 0.10\n",
      ", model null      , RMSE: 770.53\n",
      ", model all       , RMSE: 664.59\n",
      ", model svm       , RMSE: 2730.51\n",
      "progress 0.15\n",
      ", model null      , RMSE: 758.61\n",
      ", model all       , RMSE: 598.88\n",
      ", model svm       , RMSE: 2690.52\n",
      "progress 0.20\n",
      ", model null      , RMSE: 816.21\n",
      ", model all       , RMSE: 634.89\n",
      ", model svm       , RMSE: 3238.61\n",
      "progress 0.25\n",
      ", model null      , RMSE: 838.22\n",
      ", model all       , RMSE: 748.28\n",
      ", model svm       , RMSE: 3316.93\n",
      "progress 0.30\n",
      ", model null      , RMSE: 987.06\n",
      ", model all       , RMSE: 920.67\n",
      ", model svm       , RMSE: 3754.11\n",
      "progress 0.35\n",
      ", model null      , RMSE: 982.95\n",
      ", model all       , RMSE: 897.62\n",
      ", model svm       , RMSE: 3615.51\n",
      "progress 0.40\n",
      ", model null      , RMSE: 1020.67\n",
      ", model all       , RMSE: 927.23\n",
      ", model svm       , RMSE: 3506.81\n",
      "progress 0.45\n",
      ", model null      , RMSE: 1005.28\n",
      ", model all       , RMSE: 905.99\n",
      ", model svm       , RMSE: 3677.13\n",
      "progress 0.50\n",
      ", model null      , RMSE: 1023.73\n",
      ", model all       , RMSE: 882.65\n",
      ", model svm       , RMSE: 3519.18\n",
      "progress 0.55\n",
      ", model null      , RMSE: 1054.42\n",
      ", model all       , RMSE: 889.85\n",
      ", model svm       , RMSE: 3641.24\n",
      "progress 0.60\n",
      ", model null      , RMSE: 1030.49\n",
      ", model all       , RMSE: 863.65\n",
      ", model svm       , RMSE: 3524.38\n",
      "progress 0.65\n",
      ", model null      , RMSE: 1018.23\n",
      ", model all       , RMSE: 855.26\n",
      ", model svm       , RMSE: 3415.37\n",
      "progress 0.70\n",
      ", model null      , RMSE: 996.83\n",
      ", model all       , RMSE: 837.77\n",
      ", model svm       , RMSE: 3333.61\n",
      "progress 0.75\n",
      ", model null      , RMSE: 980.89\n",
      ", model all       , RMSE: 827.99\n",
      ", model svm       , RMSE: 3265.52\n",
      "progress 0.80\n",
      ", model null      , RMSE: 966.30\n",
      ", model all       , RMSE: 818.97\n",
      ", model svm       , RMSE: 3203.45\n",
      "progress 0.85\n",
      ", model null      , RMSE: 960.84\n",
      ", model all       , RMSE: 824.60\n",
      ", model svm       , RMSE: 3143.12\n",
      "progress 0.90\n",
      ", model null      , RMSE: 963.53\n",
      ", model all       , RMSE: 814.19\n",
      ", model svm       , RMSE: 3107.04\n",
      "progress 0.95\n",
      ", model null      , RMSE: 953.89\n",
      ", model all       , RMSE: 801.68\n",
      ", model svm       , RMSE: 3064.50\n",
      "progress 1.00\n",
      ", model null      , RMSE: 938.24\n",
      ", model all       , RMSE: 789.97\n",
      ", model svm       , RMSE: 3066.39\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR \n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from statsmodels.formula.api import ols\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import GradientBoostingRegressor, HistGradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, tolerance=5, min_delta=0):\n",
    "\n",
    "        self.tolerance = tolerance\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, train_loss, validation_loss):\n",
    "        if (validation_loss - train_loss) > self.min_delta:\n",
    "            self.counter +=1\n",
    "            if self.counter >= self.tolerance:  \n",
    "                self.early_stop = True\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, train_x):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(train_x.shape[1], 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "    \n",
    "def train_model(dataloader, model, loss_fn, optimizer):\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "def test_model(dataloader, model, scaler):\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X = X.to(device)\n",
    "            pred = model(X)\n",
    "\n",
    "            pred = scaler.inverse_transform(pred.detach().cpu().numpy().reshape(-1, 1))\n",
    "            y = scaler.inverse_transform(y.reshape(-1, 1))\n",
    "            test_loss += (pred - y) ** 2\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    return test_loss.item()\n",
    "\n",
    "state = 10000\n",
    "torch.manual_seed(state)\n",
    "torch.use_deterministic_algorithms(False)\n",
    "\n",
    "def create_network(train_data, test_data):\n",
    "    scaler_x = MinMaxScaler(feature_range=(0,1))\n",
    "    scaler_y = MinMaxScaler(feature_range=(0,1))\n",
    "\n",
    "    train_y = train_data['crime'].values\n",
    "    train_x = train_data.drop('crime', axis=1).values\n",
    "    test_y = test_data['crime'].values\n",
    "    test_x = test_data.drop('crime', axis=1).values\n",
    "\n",
    "    scaler_x.fit(train_x)\n",
    "    scaler_y.fit(train_y.reshape(-1, 1))\n",
    "\n",
    "    train_x = scaler_x.transform(train_x)\n",
    "    train_y = scaler_y.transform(train_y.reshape(-1, 1))\n",
    "\n",
    "    test_y = scaler_y.transform(test_y.reshape(-1, 1))\n",
    "    test_x = scaler_x.transform(test_x)\n",
    "\n",
    "    batch_size = 1\n",
    "    train = data_utils.TensorDataset(torch.Tensor(train_x), torch.Tensor(train_y))\n",
    "    test = data_utils.TensorDataset(torch.Tensor(test_x), torch.Tensor(test_y))\n",
    "    train_dataloader = DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "    test_dataloader = DataLoader(test, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # Get cpu, gpu or mps device for training.\n",
    "    device = (\n",
    "        \"cuda\"\n",
    "        if torch.cuda.is_available()\n",
    "        else \"mps\"\n",
    "        if torch.backends.mps.is_available()\n",
    "        else \"cpu\"\n",
    "    )\n",
    " \n",
    "\n",
    "    model = NeuralNetwork(train_x).to(device)\n",
    "\n",
    "    loss_fn = nn.HuberLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "    stopping = EarlyStopping(tolerance=50, min_delta=500)\n",
    "    best_val = 1e9\n",
    "    best_model = None\n",
    "    epoch = 0\n",
    "    while not stopping.early_stop and epoch < 600:\n",
    "        train_model(train_dataloader, model, loss_fn, optimizer)\n",
    "        test_val = np.sqrt(test_model(test_dataloader, model, scaler_y))\n",
    "        print(f\"epoch {epoch}, test {test_val:7.2f}, best {best_val:7.2f}\", end='\\r')\n",
    "\n",
    "        stopping(best_val, test_val)\n",
    "\n",
    "        if test_val < best_val:\n",
    "            best_val = test_val\n",
    "            best_model = copy.deepcopy(model)\n",
    "        epoch += 1\n",
    "\n",
    "    print('', end='\\r')\n",
    "    return test_model(test_dataloader, best_model, scaler_y)\n",
    "\n",
    "\n",
    "def null_model(train_set, test_set):\n",
    "    text = f\"crime ~ last_crime\"\n",
    "    model = ols(text, data=train_set).fit()\n",
    "    pred = model.predict(test_set)\n",
    "    mse = mean_squared_error(test_set['crime'], pred)\n",
    "    return mse\n",
    "\n",
    "def all_model(train_set, test_set):\n",
    "    lgas = ' + '.join([f\"lga{i}\" for i in range(56)])\n",
    "    text = f'crime ~ {lgas} + last_crime + last_house + last_egm + last2_crime + last2_house + last3_house + last2_egm + last3_egm + last4_egm + last5_egm'\n",
    "    model = ols(text, data=train_set).fit()\n",
    "    pred = model.predict(test_set)\n",
    "    mse = mean_squared_error(test_set['crime'], pred)\n",
    "\n",
    "    return mse\n",
    "\n",
    "\n",
    "def svm_model(train_data, test_data):\n",
    "    # lgas = [f\"lga{i}\" for i in range(56)]\n",
    "    # kept = ['last_crime', 'last_house', 'last_egm', 'last2_crime', 'last2_house', 'last2_egm', 'last3_house', 'last3_egm']\n",
    "\n",
    "    train_y = train_data['crime'].values\n",
    "    train_x = train_data.drop('crime', axis=1).values\n",
    "    test_y = test_data['crime'].values\n",
    "    test_x = test_data.drop('crime', axis=1).values\n",
    "\n",
    "    scaler_x = StandardScaler()\n",
    "    # train_x = train_data[kept].values\n",
    "    # test_x = test_data[kept].values\n",
    "\n",
    "    scaler_x.fit(train_x)\n",
    "    train_x = scaler_x.transform(train_x)\n",
    "    test_x = scaler_x.transform(test_x)\n",
    "\n",
    "    # pca = PCA(n_components=3)\n",
    "    # pca.fit(train_x)\n",
    "\n",
    "    # training = pca.transform(train_x)\n",
    "    # testing = pca.transform(test_x)\n",
    "\n",
    "    # lr = LinearRegression()\n",
    "    # lr.fit(training, train_y)\n",
    "    svr = SVR(kernel=\"rbf\", C=100, epsilon=0.1)\n",
    "    svr.fit(train_x, train_y)\n",
    "    pred = svr.predict(test_x)\n",
    "    mse = mean_squared_error(pred, test_y)\n",
    "    return mse\n",
    "\n",
    "def tree_model(train_data, test_data):\n",
    "    lgas = [f\"lga{i}\" for i in range(56)]\n",
    "    kept = ['last_crime', 'last_house', 'last_egm', 'last2_crime', 'last2_house', 'last2_egm', 'last3_house', 'last3_egm']\n",
    "\n",
    "    train_y = train_data['crime'].values\n",
    "    old_train_x = train_data.drop('crime', axis=1).values\n",
    "\n",
    "    test_y = test_data['crime'].values\n",
    "    old_test_x = test_data.drop('crime', axis=1).values\n",
    "\n",
    "\n",
    "    # pca = PCA(n_components=10)\n",
    "    # pca.fit(old_train_x)\n",
    "   \n",
    "\n",
    "    train_x = train_data[lgas+kept].values\n",
    "    test_x = test_data[lgas+kept].values\n",
    "    # train_x = np.hstack((train_x, pca.transform(old_train_x)))\n",
    "    # test_x = np.hstack((test_x, pca.transform(old_test_x)))\n",
    "\n",
    "    param_grid = {\n",
    "        'max_depth': [1,2,3,4,5],\n",
    "        'n_estimators': [ 50, 100, 200, 300],\n",
    "        'learning_rate': [0.1,0.15,0.2,0.25,0.3]\n",
    "    }\n",
    "\n",
    "    reg = GradientBoostingRegressor()\n",
    "    grid = GridSearchCV(estimator=reg, cv=5, param_grid=param_grid, n_jobs=18)\n",
    "    # grid = DecisionTreeRegressor(max_depth=5)\n",
    "    # reg = AdaBoostRegressor(n_estimators=1000)\n",
    "    grid.fit(train_x, train_y)\n",
    "    return mean_squared_error(test_y, grid.predict(test_x))\n",
    "\n",
    " \n",
    "\n",
    "n = 20\n",
    "fold = KFold(n, shuffle=True, random_state=state)\n",
    "\n",
    "models = {\n",
    "    'null': null_model,\n",
    "    'all': all_model,\n",
    "    # 'network': create_network,\n",
    "    'svm': svm_model,\n",
    "    # 'tree': tree_model,\n",
    "}\n",
    "\n",
    "total_mse = {k: 0 for k in models}\n",
    "total = 0\n",
    "for train, test in fold.split(new):\n",
    "    train_set = new.iloc[train]\n",
    "    test_set = new.iloc[test]\n",
    "\n",
    "    total += 1\n",
    "    print(f\"progress {total / n:.2f}\")\n",
    "    \n",
    "    for k, v in models.items():\n",
    "        mse = v(train_set, test_set)\n",
    "        total_mse[k] += mse\n",
    "        print(f\", model {k:10}, RMSE: {np.sqrt(total_mse[k]/total):6.2f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1385,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "model null           , RMSE:         938.24\n",
      "model all            , RMSE:         789.97\n",
      "model network        , RMSE:         819.70\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "for k, v in total_mse.items():\n",
    "    print(f\"model {k:15}, RMSE: {np.sqrt(v/n):14.2f}\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
