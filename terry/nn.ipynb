{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 905,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import pandas as pd\n",
    "import statsmodels as st\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import torch.utils.data as data_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 906,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>egm</th>\n",
       "      <th>medianhouseprice</th>\n",
       "      <th>offencecount</th>\n",
       "      <th>traveltimetogpominutes</th>\n",
       "      <th>areakm2</th>\n",
       "      <th>ariamin</th>\n",
       "      <th>ariamax</th>\n",
       "      <th>ariaavg</th>\n",
       "      <th>commercialkm2</th>\n",
       "      <th>...</th>\n",
       "      <th>presentationstoemergencydepartments201213</th>\n",
       "      <th>traveltimetonearestpublichospitalwithemergencydepartment</th>\n",
       "      <th>presentationstoemergencydepartmentsduetoinjury</th>\n",
       "      <th>category45emergencydepartmentpresentations</th>\n",
       "      <th>numberofdwellings</th>\n",
       "      <th>population</th>\n",
       "      <th>locationx</th>\n",
       "      <th>locationy</th>\n",
       "      <th>absremotenesscategory</th>\n",
       "      <th>crime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>392.000000</td>\n",
       "      <td>3.920000e+02</td>\n",
       "      <td>3.920000e+02</td>\n",
       "      <td>392.000000</td>\n",
       "      <td>392.000000</td>\n",
       "      <td>392.000000</td>\n",
       "      <td>392.000000</td>\n",
       "      <td>392.000000</td>\n",
       "      <td>392.000000</td>\n",
       "      <td>392.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>392.000000</td>\n",
       "      <td>392.000000</td>\n",
       "      <td>392.000000</td>\n",
       "      <td>392.000000</td>\n",
       "      <td>392.000000</td>\n",
       "      <td>392.000000</td>\n",
       "      <td>392.000000</td>\n",
       "      <td>392.000000</td>\n",
       "      <td>392.000000</td>\n",
       "      <td>392.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2017.000000</td>\n",
       "      <td>4.479159e+07</td>\n",
       "      <td>6.974263e+05</td>\n",
       "      <td>8807.719388</td>\n",
       "      <td>87.531777</td>\n",
       "      <td>2427.304028</td>\n",
       "      <td>0.638564</td>\n",
       "      <td>0.915607</td>\n",
       "      <td>0.765623</td>\n",
       "      <td>0.015513</td>\n",
       "      <td>...</td>\n",
       "      <td>0.270842</td>\n",
       "      <td>25.794808</td>\n",
       "      <td>0.248449</td>\n",
       "      <td>0.567065</td>\n",
       "      <td>40813.517857</td>\n",
       "      <td>101211.071429</td>\n",
       "      <td>-0.204235</td>\n",
       "      <td>26.559082</td>\n",
       "      <td>0.589286</td>\n",
       "      <td>8604.032054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.002556</td>\n",
       "      <td>3.648647e+07</td>\n",
       "      <td>4.668703e+05</td>\n",
       "      <td>6836.585681</td>\n",
       "      <td>89.737139</td>\n",
       "      <td>4388.218811</td>\n",
       "      <td>0.926171</td>\n",
       "      <td>1.249630</td>\n",
       "      <td>1.076033</td>\n",
       "      <td>0.024319</td>\n",
       "      <td>...</td>\n",
       "      <td>0.117438</td>\n",
       "      <td>23.200132</td>\n",
       "      <td>0.039385</td>\n",
       "      <td>0.076904</td>\n",
       "      <td>24837.496782</td>\n",
       "      <td>67489.684405</td>\n",
       "      <td>103.654912</td>\n",
       "      <td>82.711984</td>\n",
       "      <td>0.702344</td>\n",
       "      <td>3506.884396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2014.000000</td>\n",
       "      <td>1.892293e+06</td>\n",
       "      <td>1.587500e+05</td>\n",
       "      <td>387.000000</td>\n",
       "      <td>4.897709</td>\n",
       "      <td>20.822930</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050232</td>\n",
       "      <td>3.930699</td>\n",
       "      <td>0.140255</td>\n",
       "      <td>0.399250</td>\n",
       "      <td>4874.000000</td>\n",
       "      <td>9873.000000</td>\n",
       "      <td>-310.285714</td>\n",
       "      <td>-81.599301</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3076.800763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2015.000000</td>\n",
       "      <td>1.182050e+07</td>\n",
       "      <td>3.520722e+05</td>\n",
       "      <td>3061.750000</td>\n",
       "      <td>20.246923</td>\n",
       "      <td>79.778887</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.180694</td>\n",
       "      <td>8.626692</td>\n",
       "      <td>0.218529</td>\n",
       "      <td>0.513066</td>\n",
       "      <td>18526.750000</td>\n",
       "      <td>41610.000000</td>\n",
       "      <td>-23.545417</td>\n",
       "      <td>-15.651445</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6471.102274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2017.000000</td>\n",
       "      <td>3.108051e+07</td>\n",
       "      <td>5.853513e+05</td>\n",
       "      <td>8011.000000</td>\n",
       "      <td>52.602954</td>\n",
       "      <td>667.579973</td>\n",
       "      <td>0.064858</td>\n",
       "      <td>0.193099</td>\n",
       "      <td>0.117857</td>\n",
       "      <td>0.002763</td>\n",
       "      <td>...</td>\n",
       "      <td>0.252941</td>\n",
       "      <td>16.079150</td>\n",
       "      <td>0.256317</td>\n",
       "      <td>0.567085</td>\n",
       "      <td>40520.000000</td>\n",
       "      <td>94681.500000</td>\n",
       "      <td>5.389039</td>\n",
       "      <td>1.222753</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8194.577278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2019.000000</td>\n",
       "      <td>6.885112e+07</td>\n",
       "      <td>9.037315e+05</td>\n",
       "      <td>12515.500000</td>\n",
       "      <td>131.271874</td>\n",
       "      <td>3206.892301</td>\n",
       "      <td>1.088661</td>\n",
       "      <td>1.512202</td>\n",
       "      <td>1.384535</td>\n",
       "      <td>0.025111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.375373</td>\n",
       "      <td>34.781852</td>\n",
       "      <td>0.278871</td>\n",
       "      <td>0.616169</td>\n",
       "      <td>59403.000000</td>\n",
       "      <td>151932.500000</td>\n",
       "      <td>27.746864</td>\n",
       "      <td>40.975396</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10228.073289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2020.000000</td>\n",
       "      <td>1.430457e+08</td>\n",
       "      <td>2.841161e+06</td>\n",
       "      <td>37886.000000</td>\n",
       "      <td>384.960766</td>\n",
       "      <td>23359.313312</td>\n",
       "      <td>3.272194</td>\n",
       "      <td>4.383425</td>\n",
       "      <td>3.737190</td>\n",
       "      <td>0.127473</td>\n",
       "      <td>...</td>\n",
       "      <td>0.553260</td>\n",
       "      <td>96.843507</td>\n",
       "      <td>0.322547</td>\n",
       "      <td>0.725373</td>\n",
       "      <td>107828.000000</td>\n",
       "      <td>298909.000000</td>\n",
       "      <td>274.239407</td>\n",
       "      <td>343.714443</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>25932.263717</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 84 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              year           egm  medianhouseprice  offencecount  \\\n",
       "count   392.000000  3.920000e+02      3.920000e+02    392.000000   \n",
       "mean   2017.000000  4.479159e+07      6.974263e+05   8807.719388   \n",
       "std       2.002556  3.648647e+07      4.668703e+05   6836.585681   \n",
       "min    2014.000000  1.892293e+06      1.587500e+05    387.000000   \n",
       "25%    2015.000000  1.182050e+07      3.520722e+05   3061.750000   \n",
       "50%    2017.000000  3.108051e+07      5.853513e+05   8011.000000   \n",
       "75%    2019.000000  6.885112e+07      9.037315e+05  12515.500000   \n",
       "max    2020.000000  1.430457e+08      2.841161e+06  37886.000000   \n",
       "\n",
       "       traveltimetogpominutes       areakm2     ariamin     ariamax  \\\n",
       "count              392.000000    392.000000  392.000000  392.000000   \n",
       "mean                87.531777   2427.304028    0.638564    0.915607   \n",
       "std                 89.737139   4388.218811    0.926171    1.249630   \n",
       "min                  4.897709     20.822930    0.000000    0.000000   \n",
       "25%                 20.246923     79.778887    0.000000    0.000000   \n",
       "50%                 52.602954    667.579973    0.064858    0.193099   \n",
       "75%                131.271874   3206.892301    1.088661    1.512202   \n",
       "max                384.960766  23359.313312    3.272194    4.383425   \n",
       "\n",
       "          ariaavg  commercialkm2  ...  \\\n",
       "count  392.000000     392.000000  ...   \n",
       "mean     0.765623       0.015513  ...   \n",
       "std      1.076033       0.024319  ...   \n",
       "min      0.000000       0.000052  ...   \n",
       "25%      0.000000       0.000368  ...   \n",
       "50%      0.117857       0.002763  ...   \n",
       "75%      1.384535       0.025111  ...   \n",
       "max      3.737190       0.127473  ...   \n",
       "\n",
       "       presentationstoemergencydepartments201213  \\\n",
       "count                                 392.000000   \n",
       "mean                                    0.270842   \n",
       "std                                     0.117438   \n",
       "min                                     0.050232   \n",
       "25%                                     0.180694   \n",
       "50%                                     0.252941   \n",
       "75%                                     0.375373   \n",
       "max                                     0.553260   \n",
       "\n",
       "       traveltimetonearestpublichospitalwithemergencydepartment  \\\n",
       "count                                         392.000000          \n",
       "mean                                           25.794808          \n",
       "std                                            23.200132          \n",
       "min                                             3.930699          \n",
       "25%                                             8.626692          \n",
       "50%                                            16.079150          \n",
       "75%                                            34.781852          \n",
       "max                                            96.843507          \n",
       "\n",
       "       presentationstoemergencydepartmentsduetoinjury  \\\n",
       "count                                      392.000000   \n",
       "mean                                         0.248449   \n",
       "std                                          0.039385   \n",
       "min                                          0.140255   \n",
       "25%                                          0.218529   \n",
       "50%                                          0.256317   \n",
       "75%                                          0.278871   \n",
       "max                                          0.322547   \n",
       "\n",
       "       category45emergencydepartmentpresentations  numberofdwellings  \\\n",
       "count                                  392.000000         392.000000   \n",
       "mean                                     0.567065       40813.517857   \n",
       "std                                      0.076904       24837.496782   \n",
       "min                                      0.399250        4874.000000   \n",
       "25%                                      0.513066       18526.750000   \n",
       "50%                                      0.567085       40520.000000   \n",
       "75%                                      0.616169       59403.000000   \n",
       "max                                      0.725373      107828.000000   \n",
       "\n",
       "          population   locationx   locationy  absremotenesscategory  \\\n",
       "count     392.000000  392.000000  392.000000             392.000000   \n",
       "mean   101211.071429   -0.204235   26.559082               0.589286   \n",
       "std     67489.684405  103.654912   82.711984               0.702344   \n",
       "min      9873.000000 -310.285714  -81.599301               0.000000   \n",
       "25%     41610.000000  -23.545417  -15.651445               0.000000   \n",
       "50%     94681.500000    5.389039    1.222753               0.000000   \n",
       "75%    151932.500000   27.746864   40.975396               1.000000   \n",
       "max    298909.000000  274.239407  343.714443               2.000000   \n",
       "\n",
       "              crime  \n",
       "count    392.000000  \n",
       "mean    8604.032054  \n",
       "std     3506.884396  \n",
       "min     3076.800763  \n",
       "25%     6471.102274  \n",
       "50%     8194.577278  \n",
       "75%    10228.073289  \n",
       "max    25932.263717  \n",
       "\n",
       "[8 rows x 84 columns]"
      ]
     },
     "execution_count": 906,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./final.csv', index_col=0)\n",
    "data['crime'] = data['Rate per 100,000 population']\n",
    "data = data.drop(columns=['Rate per 100,000 population'])\n",
    "\n",
    "def normalize(col):\n",
    "    col = ''.join(col.split())\n",
    "    col = ''.join(e for e in col if e.isalnum())\n",
    "    out: str = col.replace(',','_').lower()\n",
    "    if out[0].isdigit():\n",
    "        out = '_' + out\n",
    "    return out\n",
    "\n",
    "data.rename(columns=normalize, inplace=True)\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 907,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lga</th>\n",
       "      <th>year</th>\n",
       "      <th>egm</th>\n",
       "      <th>medianhouseprice</th>\n",
       "      <th>traveltimetogpominutes</th>\n",
       "      <th>areakm2</th>\n",
       "      <th>ariamin</th>\n",
       "      <th>ariamax</th>\n",
       "      <th>ariaavg</th>\n",
       "      <th>commercialkm2</th>\n",
       "      <th>...</th>\n",
       "      <th>numberofdwellings</th>\n",
       "      <th>population</th>\n",
       "      <th>locationx</th>\n",
       "      <th>locationy</th>\n",
       "      <th>absremotenesscategory</th>\n",
       "      <th>distance</th>\n",
       "      <th>last_crime</th>\n",
       "      <th>last_house</th>\n",
       "      <th>last_egm</th>\n",
       "      <th>crime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>whittlesea</td>\n",
       "      <td>2015</td>\n",
       "      <td>1.091612e+08</td>\n",
       "      <td>3.864022e+05</td>\n",
       "      <td>34.862554</td>\n",
       "      <td>590.075860</td>\n",
       "      <td>0.007974</td>\n",
       "      <td>0.056596</td>\n",
       "      <td>0.022594</td>\n",
       "      <td>0.005186</td>\n",
       "      <td>...</td>\n",
       "      <td>53907.0</td>\n",
       "      <td>166996.0</td>\n",
       "      <td>16.070609</td>\n",
       "      <td>18.525154</td>\n",
       "      <td>0</td>\n",
       "      <td>24.524392</td>\n",
       "      <td>7233.141209</td>\n",
       "      <td>3.567570e+05</td>\n",
       "      <td>1.035006e+08</td>\n",
       "      <td>6975.468257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>northerngrampians</td>\n",
       "      <td>2015</td>\n",
       "      <td>1.003788e+07</td>\n",
       "      <td>1.590000e+05</td>\n",
       "      <td>179.410340</td>\n",
       "      <td>6720.196354</td>\n",
       "      <td>2.135649</td>\n",
       "      <td>2.837918</td>\n",
       "      <td>2.452597</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>...</td>\n",
       "      <td>7094.0</td>\n",
       "      <td>13042.0</td>\n",
       "      <td>-179.798887</td>\n",
       "      <td>102.227446</td>\n",
       "      <td>2</td>\n",
       "      <td>206.828650</td>\n",
       "      <td>7947.694659</td>\n",
       "      <td>1.587500e+05</td>\n",
       "      <td>1.035065e+07</td>\n",
       "      <td>9876.331158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>greatergeelong</td>\n",
       "      <td>2015</td>\n",
       "      <td>1.130210e+08</td>\n",
       "      <td>4.230712e+05</td>\n",
       "      <td>61.820207</td>\n",
       "      <td>1389.430557</td>\n",
       "      <td>0.152898</td>\n",
       "      <td>0.224843</td>\n",
       "      <td>0.182097</td>\n",
       "      <td>0.002401</td>\n",
       "      <td>...</td>\n",
       "      <td>107828.0</td>\n",
       "      <td>249716.0</td>\n",
       "      <td>-49.407904</td>\n",
       "      <td>-36.376751</td>\n",
       "      <td>0</td>\n",
       "      <td>61.354779</td>\n",
       "      <td>8127.107630</td>\n",
       "      <td>4.084374e+05</td>\n",
       "      <td>1.116281e+08</td>\n",
       "      <td>8950.482127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>colacotway</td>\n",
       "      <td>2015</td>\n",
       "      <td>1.026330e+07</td>\n",
       "      <td>3.823333e+05</td>\n",
       "      <td>137.416278</td>\n",
       "      <td>3232.099823</td>\n",
       "      <td>1.273625</td>\n",
       "      <td>1.806754</td>\n",
       "      <td>1.531375</td>\n",
       "      <td>0.000364</td>\n",
       "      <td>...</td>\n",
       "      <td>11821.0</td>\n",
       "      <td>21429.0</td>\n",
       "      <td>-114.485347</td>\n",
       "      <td>-75.055345</td>\n",
       "      <td>1</td>\n",
       "      <td>136.894848</td>\n",
       "      <td>7259.476598</td>\n",
       "      <td>3.684167e+05</td>\n",
       "      <td>1.007489e+07</td>\n",
       "      <td>7899.199246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>moorabool</td>\n",
       "      <td>2015</td>\n",
       "      <td>1.057564e+07</td>\n",
       "      <td>3.560000e+05</td>\n",
       "      <td>58.368445</td>\n",
       "      <td>2142.863230</td>\n",
       "      <td>0.331739</td>\n",
       "      <td>0.880712</td>\n",
       "      <td>0.598316</td>\n",
       "      <td>0.000394</td>\n",
       "      <td>...</td>\n",
       "      <td>18640.0</td>\n",
       "      <td>47165.0</td>\n",
       "      <td>-63.629211</td>\n",
       "      <td>23.520312</td>\n",
       "      <td>1</td>\n",
       "      <td>67.837170</td>\n",
       "      <td>6183.609090</td>\n",
       "      <td>3.395000e+05</td>\n",
       "      <td>1.030988e+07</td>\n",
       "      <td>6857.124858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>maribyrnong</td>\n",
       "      <td>2020</td>\n",
       "      <td>4.224321e+07</td>\n",
       "      <td>8.882343e+05</td>\n",
       "      <td>11.629266</td>\n",
       "      <td>31.347530</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.068430</td>\n",
       "      <td>...</td>\n",
       "      <td>33248.0</td>\n",
       "      <td>81443.0</td>\n",
       "      <td>-7.275384</td>\n",
       "      <td>1.522394</td>\n",
       "      <td>0</td>\n",
       "      <td>7.432960</td>\n",
       "      <td>9949.698189</td>\n",
       "      <td>8.490697e+05</td>\n",
       "      <td>5.725792e+07</td>\n",
       "      <td>10239.549084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>stonnington</td>\n",
       "      <td>2020</td>\n",
       "      <td>1.411828e+07</td>\n",
       "      <td>2.841161e+06</td>\n",
       "      <td>9.937739</td>\n",
       "      <td>23.986985</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066525</td>\n",
       "      <td>...</td>\n",
       "      <td>46028.0</td>\n",
       "      <td>96855.0</td>\n",
       "      <td>4.834074</td>\n",
       "      <td>-4.292877</td>\n",
       "      <td>0</td>\n",
       "      <td>6.465065</td>\n",
       "      <td>10326.889279</td>\n",
       "      <td>2.535312e+06</td>\n",
       "      <td>1.986235e+07</td>\n",
       "      <td>10291.270757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>gleneira</td>\n",
       "      <td>2020</td>\n",
       "      <td>5.402530e+07</td>\n",
       "      <td>1.516358e+06</td>\n",
       "      <td>15.409791</td>\n",
       "      <td>41.586761</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032422</td>\n",
       "      <td>...</td>\n",
       "      <td>62435.0</td>\n",
       "      <td>150761.0</td>\n",
       "      <td>6.103827</td>\n",
       "      <td>-8.569276</td>\n",
       "      <td>0</td>\n",
       "      <td>10.520894</td>\n",
       "      <td>4799.397152</td>\n",
       "      <td>1.430137e+06</td>\n",
       "      <td>7.424468e+07</td>\n",
       "      <td>5086.773226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>bayside</td>\n",
       "      <td>2020</td>\n",
       "      <td>1.022713e+07</td>\n",
       "      <td>1.744736e+06</td>\n",
       "      <td>20.118347</td>\n",
       "      <td>35.882194</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023797</td>\n",
       "      <td>...</td>\n",
       "      <td>38495.0</td>\n",
       "      <td>97337.0</td>\n",
       "      <td>5.883758</td>\n",
       "      <td>-14.204648</td>\n",
       "      <td>0</td>\n",
       "      <td>15.375000</td>\n",
       "      <td>4849.326535</td>\n",
       "      <td>1.572118e+06</td>\n",
       "      <td>1.380787e+07</td>\n",
       "      <td>5319.088156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>mooneevalley</td>\n",
       "      <td>2020</td>\n",
       "      <td>5.749777e+07</td>\n",
       "      <td>1.261210e+06</td>\n",
       "      <td>13.016887</td>\n",
       "      <td>50.700036</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.040354</td>\n",
       "      <td>...</td>\n",
       "      <td>46767.0</td>\n",
       "      <td>115655.0</td>\n",
       "      <td>-5.548091</td>\n",
       "      <td>7.139844</td>\n",
       "      <td>0</td>\n",
       "      <td>9.042051</td>\n",
       "      <td>6550.321978</td>\n",
       "      <td>1.209735e+06</td>\n",
       "      <td>7.765076e+07</td>\n",
       "      <td>6627.703374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>336 rows Ã— 88 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   lga  year           egm  medianhouseprice  \\\n",
       "0           whittlesea  2015  1.091612e+08      3.864022e+05   \n",
       "1    northerngrampians  2015  1.003788e+07      1.590000e+05   \n",
       "2       greatergeelong  2015  1.130210e+08      4.230712e+05   \n",
       "3           colacotway  2015  1.026330e+07      3.823333e+05   \n",
       "4            moorabool  2015  1.057564e+07      3.560000e+05   \n",
       "..                 ...   ...           ...               ...   \n",
       "331        maribyrnong  2020  4.224321e+07      8.882343e+05   \n",
       "332        stonnington  2020  1.411828e+07      2.841161e+06   \n",
       "333           gleneira  2020  5.402530e+07      1.516358e+06   \n",
       "334            bayside  2020  1.022713e+07      1.744736e+06   \n",
       "335       mooneevalley  2020  5.749777e+07      1.261210e+06   \n",
       "\n",
       "     traveltimetogpominutes      areakm2   ariamin   ariamax   ariaavg  \\\n",
       "0                 34.862554   590.075860  0.007974  0.056596  0.022594   \n",
       "1                179.410340  6720.196354  2.135649  2.837918  2.452597   \n",
       "2                 61.820207  1389.430557  0.152898  0.224843  0.182097   \n",
       "3                137.416278  3232.099823  1.273625  1.806754  1.531375   \n",
       "4                 58.368445  2142.863230  0.331739  0.880712  0.598316   \n",
       "..                      ...          ...       ...       ...       ...   \n",
       "331               11.629266    31.347530  0.000000  0.000000  0.000000   \n",
       "332                9.937739    23.986985  0.000000  0.000000  0.000000   \n",
       "333               15.409791    41.586761  0.000000  0.000000  0.000000   \n",
       "334               20.118347    35.882194  0.000000  0.000000  0.000000   \n",
       "335               13.016887    50.700036  0.000000  0.000000  0.000000   \n",
       "\n",
       "     commercialkm2  ...  numberofdwellings  population   locationx  \\\n",
       "0         0.005186  ...            53907.0    166996.0   16.070609   \n",
       "1         0.000128  ...             7094.0     13042.0 -179.798887   \n",
       "2         0.002401  ...           107828.0    249716.0  -49.407904   \n",
       "3         0.000364  ...            11821.0     21429.0 -114.485347   \n",
       "4         0.000394  ...            18640.0     47165.0  -63.629211   \n",
       "..             ...  ...                ...         ...         ...   \n",
       "331       0.068430  ...            33248.0     81443.0   -7.275384   \n",
       "332       0.066525  ...            46028.0     96855.0    4.834074   \n",
       "333       0.032422  ...            62435.0    150761.0    6.103827   \n",
       "334       0.023797  ...            38495.0     97337.0    5.883758   \n",
       "335       0.040354  ...            46767.0    115655.0   -5.548091   \n",
       "\n",
       "      locationy  absremotenesscategory    distance    last_crime  \\\n",
       "0     18.525154                      0   24.524392   7233.141209   \n",
       "1    102.227446                      2  206.828650   7947.694659   \n",
       "2    -36.376751                      0   61.354779   8127.107630   \n",
       "3    -75.055345                      1  136.894848   7259.476598   \n",
       "4     23.520312                      1   67.837170   6183.609090   \n",
       "..          ...                    ...         ...           ...   \n",
       "331    1.522394                      0    7.432960   9949.698189   \n",
       "332   -4.292877                      0    6.465065  10326.889279   \n",
       "333   -8.569276                      0   10.520894   4799.397152   \n",
       "334  -14.204648                      0   15.375000   4849.326535   \n",
       "335    7.139844                      0    9.042051   6550.321978   \n",
       "\n",
       "       last_house      last_egm         crime  \n",
       "0    3.567570e+05  1.035006e+08   6975.468257  \n",
       "1    1.587500e+05  1.035065e+07   9876.331158  \n",
       "2    4.084374e+05  1.116281e+08   8950.482127  \n",
       "3    3.684167e+05  1.007489e+07   7899.199246  \n",
       "4    3.395000e+05  1.030988e+07   6857.124858  \n",
       "..            ...           ...           ...  \n",
       "331  8.490697e+05  5.725792e+07  10239.549084  \n",
       "332  2.535312e+06  1.986235e+07  10291.270757  \n",
       "333  1.430137e+06  7.424468e+07   5086.773226  \n",
       "334  1.572118e+06  1.380787e+07   5319.088156  \n",
       "335  1.209735e+06  7.765076e+07   6627.703374  \n",
       "\n",
       "[336 rows x 88 columns]"
      ]
     },
     "execution_count": 907,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual = data[data['year'].isin(list(range(2015, 2021)))]\n",
    "actual = actual.copy()\n",
    "\n",
    "# insert last year\n",
    "for i, row in actual.iterrows():\n",
    "    last = data[(data['year'] == row['year']-1) & (data['lga'] == row['lga'])].copy()\n",
    "    distance = np.sqrt(row['locationx'] ** 2 + row['locationy'] ** 2)\n",
    "    actual.loc[i, 'distance'] = distance\n",
    "    actual.loc[i, 'last_crime'] = last['crime'].values[0]\n",
    "    actual.loc[i, 'last_house'] = last['medianhouseprice'].values[0]\n",
    "    actual.loc[i, 'last_egm'] = last['egm'].values[0]\n",
    "\n",
    "actual = actual.reset_index(drop=True)\n",
    "actual = actual.drop(columns=['offencecount'], axis=1)\n",
    "cr = actual.pop('crime')\n",
    "actual.insert(actual.shape[1], \"crime\", cr)\n",
    "actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1092,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>last_crime</th>\n",
       "      <th>distance</th>\n",
       "      <th>last_egm</th>\n",
       "      <th>last_house</th>\n",
       "      <th>crime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7233.141209</td>\n",
       "      <td>24.524392</td>\n",
       "      <td>1.035006e+08</td>\n",
       "      <td>3.567570e+05</td>\n",
       "      <td>6975.468257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7947.694659</td>\n",
       "      <td>206.828650</td>\n",
       "      <td>1.035065e+07</td>\n",
       "      <td>1.587500e+05</td>\n",
       "      <td>9876.331158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8127.107630</td>\n",
       "      <td>61.354779</td>\n",
       "      <td>1.116281e+08</td>\n",
       "      <td>4.084374e+05</td>\n",
       "      <td>8950.482127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7259.476598</td>\n",
       "      <td>136.894848</td>\n",
       "      <td>1.007489e+07</td>\n",
       "      <td>3.684167e+05</td>\n",
       "      <td>7899.199246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6183.609090</td>\n",
       "      <td>67.837170</td>\n",
       "      <td>1.030988e+07</td>\n",
       "      <td>3.395000e+05</td>\n",
       "      <td>6857.124858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9949.698189</td>\n",
       "      <td>7.432960</td>\n",
       "      <td>5.725792e+07</td>\n",
       "      <td>8.490697e+05</td>\n",
       "      <td>10239.549084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10326.889279</td>\n",
       "      <td>6.465065</td>\n",
       "      <td>1.986235e+07</td>\n",
       "      <td>2.535312e+06</td>\n",
       "      <td>10291.270757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4799.397152</td>\n",
       "      <td>10.520894</td>\n",
       "      <td>7.424468e+07</td>\n",
       "      <td>1.430137e+06</td>\n",
       "      <td>5086.773226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4849.326535</td>\n",
       "      <td>15.375000</td>\n",
       "      <td>1.380787e+07</td>\n",
       "      <td>1.572118e+06</td>\n",
       "      <td>5319.088156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6550.321978</td>\n",
       "      <td>9.042051</td>\n",
       "      <td>7.765076e+07</td>\n",
       "      <td>1.209735e+06</td>\n",
       "      <td>6627.703374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>336 rows Ã— 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1    2    3    4    5    6    7    8    9  ...   51   52   53  \\\n",
       "0    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  1.0  0.0  0.0   \n",
       "1    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "2    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "3    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "4    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "..   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "331  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "332  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "333  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "334  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "335  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "\n",
       "      54   55    last_crime    distance      last_egm    last_house  \\\n",
       "0    0.0  0.0   7233.141209   24.524392  1.035006e+08  3.567570e+05   \n",
       "1    0.0  0.0   7947.694659  206.828650  1.035065e+07  1.587500e+05   \n",
       "2    0.0  0.0   8127.107630   61.354779  1.116281e+08  4.084374e+05   \n",
       "3    0.0  0.0   7259.476598  136.894848  1.007489e+07  3.684167e+05   \n",
       "4    0.0  0.0   6183.609090   67.837170  1.030988e+07  3.395000e+05   \n",
       "..   ...  ...           ...         ...           ...           ...   \n",
       "331  0.0  0.0   9949.698189    7.432960  5.725792e+07  8.490697e+05   \n",
       "332  0.0  0.0  10326.889279    6.465065  1.986235e+07  2.535312e+06   \n",
       "333  0.0  0.0   4799.397152   10.520894  7.424468e+07  1.430137e+06   \n",
       "334  0.0  0.0   4849.326535   15.375000  1.380787e+07  1.572118e+06   \n",
       "335  0.0  0.0   6550.321978    9.042051  7.765076e+07  1.209735e+06   \n",
       "\n",
       "            crime  \n",
       "0     6975.468257  \n",
       "1     9876.331158  \n",
       "2     8950.482127  \n",
       "3     7899.199246  \n",
       "4     6857.124858  \n",
       "..            ...  \n",
       "331  10239.549084  \n",
       "332  10291.270757  \n",
       "333   5086.773226  \n",
       "334   5319.088156  \n",
       "335   6627.703374  \n",
       "\n",
       "[336 rows x 61 columns]"
      ]
     },
     "execution_count": 1092,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one hot encode\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "\n",
    "\n",
    "encoder = OneHotEncoder()\n",
    "encoded = actual.copy()\n",
    "encoded = encoded[[\n",
    "    'lga',\n",
    "    'last_crime',\n",
    "    'distance',\n",
    "    'last_egm', \n",
    "    'last_house', \n",
    "    'crime'\n",
    "  ]]\n",
    "\n",
    "new_ = encoded.select_dtypes(include=[np.number])\n",
    "\n",
    "idx = new_.columns.get_loc('crime')\n",
    "print(idx)\n",
    "# year_idx = new_.columns.get_loc('year')\n",
    "# print(year_idx)\n",
    "last_idx = new_.columns.get_loc('last_crime')\n",
    "\n",
    "# scaler = MinMaxScaler(feature_range=(0,1))\n",
    "# new_[new_.columns] = scaler.fit_transform(new_[new_.columns])\n",
    "# standardize all\n",
    "\n",
    "out = encoder.fit_transform(encoded[['lga']])\n",
    "lga = pd.DataFrame(out.toarray())\n",
    "\n",
    "new = pd.concat([lga, new_], axis=1)\n",
    "new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1093,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(235, 60) (235, 1)\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.2151, 0.2948, 0.3122, 0.0679]])\n",
      "tensor([[0.1856]])\n",
      "Using cuda device\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=60, out_features=32, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=32, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# ml model\n",
    "\n",
    "\n",
    "# one hot encode\n",
    "\n",
    "state = 72\n",
    "train_data: pd.DataFrame = new.sample(frac=0.7, random_state=state)\n",
    "test_data = new.drop(train_data.index)\n",
    "\n",
    "scaler_x = MinMaxScaler(feature_range=(0,1))\n",
    "scaler_y = MinMaxScaler(feature_range=(0,1))\n",
    "\n",
    "train_y = train_data['crime'].values\n",
    "train_x = train_data.drop('crime', axis=1).values\n",
    "test_y = test_data['crime'].values\n",
    "test_x = test_data.drop('crime', axis=1).values\n",
    "\n",
    "\n",
    "scaler_x.fit(np.vstack((train_x, test_x)))\n",
    "scaler_y.fit(train_y.reshape(-1, 1))\n",
    "\n",
    "train_x = scaler_x.transform(train_x)\n",
    "train_y = scaler_y.transform(train_y.reshape(-1, 1))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "test_y = scaler_y.transform(test_y.reshape(-1, 1))\n",
    "test_x = scaler_x.transform(test_x)\n",
    "\n",
    "print(train_x.shape, train_y.shape)\n",
    "\n",
    "batch_size = 1\n",
    "\n",
    "train = data_utils.TensorDataset(torch.Tensor(train_x), torch.Tensor(train_y))\n",
    "test = data_utils.TensorDataset(torch.Tensor(test_x), torch.Tensor(test_y))\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(X)\n",
    "    print(y)\n",
    "    # print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    # print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break\n",
    "\n",
    "\n",
    "# Get cpu, gpu or mps device for training.\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(train_x.shape[1], 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1094,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "# optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4)\n",
    "\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # if batch % 10 == 0:\n",
    "            # loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            # print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    # print(f\"Avg loss: {test_loss:>8f} \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1095,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse_null 889.8375480998527 test 3398.81, train 3431.41\n",
      "mse_null 889.8375480998529 test 3351.99, train 3365.40\n",
      "mse_null 889.8375480998532 test 3302.68, train 3315.47\n",
      "mse_null 889.8375480998529 test 3263.00, train 3274.20\n",
      "mse_null 889.8375480998532 test 3206.67, train 3159.55\n",
      "mse_null 889.8375480998532 test 3116.89, train 3074.84\n",
      "mse_null 889.8375480998528 test 3040.13, train 2965.84\n",
      "mse_null 889.8375480998529 test 2949.31, train 2860.69\n",
      "mse_null 889.837548099853 test 2948.69, train 2853.33\n",
      "mse_null 889.8375480998529 test 2753.55, train 2599.97\n",
      "mse_null 889.8375480998528 test 2638.73, train 2464.81\n",
      "mse_null 889.8375480998529 test 2451.12, train 2253.64\n",
      "mse_null 889.8375480998532 test 2368.36, train 2133.86\n",
      "mse_null 889.8375480998529 test 2138.25, train 1904.78\n",
      "mse_null 889.8375480998529 test 1989.33, train 1737.81\n",
      "mse_null 889.8375480998528 test 1845.06, train 1593.22\n",
      "mse_null 889.8375480998529 test 1717.91, train 1451.79\n",
      "mse_null 889.8375480998528 test 1603.39, train 1334.34\n",
      "mse_null 889.8375480998532 test 1542.09, train 1242.02\n",
      "mse_null 889.8375480998529 test 1430.83, train 1153.09\n",
      "mse_null 889.8375480998529 test 1368.28, train 1084.20\n",
      "mse_null 889.8375480998529 test 1322.36, train 1027.83\n",
      "mse_null 889.8375480998529 test 1289.52, train 980.78\n",
      "mse_null 889.837548099853 test 1259.88, train 943.25\n",
      "mse_null 889.8375480998529 test 1232.24, train 910.07\n",
      "mse_null 889.8375480998529 test 1233.32, train 892.26\n",
      "mse_null 889.8375480998529 test 1190.43, train 857.68\n",
      "mse_null 889.8375480998529 test 1199.03, train 848.24\n",
      "mse_null 889.837548099853 test 1152.39, train 817.97\n",
      "mse_null 889.8375480998528 test 1147.54, train 802.71\n",
      "mse_null 889.837548099853 test 1135.52, train 788.32\n",
      "mse_null 889.837548099853 test 1137.36, train 783.58\n",
      "mse_null 889.8375480998527 test 1109.51, train 763.63\n",
      "mse_null 889.8375480998529 test 1090.83, train 760.09\n",
      "mse_null 889.8375480998529 test 1080.15, train 748.66\n",
      "mse_null 889.8375480998529 test 1072.44, train 741.05\n",
      "mse_null 889.8375480998529 test 1066.88, train 745.02\n",
      "mse_null 889.8375480998529 test 1076.50, train 732.11\n",
      "mse_null 889.837548099853 test 1051.32, train 719.98\n",
      "mse_null 889.837548099853 test 1051.65, train 739.93\n",
      "mse_null 889.8375480998528 test 1045.99, train 709.24\n",
      "mse_null 889.8375480998529 test 1042.44, train 706.17\n",
      "mse_null 889.8375480998529 test 1060.48, train 724.32\n",
      "mse_null 889.8375480998529 test 1033.81, train 699.29\n",
      "mse_null 889.8375480998529 test 1037.89, train 703.62\n",
      "mse_null 889.8375480998529 test 1026.42, train 693.54\n",
      "mse_null 889.8375480998529 test 1024.74, train 692.75\n",
      "mse_null 889.8375480998532 test 1017.62, train 688.81\n",
      "mse_null 889.837548099853 test 1011.69, train 691.73\n",
      "mse_null 889.8375480998529 test 1010.19, train 690.94\n",
      "mse_null 889.837548099853 test 1006.63, train 684.20\n",
      "mse_null 889.8375480998529 test 1005.23, train 682.05\n",
      "mse_null 889.8375480998529 test 1018.06, train 698.12\n",
      "mse_null 889.8375480998529 test 998.65, train 684.55\n",
      "mse_null 889.8375480998529 test 995.92, train 678.55\n",
      "mse_null 889.8375480998529 test 998.82, train 681.54\n",
      "mse_null 889.8375480998529 test 991.04, train 681.96\n",
      "mse_null 889.8375480998532 test 993.47, train 679.35\n",
      "mse_null 889.8375480998529 test 987.85, train 680.85\n",
      "mse_null 889.8375480998529 test 984.76, train 674.37\n",
      "mse_null 889.8375480998529 test 984.82, train 674.76\n",
      "mse_null 889.8375480998532 test 1008.47, train 722.11\n",
      "mse_null 889.8375480998528 test 984.37, train 673.95\n",
      "mse_null 889.8375480998529 test 978.27, train 671.78\n",
      "mse_null 889.837548099853 test 1004.92, train 704.24\n",
      "mse_null 889.8375480998527 test 977.21, train 670.85\n",
      "mse_null 889.837548099853 test 986.88, train 682.74\n",
      "mse_null 889.8375480998528 test 987.62, train 689.99\n",
      "mse_null 889.8375480998529 test 1027.15, train 736.74\n",
      "mse_null 889.837548099853 test 976.18, train 673.12\n",
      "mse_null 889.8375480998528 test 977.03, train 681.24\n",
      "mse_null 889.837548099853 test 968.80, train 672.22\n",
      "mse_null 889.8375480998529 test 1020.81, train 738.92\n",
      "mse_null 889.8375480998528 test 966.25, train 673.66\n",
      "mse_null 889.837548099853 test 959.97, train 667.19\n",
      "mse_null 889.8375480998529 test 964.90, train 675.02\n",
      "mse_null 889.8375480998529 test 964.81, train 669.49\n",
      "mse_null 889.837548099853 test 976.84, train 687.63\n",
      "mse_null 889.8375480998529 test 966.00, train 673.72\n",
      "mse_null 889.8375480998529 test 959.32, train 665.61\n",
      "mse_null 889.8375480998529 test 960.47, train 666.64\n",
      "mse_null 889.837548099853 test 977.64, train 695.65\n",
      "mse_null 889.8375480998529 test 957.66, train 664.77\n",
      "mse_null 889.8375480998528 test 960.88, train 671.76\n",
      "mse_null 889.8375480998529 test 962.71, train 676.49\n",
      "mse_null 889.8375480998529 test 957.46, train 666.18\n",
      "mse_null 889.8375480998529 test 957.68, train 667.04\n",
      "mse_null 889.8375480998529 test 979.86, train 699.78\n",
      "mse_null 889.8375480998528 test 982.84, train 702.86\n",
      "mse_null 889.837548099853 test 955.49, train 665.24\n",
      "mse_null 889.8375480998529 test 959.65, train 669.08\n",
      "mse_null 889.8375480998529 test 954.31, train 662.72\n",
      "mse_null 889.8375480998532 test 955.63, train 665.30\n",
      "mse_null 889.8375480998529 test 954.68, train 664.20\n",
      "mse_null 889.8375480998529 test 964.88, train 679.05\n",
      "mse_null 889.8375480998529 test 960.33, train 671.89\n",
      "mse_null 889.8375480998529 test 953.54, train 662.04\n",
      "mse_null 889.8375480998529 test 956.02, train 666.47\n",
      "mse_null 889.8375480998529 test 954.25, train 665.60\n",
      "mse_null 889.8375480998529 test 949.96, train 661.15\n",
      "mse_null 889.837548099853 test 948.51, train 661.54\n",
      "mse_null 889.8375480998529 test 950.87, train 662.43\n",
      "mse_null 889.837548099853 test 947.59, train 659.92\n",
      "mse_null 889.8375480998529 test 949.07, train 659.90\n",
      "mse_null 889.8375480998529 test 954.82, train 671.57\n",
      "mse_null 889.8375480998532 test 948.17, train 661.46\n",
      "mse_null 889.8375480998532 test 950.08, train 663.60\n",
      "mse_null 889.8375480998528 test 947.39, train 659.95\n",
      "mse_null 889.8375480998527 test 948.09, train 658.53\n",
      "mse_null 889.8375480998529 test 979.57, train 705.42\n",
      "mse_null 889.837548099853 test 1010.51, train 750.19\n",
      "mse_null 889.8375480998532 test 942.57, train 658.07\n",
      "mse_null 889.8375480998529 test 946.04, train 660.72\n",
      "mse_null 889.837548099853 test 944.14, train 661.10\n",
      "mse_null 889.837548099853 test 965.82, train 690.80\n",
      "mse_null 889.8375480998529 test 940.54, train 657.54\n",
      "mse_null 889.8375480998529 test 941.31, train 659.81\n",
      "mse_null 889.8375480998528 test 939.13, train 658.06\n",
      "mse_null 889.837548099853 test 938.39, train 659.52\n",
      "mse_null 889.8375480998532 test 940.61, train 658.03\n",
      "mse_null 889.837548099853 test 942.57, train 662.34\n",
      "mse_null 889.8375480998529 test 940.61, train 660.56\n",
      "mse_null 889.837548099853 test 942.87, train 660.85\n",
      "mse_null 889.8375480998529 test 958.56, train 680.18\n",
      "mse_null 889.8375480998528 test 968.54, train 696.69\n",
      "mse_null 889.8375480998529 test 938.98, train 656.99\n",
      "mse_null 889.8375480998529 test 969.76, train 699.11\n",
      "mse_null 889.8375480998528 test 938.17, train 656.93\n",
      "mse_null 889.8375480998529 test 938.17, train 655.47\n",
      "mse_null 889.8375480998529 test 958.64, train 682.64\n",
      "mse_null 889.837548099853 test 946.06, train 661.16\n",
      "mse_null 889.8375480998527 test 947.60, train 660.52\n",
      "mse_null 889.8375480998529 test 951.21, train 667.64\n",
      "mse_null 889.8375480998529 test 941.19, train 654.00\n",
      "mse_null 889.8375480998529 test 944.03, train 660.29\n",
      "mse_null 889.8375480998532 test 946.87, train 665.11\n",
      "mse_null 889.8375480998532 test 961.98, train 687.55\n",
      "mse_null 889.8375480998529 test 950.63, train 672.47\n",
      "mse_null 889.837548099853 test 939.29, train 656.66\n",
      "mse_null 889.837548099853 test 947.12, train 667.56\n",
      "mse_null 889.837548099853 test 938.71, train 658.57\n",
      "mse_null 889.8375480998529 test 960.17, train 685.46\n",
      "mse_null 889.8375480998529 test 957.11, train 681.06\n",
      "mse_null 889.8375480998528 test 938.28, train 654.06\n",
      "mse_null 889.837548099853 test 935.98, train 651.95\n",
      "mse_null 889.8375480998529 test 944.25, train 662.08\n",
      "mse_null 889.8375480998529 test 946.07, train 663.57\n",
      "mse_null 889.8375480998529 test 942.21, train 659.10\n",
      "mse_null 889.8375480998528 test 948.14, train 669.43\n",
      "mse_null 889.8375480998529 test 940.22, train 656.89\n",
      "mse_null 889.8375480998529 test 936.38, train 651.00\n",
      "mse_null 889.8375480998529 test 933.56, train 652.55\n",
      "mse_null 889.837548099853 test 935.00, train 652.92\n",
      "mse_null 889.837548099853 test 939.68, train 658.56\n",
      "mse_null 889.837548099853 test 950.21, train 671.80\n",
      "mse_null 889.8375480998529 test 940.16, train 657.74\n",
      "mse_null 889.8375480998529 test 958.43, train 682.43\n",
      "mse_null 889.8375480998529 test 951.97, train 673.35\n",
      "mse_null 889.8375480998529 test 937.32, train 649.34\n",
      "mse_null 889.8375480998529 test 939.09, train 652.03\n",
      "mse_null 889.8375480998532 test 951.73, train 671.10\n",
      "mse_null 889.8375480998532 test 946.32, train 662.67\n",
      "mse_null 889.837548099853 test 936.79, train 649.14\n",
      "mse_null 889.8375480998528 test 938.31, train 649.99\n",
      "mse_null 889.8375480998529 test 937.62, train 649.18\n",
      "mse_null 889.837548099853 test 936.98, train 648.21\n",
      "mse_null 889.8375480998529 test 946.76, train 664.43\n",
      "mse_null 889.8375480998528 test 943.81, train 661.57\n",
      "mse_null 889.8375480998529 test 950.14, train 670.15\n",
      "mse_null 889.837548099853 test 945.62, train 662.57\n",
      "mse_null 889.8375480998527 test 938.88, train 657.21\n",
      "mse_null 889.837548099853 test 933.16, train 647.02\n",
      "mse_null 889.837548099853 test 941.53, train 659.37\n",
      "mse_null 889.8375480998528 test 931.92, train 647.61\n",
      "mse_null 889.8375480998528 test 936.79, train 656.43\n",
      "mse_null 889.8375480998532 test 932.34, train 650.53\n",
      "mse_null 889.8375480998528 test 929.19, train 646.19\n",
      "mse_null 889.8375480998528 test 934.01, train 651.91\n",
      "mse_null 889.837548099853 test 929.49, train 645.83\n",
      "mse_null 889.8375480998528 test 935.55, train 655.52\n",
      "mse_null 889.8375480998529 test 930.15, train 647.79\n",
      "mse_null 889.8375480998529 test 957.66, train 686.04\n",
      "mse_null 889.8375480998529 test 927.24, train 645.24\n",
      "mse_null 889.837548099853 test 932.62, train 653.42\n",
      "mse_null 889.8375480998529 test 928.29, train 645.71\n",
      "mse_null 889.837548099853 test 928.62, train 645.25\n",
      "mse_null 889.8375480998529 test 935.50, train 652.88\n",
      "mse_null 889.8375480998529 test 931.12, train 646.71\n",
      "mse_null 889.8375480998527 test 953.65, train 680.54\n",
      "mse_null 889.8375480998527 test 945.92, train 669.87\n",
      "mse_null 889.8375480998532 test 927.23, train 645.66\n",
      "mse_null 889.8375480998529 test 927.71, train 646.33\n",
      "mse_null 889.8375480998527 test 929.63, train 649.33\n",
      "mse_null 889.837548099853 test 926.48, train 648.69\n",
      "mse_null 889.8375480998529 test 926.42, train 647.85\n",
      "mse_null 889.837548099853 test 942.73, train 670.05\n",
      "mse_null 889.8375480998529 test 930.03, train 650.88\n",
      "mse_null 889.8375480998532 test 954.02, train 680.54\n",
      "mse_null 889.8375480998528 test 949.42, train 673.41\n",
      "mse_null 889.8375480998529 test 931.19, train 650.38\n",
      "mse_null 889.8375480998528 test 939.94, train 665.54\n",
      "mse_null 889.8375480998529 test 931.67, train 651.16\n",
      "mse_null 889.8375480998529 test 932.32, train 654.74\n",
      "mse_null 889.8375480998529 test 969.88, train 704.32\n",
      "mse_null 889.8375480998529 test 926.52, train 643.10\n",
      "mse_null 889.837548099853 test 926.39, train 641.63\n",
      "mse_null 889.837548099853 test 929.32, train 642.91\n",
      "mse_null 889.8375480998532 test 931.59, train 648.28\n",
      "mse_null 889.8375480998529 test 933.71, train 649.49\n",
      "mse_null 889.8375480998528 test 929.10, train 641.07\n",
      "mse_null 889.837548099853 test 935.05, train 651.13\n",
      "mse_null 889.8375480998532 test 944.21, train 665.48\n",
      "mse_null 889.837548099853 test 927.69, train 642.02\n",
      "mse_null 889.8375480998529 test 942.91, train 665.92\n",
      "mse_null 889.8375480998529 test 929.67, train 644.21\n",
      "mse_null 889.8375480998529 test 939.28, train 656.37\n",
      "mse_null 889.8375480998529 test 951.04, train 674.28\n",
      "mse_null 889.8375480998529 test 929.56, train 643.52\n",
      "mse_null 889.8375480998529 test 935.79, train 653.45\n",
      "mse_null 889.8375480998529 test 926.23, train 640.16\n",
      "mse_null 889.8375480998529 test 929.96, train 645.22\n",
      "mse_null 889.8375480998529 test 926.92, train 639.70\n",
      "mse_null 889.8375480998529 test 927.99, train 642.28\n",
      "mse_null 889.8375480998527 test 927.38, train 643.13\n",
      "mse_null 889.837548099853 test 924.70, train 640.47\n",
      "mse_null 889.8375480998532 test 925.56, train 639.06\n",
      "mse_null 889.8375480998528 test 932.48, train 646.72\n",
      "mse_null 889.8375480998529 test 927.23, train 638.53\n",
      "mse_null 889.837548099853 test 927.71, train 638.45\n",
      "mse_null 889.8375480998529 test 931.48, train 641.75\n",
      "mse_null 889.8375480998528 test 934.69, train 646.25\n",
      "mse_null 889.8375480998529 test 929.11, train 638.35\n",
      "mse_null 889.8375480998528 test 932.77, train 644.35\n",
      "mse_null 889.8375480998532 test 936.55, train 645.60\n",
      "mse_null 889.837548099853 test 930.33, train 637.49\n",
      "mse_null 889.8375480998529 test 932.34, train 639.97\n",
      "mse_null 889.8375480998529 test 930.96, train 638.48\n",
      "mse_null 889.8375480998532 test 954.36, train 674.01\n",
      "mse_null 889.837548099853 test 959.19, train 682.84\n",
      "mse_null 889.8375480998529 test 930.03, train 640.68\n",
      "mse_null 889.8375480998529 test 928.47, train 638.03\n",
      "mse_null 889.8375480998529 test 927.81, train 639.09\n",
      "mse_null 889.837548099853 test 932.33, train 643.43\n",
      "mse_null 889.8375480998528 test 972.99, train 698.48\n",
      "mse_null 889.8375480998529 test 967.00, train 689.91\n",
      "mse_null 889.837548099853 test 942.33, train 657.61\n",
      "mse_null 889.8375480998527 test 928.72, train 638.71\n",
      "mse_null 889.8375480998529 test 925.22, train 635.71\n",
      "mse_null 889.8375480998529 test 932.05, train 645.30\n",
      "mse_null 889.8375480998529 test 927.46, train 637.63\n",
      "mse_null 889.8375480998529 test 930.30, train 639.76\n",
      "mse_null 889.8375480998529 test 931.80, train 644.28\n",
      "mse_null 889.837548099853 test 932.88, train 645.00\n",
      "mse_null 889.8375480998529 test 925.59, train 635.74\n",
      "mse_null 889.8375480998529 test 925.45, train 635.74\n",
      "mse_null 889.8375480998529 test 925.06, train 635.93\n",
      "mse_null 889.8375480998529 test 928.33, train 639.03\n",
      "mse_null 889.8375480998529 test 930.44, train 641.40\n",
      "mse_null 889.8375480998532 test 927.13, train 634.45\n",
      "mse_null 889.8375480998532 test 930.78, train 641.90\n",
      "mse_null 889.8375480998527 test 928.00, train 634.55\n",
      "mse_null 889.8375480998532 test 926.44, train 633.77\n",
      "mse_null 889.8375480998529 test 973.31, train 702.42\n",
      "mse_null 889.8375480998528 test 926.57, train 636.44\n",
      "mse_null 889.8375480998528 test 926.58, train 635.13\n",
      "mse_null 889.8375480998529 test 925.83, train 633.63\n",
      "mse_null 889.8375480998529 test 936.97, train 647.52\n",
      "mse_null 889.837548099853 test 927.72, train 633.55\n",
      "mse_null 889.8375480998529 test 926.99, train 634.05\n",
      "mse_null 889.8375480998527 test 923.61, train 633.20\n",
      "mse_null 889.8375480998528 test 923.56, train 633.15\n",
      "mse_null 889.8375480998529 test 924.14, train 633.11\n",
      "mse_null 889.837548099853 test 931.21, train 639.88\n",
      "mse_null 889.8375480998529 test 956.54, train 676.71\n",
      "mse_null 889.8375480998529 test 926.70, train 632.88\n",
      "mse_null 889.8375480998532 test 928.66, train 632.20\n",
      "mse_null 889.837548099853 test 926.87, train 636.17\n",
      "mse_null 889.837548099853 test 927.64, train 634.04\n",
      "mse_null 889.8375480998528 test 933.27, train 643.36\n",
      "mse_null 889.8375480998528 test 924.87, train 632.65\n",
      "mse_null 889.837548099853 test 924.89, train 631.45\n",
      "mse_null 889.8375480998529 test 932.37, train 646.84\n",
      "mse_null 889.8375480998528 test 931.54, train 649.23\n",
      "mse_null 889.8375480998528 test 920.71, train 632.25\n",
      "mse_null 889.8375480998528 test 921.52, train 634.32\n",
      "mse_null 889.8375480998529 test 922.11, train 631.14\n",
      "mse_null 889.8375480998529 test 925.58, train 634.50\n",
      "mse_null 889.8375480998529 test 940.36, train 649.99\n",
      "mse_null 889.8375480998529 test 925.40, train 630.87\n",
      "mse_null 889.8375480998528 test 925.76, train 633.14\n",
      "mse_null 889.8375480998529 test 926.33, train 631.24\n",
      "mse_null 889.8375480998528 test 926.22, train 631.84\n",
      "mse_null 889.8375480998526 test 924.71, train 629.96\n",
      "mse_null 889.8375480998529 test 941.85, train 652.91\n",
      "mse_null 889.837548099853 test 945.31, train 662.93\n",
      "mse_null 889.837548099853 test 920.10, train 629.43\n",
      "mse_null 889.8375480998526 test 925.48, train 637.27\n",
      "mse_null 889.8375480998526 test 924.65, train 635.35\n",
      "mse_null 889.8375480998529 test 932.04, train 644.11\n",
      "mse_null 889.8375480998529 test 939.13, train 658.80\n",
      "mse_null 889.8375480998528 test 937.24, train 653.72\n",
      "mse_null 889.837548099853 test 920.98, train 629.13\n",
      "mse_null 889.8375480998532 test 921.89, train 628.58\n",
      "mse_null 889.8375480998532 test 925.82, train 635.23\n",
      "mse_null 889.8375480998529 test 935.91, train 647.75\n",
      "mse_null 889.8375480998527 test 940.91, train 652.49\n",
      "mse_null 889.8375480998527 test 924.60, train 630.29\n",
      "mse_null 889.8375480998532 test 975.03, train 710.76\n",
      "mse_null 889.8375480998529 test 941.24, train 662.68\n",
      "mse_null 889.8375480998529 test 938.03, train 653.95\n",
      "mse_null 889.8375480998529 test 949.90, train 661.99\n",
      "mse_null 889.8375480998529 test 925.80, train 632.14\n",
      "mse_null 889.8375480998529 test 926.83, train 634.20\n",
      "mse_null 889.837548099853 test 922.51, train 627.29\n",
      "mse_null 889.8375480998528 test 925.31, train 631.61\n",
      "mse_null 889.8375480998529 test 924.22, train 629.82\n",
      "mse_null 889.837548099853 test 953.70, train 669.54\n",
      "mse_null 889.837548099853 test 929.98, train 640.66\n",
      "mse_null 889.8375480998529 test 921.49, train 629.68\n",
      "mse_null 889.8375480998529 test 937.58, train 653.44\n",
      "mse_null 889.8375480998528 test 932.58, train 647.03\n",
      "mse_null 889.8375480998529 test 915.53, train 626.61\n",
      "mse_null 889.837548099853 test 917.94, train 626.33\n",
      "mse_null 889.8375480998529 test 936.04, train 652.63\n",
      "mse_null 889.8375480998529 test 923.57, train 629.83\n",
      "mse_null 889.8375480998529 test 925.45, train 634.17\n",
      "mse_null 889.8375480998528 test 923.65, train 637.89\n",
      "mse_null 889.837548099853 test 922.84, train 632.38\n",
      "mse_null 889.8375480998529 test 927.07, train 642.83\n",
      "mse_null 889.8375480998529 test 921.31, train 631.69\n",
      "mse_null 889.8375480998529 test 919.53, train 625.52\n",
      "mse_null 889.8375480998533 test 920.03, train 625.74\n",
      "mse_null 889.8375480998529 test 924.83, train 629.70\n",
      "mse_null 889.8375480998529 test 918.65, train 624.90\n",
      "mse_null 889.8375480998529 test 921.39, train 626.09\n",
      "mse_null 889.837548099853 test 921.61, train 629.72\n",
      "mse_null 889.8375480998529 test 926.58, train 632.18\n",
      "mse_null 889.8375480998528 test 927.45, train 635.44\n",
      "mse_null 889.8375480998529 test 931.28, train 640.46\n",
      "mse_null 889.8375480998528 test 918.37, train 624.47\n",
      "mse_null 889.8375480998529 test 920.70, train 627.52\n",
      "mse_null 889.8375480998529 test 920.83, train 624.28\n",
      "mse_null 889.8375480998529 test 922.69, train 628.25\n",
      "mse_null 889.837548099853 test 920.86, train 624.19\n",
      "mse_null 889.837548099853 test 964.19, train 682.24\n",
      "mse_null 889.8375480998529 test 927.44, train 635.72\n",
      "mse_null 889.8375480998527 test 928.35, train 632.25\n",
      "mse_null 889.8375480998529 test 926.44, train 631.86\n",
      "mse_null 889.8375480998529 test 921.54, train 626.02\n",
      "mse_null 889.8375480998532 test 919.78, train 623.21\n",
      "mse_null 889.8375480998529 test 931.96, train 637.66\n",
      "mse_null 889.8375480998529 test 922.33, train 632.03\n",
      "mse_null 889.837548099853 test 918.60, train 622.91\n",
      "mse_null 889.8375480998529 test 973.72, train 707.19\n",
      "mse_null 889.8375480998528 test 921.64, train 623.32\n",
      "mse_null 889.8375480998529 test 927.55, train 631.34\n",
      "mse_null 889.8375480998529 test 920.69, train 622.83\n",
      "mse_null 889.8375480998529 test 940.86, train 647.84\n",
      "mse_null 889.8375480998529 test 921.24, train 625.15\n",
      "mse_null 889.8375480998529 test 926.86, train 629.26\n",
      "mse_null 889.8375480998529 test 920.08, train 623.07\n",
      "mse_null 889.837548099853 test 926.29, train 627.39\n",
      "mse_null 889.8375480998528 test 921.43, train 622.98\n",
      "mse_null 889.837548099853 test 921.91, train 625.00\n",
      "mse_null 889.8375480998532 test 919.95, train 622.44\n",
      "mse_null 889.837548099853 test 921.72, train 629.27\n",
      "mse_null 889.8375480998529 test 922.82, train 629.43\n",
      "mse_null 889.8375480998529 test 928.73, train 636.20\n",
      "mse_null 889.8375480998529 test 929.69, train 636.08\n",
      "mse_null 889.8375480998529 test 929.61, train 630.39\n",
      "mse_null 889.8375480998529 test 935.08, train 640.06\n",
      "mse_null 889.8375480998529 test 950.20, train 669.73\n",
      "mse_null 889.837548099853 test 920.64, train 621.34\n",
      "mse_null 889.8375480998529 test 921.60, train 621.92\n",
      "mse_null 889.8375480998529 test 922.54, train 620.50\n",
      "mse_null 889.8375480998529 test 923.48, train 622.72\n",
      "mse_null 889.8375480998532 test 923.76, train 622.55\n",
      "mse_null 889.8375480998529 test 930.35, train 628.73\n",
      "mse_null 889.8375480998529 test 926.24, train 622.66\n",
      "mse_null 889.8375480998529 test 930.40, train 627.49\n",
      "mse_null 889.8375480998529 test 939.25, train 646.11\n",
      "mse_null 889.8375480998528 test 926.69, train 620.32\n",
      "mse_null 889.837548099853 test 928.62, train 622.86\n",
      "mse_null 889.8375480998528 test 922.65, train 622.82\n",
      "mse_null 889.8375480998528 test 950.28, train 655.16\n",
      "mse_null 889.8375480998529 test 930.39, train 626.68\n",
      "mse_null 889.8375480998529 test 924.42, train 619.56\n",
      "mse_null 889.8375480998529 test 924.04, train 619.43\n",
      "mse_null 889.8375480998529 test 927.19, train 623.82\n",
      "mse_null 889.837548099853 test 928.03, train 629.35\n",
      "mse_null 889.837548099853 test 922.55, train 619.04\n",
      "mse_null 889.8375480998532 test 927.29, train 624.13\n",
      "mse_null 889.8375480998528 test 925.77, train 622.57\n",
      "mse_null 889.837548099853 test 951.45, train 669.38\n",
      "mse_null 889.8375480998529 test 939.10, train 642.51\n",
      "mse_null 889.8375480998528 test 924.85, train 627.72\n",
      "mse_null 889.8375480998529 test 922.08, train 620.47\n",
      "mse_null 889.8375480998529 test 923.99, train 618.67\n",
      "mse_null 889.8375480998532 test 924.84, train 618.39\n",
      "mse_null 889.8375480998529 test 927.41, train 619.59\n",
      "mse_null 889.837548099853 test 932.56, train 625.72\n",
      "mse_null 889.8375480998529 test 931.14, train 623.79\n",
      "mse_null 889.8375480998529 test 931.10, train 625.31\n",
      "mse_null 889.8375480998528 test 924.21, train 618.26\n",
      "mse_null 889.8375480998532 test 945.63, train 646.73\n",
      "mse_null 889.8375480998528 test 925.09, train 624.59\n",
      "mse_null 889.8375480998529 test 921.54, train 619.33\n",
      "mse_null 889.8375480998529 test 924.84, train 619.62\n",
      "mse_null 889.8375480998529 test 923.11, train 618.83\n",
      "mse_null 889.8375480998529 test 927.14, train 620.84\n",
      "mse_null 889.8375480998532 test 923.96, train 617.29\n",
      "mse_null 889.8375480998529 test 925.00, train 620.00\n",
      "mse_null 889.8375480998529 test 934.95, train 629.85\n",
      "mse_null 889.8375480998532 test 923.97, train 617.26\n",
      "mse_null 889.8375480998532 test 927.85, train 627.09\n",
      "mse_null 889.837548099853 test 960.90, train 679.83\n",
      "mse_null 889.8375480998529 test 934.41, train 628.91\n",
      "mse_null 889.8375480998528 test 936.02, train 638.17\n",
      "mse_null 889.8375480998529 test 938.36, train 643.89\n",
      "mse_null 889.8375480998532 test 920.94, train 618.83\n",
      "mse_null 889.8375480998529 test 921.64, train 617.73\n",
      "mse_null 889.8375480998528 test 946.64, train 646.01\n",
      "mse_null 889.8375480998532 test 929.56, train 622.01\n",
      "mse_null 889.8375480998529 test 930.73, train 628.99\n",
      "mse_null 889.8375480998529 test 926.02, train 621.58\n",
      "mse_null 889.8375480998529 test 923.28, train 619.31\n",
      "mse_null 889.8375480998529 test 931.09, train 624.53\n",
      "mse_null 889.837548099853 test 929.90, train 624.56\n",
      "mse_null 889.837548099853 test 934.02, train 629.51\n",
      "mse_null 889.8375480998529 test 923.23, train 616.77\n",
      "mse_null 889.8375480998529 test 926.73, train 622.73\n",
      "mse_null 889.837548099853 test 946.56, train 645.30\n",
      "mse_null 889.8375480998529 test 921.29, train 615.14\n",
      "mse_null 889.8375480998527 test 966.70, train 671.22\n",
      "mse_null 889.8375480998529 test 924.54, train 619.21\n",
      "mse_null 889.837548099853 test 921.66, train 615.30\n",
      "mse_null 889.8375480998529 test 921.38, train 615.40\n",
      "mse_null 889.8375480998528 test 921.74, train 614.80\n",
      "mse_null 889.8375480998529 test 935.06, train 638.45\n",
      "mse_null 889.8375480998532 test 931.53, train 626.24\n",
      "mse_null 889.8375480998529 test 928.20, train 623.27\n",
      "mse_null 889.8375480998529 test 919.20, train 614.29\n",
      "mse_null 889.8375480998532 test 920.71, train 616.87\n",
      "mse_null 889.837548099853 test 917.27, train 614.24\n",
      "mse_null 889.8375480998527 test 919.25, train 620.08\n",
      "mse_null 889.8375480998529 test 917.04, train 614.39\n",
      "mse_null 889.8375480998529 test 927.81, train 625.06\n",
      "mse_null 889.8375480998529 test 920.43, train 614.94\n",
      "mse_null 889.8375480998529 test 921.08, train 616.65\n",
      "mse_null 889.8375480998527 test 921.92, train 614.93\n",
      "mse_null 889.8375480998528 test 925.69, train 620.89\n",
      "mse_null 889.8375480998529 test 929.84, train 635.40\n",
      "mse_null 889.8375480998529 test 917.85, train 613.68\n",
      "mse_null 889.837548099853 test 923.30, train 616.58\n",
      "mse_null 889.837548099853 test 920.25, train 615.29\n",
      "mse_null 889.837548099853 test 919.26, train 613.36\n",
      "mse_null 889.837548099853 test 919.96, train 612.99\n",
      "mse_null 889.837548099853 test 920.66, train 613.10\n",
      "mse_null 889.8375480998529 test 968.47, train 695.13\n",
      "mse_null 889.837548099853 test 924.88, train 629.45\n",
      "mse_null 889.8375480998529 test 941.09, train 641.65\n",
      "mse_null 889.8375480998532 test 932.32, train 625.79\n",
      "mse_null 889.8375480998528 test 937.07, train 644.42\n",
      "mse_null 889.8375480998532 test 919.43, train 612.47\n",
      "mse_null 889.837548099853 test 917.64, train 614.87\n",
      "mse_null 889.8375480998528 test 916.96, train 614.17\n",
      "mse_null 889.8375480998529 test 925.13, train 620.87\n",
      "mse_null 889.837548099853 test 917.99, train 613.29\n",
      "mse_null 889.8375480998529 test 920.16, train 612.33\n",
      "mse_null 889.8375480998532 test 918.69, train 611.89\n",
      "mse_null 889.8375480998528 test 928.83, train 621.33\n",
      "mse_null 889.8375480998527 test 931.68, train 623.02\n",
      "mse_null 889.8375480998529 test 921.77, train 615.58\n",
      "mse_null 889.8375480998532 test 921.01, train 612.00\n",
      "mse_null 889.8375480998527 test 921.47, train 611.51\n",
      "mse_null 889.8375480998529 test 922.93, train 617.11\n",
      "mse_null 889.8375480998529 test 925.91, train 615.91\n",
      "mse_null 889.8375480998529 test 929.45, train 620.53\n",
      "mse_null 889.8375480998529 test 919.96, train 611.58\n",
      "mse_null 889.8375480998528 test 922.26, train 619.51\n",
      "mse_null 889.8375480998529 test 929.15, train 631.89\n",
      "mse_null 889.8375480998527 test 925.50, train 616.28\n",
      "mse_null 889.8375480998529 test 920.16, train 610.90\n",
      "mse_null 889.8375480998529 test 922.00, train 612.32\n",
      "mse_null 889.8375480998529 test 955.64, train 654.34\n",
      "mse_null 889.8375480998529 test 920.37, train 610.61\n",
      "mse_null 889.8375480998529 test 918.91, train 611.13\n",
      "mse_null 889.8375480998529 test 920.77, train 610.52\n",
      "mse_null 889.8375480998528 test 942.33, train 632.95\n",
      "mse_null 889.8375480998529 test 921.46, train 611.09\n",
      "mse_null 889.837548099853 test 921.33, train 612.75\n",
      "mse_null 889.8375480998532 test 921.26, train 618.37\n",
      "mse_null 889.8375480998529 test 950.54, train 664.57\n",
      "mse_null 889.8375480998529 test 925.77, train 613.87\n",
      "mse_null 889.8375480998529 test 921.26, train 611.29\n",
      "mse_null 889.837548099853 test 923.69, train 614.91\n",
      "mse_null 889.8375480998529 test 935.49, train 635.69\n",
      "mse_null 889.8375480998529 test 926.09, train 625.16\n",
      "mse_null 889.837548099853 test 923.83, train 620.24\n",
      "mse_null 889.8375480998527 test 920.13, train 614.37\n",
      "mse_null 889.8375480998532 test 948.41, train 662.57\n",
      "mse_null 889.8375480998532 test 937.55, train 648.89\n",
      "mse_null 889.8375480998529 test 919.83, train 613.89\n",
      "mse_null 889.837548099853 test 917.82, train 616.03\n",
      "mse_null 889.837548099853 test 922.73, train 611.97\n",
      "mse_null 889.8375480998528 test 925.24, train 624.28\n",
      "mse_null 889.8375480998529 test 922.11, train 613.74\n",
      "mse_null 889.8375480998529 test 944.52, train 635.62\n",
      "mse_null 889.837548099853 test 922.04, train 609.09\n",
      "mse_null 889.8375480998529 test 925.71, train 618.04\n",
      "mse_null 889.8375480998529 test 922.87, train 608.75\n",
      "mse_null 889.8375480998532 test 934.39, train 622.69\n",
      "mse_null 889.8375480998529 test 927.40, train 623.20\n",
      "mse_null 889.8375480998526 test 925.17, train 615.90\n",
      "mse_null 889.8375480998529 test 920.34, train 608.49\n",
      "mse_null 889.837548099853 test 958.25, train 655.01\n",
      "mse_null 889.8375480998529 test 935.42, train 624.53\n",
      "mse_null 889.8375480998529 test 928.90, train 614.98\n",
      "mse_null 889.8375480998529 test 937.04, train 626.66\n",
      "mse_null 889.8375480998527 test 930.82, train 628.61\n",
      "mse_null 889.8375480998529 test 920.88, train 608.31\n",
      "mse_null 889.8375480998529 test 922.97, train 612.35\n",
      "mse_null 889.8375480998529 test 926.95, train 612.80\n",
      "mse_null 889.8375480998527 test 924.37, train 620.10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1095], line 72\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stopping\u001b[38;5;241m.\u001b[39mearly_stop:\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;66;03m# print(f\"Epoch {t+1}\\n-------------------------------\")\u001b[39;00m\n\u001b[1;32m     71\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m---> 72\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m     test_val \u001b[38;5;241m=\u001b[39m validate(test_dataloader, model, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     75\u001b[0m     train_val \u001b[38;5;241m=\u001b[39m validate(train_dataloader, model, \u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[1094], line 12\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(dataloader, model, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m      9\u001b[0m X, y \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mto(device), y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Compute prediction error\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(pred, y)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Backpropagation\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dl/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1526\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dl/lib/python3.10/site-packages/torch/nn/modules/module.py:1536\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1532\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1533\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1534\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1535\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1536\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1539\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[1093], line 75\u001b[0m, in \u001b[0;36mNeuralNetwork.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     74\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflatten(x)\n\u001b[0;32m---> 75\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear_relu_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m logits\n",
      "File \u001b[0;32m~/miniconda3/envs/dl/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1526\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dl/lib/python3.10/site-packages/torch/nn/modules/module.py:1536\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1532\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1533\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1534\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1535\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1536\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1539\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dl/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/dl/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1526\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dl/lib/python3.10/site-packages/torch/nn/modules/module.py:1536\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1532\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1533\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1534\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1535\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1536\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1539\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dl/lib/python3.10/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import copy\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, tolerance=5, min_delta=0):\n",
    "\n",
    "        self.tolerance = tolerance\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, train_loss, validation_loss):\n",
    "        if (validation_loss - train_loss) > self.min_delta:\n",
    "            self.counter +=1\n",
    "            if self.counter >= self.tolerance:  \n",
    "                self.early_stop = True\n",
    "\n",
    "null_mse = 0\n",
    "def validate(test_dataloader, model, verbose=False):\n",
    "    global null_mse\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        i = 0\n",
    "        mse = 0\n",
    "        mse_null = 0\n",
    "        for x, y in test_dataloader:\n",
    "            x = x.clone()\n",
    "            y = y.clone()\n",
    "            i += 1\n",
    "            labels = 56\n",
    "            # labels = 0\n",
    "            # old_x = scaler_x.inverse_transform(x)\n",
    "            # year = old_x[:, year_idx]\n",
    "            # crime = old_x[:, idx]\n",
    "            crime = scaler_y.inverse_transform(y.reshape(-1,1))\n",
    "            old_x = x\n",
    "            x = x.to(device)\n",
    "            pred = model(x)\n",
    "            # print('pred', pred, 'y', y)\n",
    "            pred = pred.detach().cpu().numpy()\n",
    "            old_x = old_x.detach().cpu().numpy()\n",
    "            # out2 = np.hstack((x[:,labels:], pred.reshape(-1,1)))\n",
    "            out2 = scaler_x.inverse_transform(old_x)\n",
    "            pred = scaler_y.inverse_transform(pred.reshape(-1,1))\n",
    "\n",
    "            mse += np.sum((pred - crime) ** 2)\n",
    "            mse_null += np.sum((out2[:, last_idx+labels] - crime) ** 2)\n",
    "\n",
    "    if verbose:\n",
    "        # print('mse', np.sqrt(mse/(batch_size*i)), end=' ')\n",
    "        print('mse_null', np.sqrt(mse_null/(batch_size*i)), end=' ')\n",
    "        null_mse = np.sqrt(mse_null/(batch_size*i))\n",
    "    return np.sqrt(mse/(batch_size*i))\n",
    "\n",
    "epochs = []\n",
    "loss = []\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "stopping = EarlyStopping(tolerance=20, min_delta=100)\n",
    "best_val = 1e9\n",
    "best_model = None\n",
    "last = 0\n",
    "epoch = 0\n",
    "while not stopping.early_stop:\n",
    "    # print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    model.train()\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "\n",
    "    test_val = validate(test_dataloader, model, True)\n",
    "    train_val = validate(train_dataloader, model, False)\n",
    "    print(f\"test {test_val:.2f}, train {train_val:.2f}\", end='\\n')\n",
    "\n",
    "    stopping(best_val, test_val)\n",
    "    last = test_val\n",
    "\n",
    "    if test_val < best_val:\n",
    "        best_val = test_val\n",
    "        best_model = copy.deepcopy(model)\n",
    "\n",
    "    epochs.append(epoch)\n",
    "    loss.append(test_val)\n",
    "    epoch += 1\n",
    "    if epoch % 10 == 0:\n",
    "        ax.clear()\n",
    "        ax.plot(epochs, loss)\n",
    "        ax.axhline(y=null_mse, color='r')\n",
    "        ax.set_ylim([best_val, best_val+200])\n",
    "        fig.savefig('loss.png')\n",
    "\n",
    "\n",
    "print(f\"\\nBest loss: {best_val:.2f}\")\n",
    "model = best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.scale_\n",
    "scaler.var_\n",
    "\n",
    "m = scaler.mean_[idx]\n",
    "s = scaler.scale_[idx]\n",
    "m, s\n",
    "\n",
    "y_m = scaler.mean_[year_idx]\n",
    "s_m = scaler.scale_[year_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1])"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = next(iter(test_dataloader))\n",
    "y.reshape(4, -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 5.7707e-02, 0.0000e+00, 4.5917e-01,\n",
      "         2.8705e-01, 6.5267e-01, 6.4742e-01, 6.5627e-01, 5.9151e-04, 1.6346e-03,\n",
      "         1.5562e-03, 8.6199e-01, 1.8667e-01, 1.0964e-02, 8.0049e-02, 6.9897e-01,\n",
      "         0.0000e+00, 1.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         3.3883e-01, 1.0000e+00, 8.0340e-01, 1.0000e+00, 4.1874e-01, 2.8879e-01,\n",
      "         6.7442e-01, 1.0000e+00, 0.0000e+00, 4.0087e-01, 1.0000e+00, 7.2944e-01,\n",
      "         0.0000e+00, 1.0000e+00, 5.0468e-01, 0.0000e+00, 0.0000e+00, 1.5278e-02,\n",
      "         6.0744e-01, 1.2217e-01, 2.5315e-01, 1.2972e-01, 7.1621e-01, 7.2422e-01,\n",
      "         7.2178e-01, 1.0181e-02, 3.5626e-01, 7.1494e-01, 3.3358e-01, 6.1885e-01,\n",
      "         0.0000e+00, 2.0194e-01, 7.8426e-01, 7.4145e-01, 8.5923e-02, 7.7189e-03,\n",
      "         3.7822e-02, 9.1960e-01, 1.4562e-01, 8.1956e-01, 8.7483e-01, 8.3046e-01,\n",
      "         8.7217e-01, 6.9609e-01, 3.0708e-01, 1.2629e-02, 1.2683e-02, 1.6128e-02,\n",
      "         1.0737e-02, 2.6384e-01, 5.5139e-01, 6.2397e-02, 7.5782e-01, 7.6388e-01,\n",
      "         3.2580e-01, 2.1563e-02, 1.0964e-02, 2.2324e-01, 4.3221e-01, 1.0000e+00,\n",
      "         4.6476e-01, 2.1312e-01, 0.0000e+00, 5.7169e-02]], device='cuda:0')\n",
      "Predicted: \"[8890.785]\",\n",
      " Actual: \"[9876.331]\", Last: [4849.3267]\n",
      "Year: \"[2015.]\"\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.1386, 0.0191, 0.4852, 0.4126, 0.5159, 0.6459,\n",
      "         0.5685, 0.0010, 0.0059, 0.0038, 0.4590, 0.6937, 0.1256, 0.2877, 0.2961,\n",
      "         0.1548, 0.1984, 0.0000, 0.3023, 0.0925, 0.3765, 0.1914, 0.2286, 0.2860,\n",
      "         0.1614, 0.2066, 0.6937, 0.4949, 0.3952, 0.0406, 0.7546, 0.7175, 0.3625,\n",
      "         0.1300, 0.2824, 0.2850, 0.4223, 0.0000, 0.1497, 0.5161, 0.1084, 0.2348,\n",
      "         0.0854, 0.4641, 0.6292, 0.7046, 0.1252, 0.4561, 0.4681, 0.2401, 0.5482,\n",
      "         0.3714, 0.3525, 0.7762, 0.7364, 0.2572, 0.0332, 0.0684, 0.8413, 0.3063,\n",
      "         0.6012, 0.5846, 0.6525, 0.7774, 0.7540, 0.3406, 0.1008, 0.0590, 0.0296,\n",
      "         0.0168, 1.0000, 0.9335, 0.7441, 0.5984, 0.6959, 0.8581, 0.1904, 0.1256,\n",
      "         0.8335, 0.1207, 0.5000, 0.4029, 0.2629, 0.0177, 0.1369]],\n",
      "       device='cuda:0')\n",
      "Predicted: \"[10688.268]\",\n",
      " Actual: \"[10182.525]\", Last: [4849.3267]\n",
      "Year: \"[2015.]\"\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.2089, 0.1216, 0.3440, 0.0974, 0.2835, 0.2692,\n",
      "         0.2811, 0.0217, 0.0106, 0.0218, 0.9838, 0.0021, 0.1840, 0.4435, 0.1446,\n",
      "         0.1134, 0.0882, 0.0000, 0.1017, 0.0904, 0.4137, 0.2628, 0.1970, 0.4418,\n",
      "         0.4433, 0.3202, 0.4898, 0.7477, 0.6658, 0.0000, 0.6081, 0.5729, 0.4096,\n",
      "         0.1904, 0.2069, 0.0522, 0.3094, 0.0000, 0.2074, 0.9004, 0.0989, 0.4718,\n",
      "         0.1558, 0.6591, 0.5440, 0.6201, 0.1780, 0.7157, 0.6322, 0.5135, 0.2330,\n",
      "         0.6788, 0.2728, 0.8455, 0.8271, 0.3803, 0.0293, 0.0878, 0.7671, 0.3483,\n",
      "         0.4115, 0.5153, 0.4688, 0.6070, 0.7674, 0.8017, 0.1499, 0.1622, 0.1959,\n",
      "         0.1888, 0.3306, 0.3038, 0.6749, 0.1993, 0.7542, 0.5355, 0.2008, 0.1840,\n",
      "         0.6702, 0.4918, 0.5000, 0.3393, 0.3624, 0.1469, 0.1923]],\n",
      "       device='cuda:0')\n",
      "Predicted: \"[12108.879]\",\n",
      " Actual: \"[11862.488]\", Last: [4849.3267]\n",
      "Year: \"[2015.]\"\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0333, 0.0501, 0.3176, 0.1529, 0.4460, 0.5155,\n",
      "         0.4741, 0.0010, 0.0067, 0.0081, 0.8717, 0.1651, 0.0744, 0.0758, 0.4359,\n",
      "         0.0000, 0.3001, 0.0000, 0.2435, 0.7719, 0.4158, 0.1761, 0.1782, 0.4716,\n",
      "         0.1188, 0.2208, 0.4330, 0.4642, 0.5912, 0.0000, 1.0000, 0.6453, 0.7626,\n",
      "         0.1914, 0.4158, 0.4196, 0.0000, 0.4372, 0.0901, 0.3510, 0.0257, 0.0747,\n",
      "         0.0226, 0.3801, 0.6385, 0.6986, 0.0771, 0.2511, 0.4764, 0.0605, 0.7462,\n",
      "         0.3116, 0.4918, 0.7643, 0.7335, 0.2319, 0.0205, 0.1263, 0.8442, 0.0677,\n",
      "         0.8223, 0.5191, 0.6069, 0.7446, 0.7963, 0.1761, 0.1104, 0.0510, 0.0374,\n",
      "         0.0193, 0.3585, 0.3074, 0.1878, 0.4801, 0.8279, 0.5612, 0.1341, 0.0744,\n",
      "         0.6850, 0.0000, 0.5000, 0.2720, 0.0496, 0.0501, 0.0299]],\n",
      "       device='cuda:0')\n",
      "Predicted: \"[5519.821]\",\n",
      " Actual: \"[4666.273]\", Last: [4849.3267]\n",
      "Year: \"[2015.]\"\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0541, 0.0379, 0.6204, 0.1506, 0.9109, 0.7730,\n",
      "         0.8453, 0.0026, 0.0067, 0.0054, 0.9317, 0.0917, 0.0333, 0.0881, 0.2337,\n",
      "         0.0000, 0.4930, 0.0000, 0.5795, 0.2191, 0.8916, 0.1133, 0.5413, 0.6355,\n",
      "         0.3821, 0.6763, 0.4855, 0.6056, 0.7842, 0.0000, 0.7148, 0.3087, 0.4502,\n",
      "         0.0000, 0.6687, 0.1687, 1.0000, 0.0000, 0.0420, 0.8647, 0.0883, 0.3531,\n",
      "         0.1697, 0.7456, 0.5608, 0.5199, 0.0326, 0.4946, 0.5968, 0.5449, 0.1228,\n",
      "         0.6426, 0.4395, 0.8274, 0.6897, 0.0748, 0.0650, 0.1217, 0.8147, 0.0000,\n",
      "         0.8496, 0.5839, 0.9144, 0.7469, 0.8420, 0.3218, 0.0000, 0.0224, 0.0271,\n",
      "         0.0043, 0.4202, 0.2891, 0.9238, 0.1766, 0.7752, 0.9104, 0.0390, 0.0333,\n",
      "         0.0867, 0.4447, 1.0000, 0.6325, 0.3925, 0.0305, 0.0511]],\n",
      "       device='cuda:0')\n",
      "Predicted: \"[13529.122]\",\n",
      " Actual: \"[15374.899]\", Last: [4849.3267]\n",
      "Year: \"[2015.]\"\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0808, 0.1025, 0.2297, 0.2061, 0.2210, 0.3385,\n",
      "         0.2902, 0.0013, 0.0027, 0.0122, 0.5084, 0.6228, 0.1545, 0.3917, 0.0836,\n",
      "         0.1311, 0.1046, 0.0000, 0.1373, 0.1828, 0.2392, 0.1418, 0.1936, 0.3004,\n",
      "         0.0683, 0.1311, 0.1938, 0.3379, 0.3405, 0.2292, 0.5753, 0.6948, 0.4913,\n",
      "         0.2202, 0.2392, 0.0604, 0.3577, 0.0000, 0.1760, 0.8581, 0.0427, 0.1709,\n",
      "         0.0573, 0.4766, 0.4692, 0.6612, 0.1603, 0.3611, 0.3916, 0.1775, 0.6198,\n",
      "         0.5152, 0.5195, 0.8312, 0.8116, 0.3864, 0.0657, 0.1329, 0.7978, 0.2776,\n",
      "         0.5855, 0.4000, 0.4409, 0.7401, 0.8739, 0.1893, 0.0865, 0.0424, 0.0287,\n",
      "         0.0109, 0.4976, 0.3453, 0.6747, 0.2100, 0.6965, 0.7187, 0.1732, 0.1545,\n",
      "         0.6932, 0.1194, 0.5000, 0.2227, 0.2228, 0.0982, 0.0734]],\n",
      "       device='cuda:0')\n",
      "Predicted: \"[7773.0835]\",\n",
      " Actual: \"[7883.0195]\", Last: [4849.3267]\n",
      "Year: \"[2015.]\"\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0442, 0.0421, 0.4282, 0.1362, 0.3815, 0.4535,\n",
      "         0.4210, 0.0013, 0.0064, 0.0084, 0.6708, 0.4196, 0.0602, 0.1746, 0.1672,\n",
      "         0.2622, 0.5911, 0.0000, 0.4300, 0.1045, 0.3189, 0.2431, 0.3872, 0.2698,\n",
      "         0.4100, 0.7307, 0.4030, 0.7537, 0.7262, 0.0000, 0.4474, 0.5954, 0.2897,\n",
      "         0.2202, 0.9566, 0.1207, 0.7153, 0.0000, 0.0761, 0.8583, 0.0788, 0.3778,\n",
      "         0.1407, 0.7175, 0.6177, 0.6169, 0.0613, 0.5436, 0.5101, 0.4393, 0.4683,\n",
      "         0.6939, 0.4123, 0.8209, 0.7639, 0.5022, 0.0367, 0.1408, 0.8306, 0.2354,\n",
      "         0.6509, 0.5383, 0.7750, 0.8526, 0.8213, 0.2134, 0.0469, 0.0477, 0.0564,\n",
      "         0.0285, 0.3953, 0.2710, 0.8603, 0.1659, 0.7560, 0.9289, 0.0733, 0.0602,\n",
      "         0.7675, 0.5171, 0.5000, 0.4394, 0.2597, 0.0386, 0.0394]],\n",
      "       device='cuda:0')\n",
      "Predicted: \"[9019.276]\",\n",
      " Actual: \"[8563.408]\", Last: [4849.3267]\n",
      "Year: \"[2015.]\"\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.0000, 0.0000, 0.0000, 0.2068, 0.3165, 0.0042, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 1.0000, 0.1488, 0.5964, 0.0000, 0.3732, 0.2505, 0.3091, 0.0554,\n",
      "         0.3476, 0.1442, 0.0000, 0.2538, 0.6579, 0.1057, 0.3492, 0.1057, 0.7332,\n",
      "         0.8833, 0.8145, 1.0000, 0.1019, 0.1199, 0.1025, 0.3601, 0.1569, 0.2874,\n",
      "         0.1459, 0.1585, 0.0400, 0.0000, 0.0000, 0.3142, 0.9145, 0.1034, 1.0000,\n",
      "         0.5456, 0.2145, 0.1004, 0.2292, 0.1982, 0.4519, 0.1384, 1.0000, 0.0890,\n",
      "         0.8734, 0.5952, 0.2590, 0.1323, 0.3235, 0.4206, 0.9978, 0.1313, 0.4363,\n",
      "         0.4692, 0.2401, 0.2421, 0.3608, 0.3498, 0.0803, 0.4590, 0.3525, 0.3784,\n",
      "         0.4102, 0.0429, 0.0431, 0.3654, 0.0148, 0.4438, 0.6793, 0.3187, 0.2505,\n",
      "         0.5348, 0.1956, 0.0000, 0.0035, 0.5104, 0.2998, 0.1973]],\n",
      "       device='cuda:0')\n",
      "Predicted: \"[14583.163]\",\n",
      " Actual: \"[14405.659]\", Last: [4849.3267]\n",
      "Year: \"[2015.]\"\n",
      "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 2.0000e-01, 5.0714e-02, 2.7963e-04, 4.5917e-01,\n",
      "         2.8705e-01, 6.5267e-01, 6.4742e-01, 6.5627e-01, 5.9151e-04, 1.6346e-03,\n",
      "         1.5562e-03, 8.6199e-01, 1.8667e-01, 1.0964e-02, 8.0049e-02, 6.9897e-01,\n",
      "         0.0000e+00, 1.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         3.3883e-01, 1.0000e+00, 8.0340e-01, 1.0000e+00, 4.1874e-01, 2.8879e-01,\n",
      "         6.7442e-01, 1.0000e+00, 0.0000e+00, 4.0087e-01, 1.0000e+00, 7.2944e-01,\n",
      "         0.0000e+00, 1.0000e+00, 5.0468e-01, 0.0000e+00, 0.0000e+00, 1.5278e-02,\n",
      "         6.0744e-01, 1.2217e-01, 2.5315e-01, 1.2972e-01, 7.1621e-01, 7.2422e-01,\n",
      "         7.2178e-01, 1.0181e-02, 3.5626e-01, 7.1494e-01, 3.3358e-01, 6.1885e-01,\n",
      "         0.0000e+00, 2.0194e-01, 7.8426e-01, 7.4145e-01, 8.5923e-02, 7.7189e-03,\n",
      "         3.7822e-02, 9.1960e-01, 1.4562e-01, 8.1956e-01, 8.7483e-01, 8.3046e-01,\n",
      "         8.7217e-01, 6.9609e-01, 3.0708e-01, 1.2629e-02, 1.2683e-02, 1.6128e-02,\n",
      "         1.0737e-02, 2.6384e-01, 5.5139e-01, 6.2397e-02, 7.5782e-01, 7.6388e-01,\n",
      "         3.2580e-01, 2.1563e-02, 1.0964e-02, 2.2324e-01, 4.3221e-01, 1.0000e+00,\n",
      "         4.6476e-01, 2.9750e-01, 1.0030e-04, 5.4947e-02]], device='cuda:0')\n",
      "Predicted: \"[8593.391]\",\n",
      " Actual: \"[11633.535]\", Last: [4849.3267]\n",
      "Year: \"[2016.]\"\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.2000, 0.0586, 0.1026, 0.3487, 0.1376, 0.3892, 0.4122,\n",
      "         0.4098, 0.0024, 0.0026, 0.0062, 0.6771, 0.4152, 0.0400, 0.1160, 0.4254,\n",
      "         0.0000, 0.1377, 0.0000, 0.3861, 0.3988, 0.4057, 0.2062, 0.7245, 0.4031,\n",
      "         0.3478, 0.3551, 0.2380, 0.7144, 0.8892, 0.0000, 0.7319, 0.6278, 0.3995,\n",
      "         0.5603, 0.6086, 0.7679, 0.9102, 0.0000, 0.0478, 0.4745, 0.0598, 0.2251,\n",
      "         0.0973, 0.5681, 0.6108, 0.6282, 0.0369, 0.3980, 0.4828, 0.3779, 0.3644,\n",
      "         0.3749, 0.3293, 0.7814, 0.7206, 0.2722, 0.0118, 0.0805, 0.8613, 0.1101,\n",
      "         0.6446, 0.6526, 0.7816, 0.7820, 0.8299, 0.1852, 0.0392, 0.0250, 0.0279,\n",
      "         0.0256, 0.3195, 0.6599, 0.0000, 0.9223, 1.0000, 0.4108, 0.0675, 0.0400,\n",
      "         0.3350, 0.0154, 0.5000, 0.3066, 0.2110, 0.0897, 0.0565]],\n",
      "       device='cuda:0')\n",
      "Predicted: \"[8092.0864]\",\n",
      " Actual: \"[9343.694]\", Last: [4849.3267]\n",
      "Year: \"[2016.]\"\n",
      "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 2.0000e-01, 1.5407e-01, 7.0830e-02, 7.0305e-01,\n",
      "         9.1186e-01, 9.0775e-01, 1.0000e+00, 1.0000e+00, 1.5658e-04, 6.9182e-04,\n",
      "         3.1752e-03, 2.1984e-01, 1.0000e+00, 1.3755e-01, 2.4048e-01, 3.6737e-01,\n",
      "         0.0000e+00, 7.1795e-01, 6.9628e-01, 3.5527e-01, 8.6101e-02, 6.1318e-01,\n",
      "         1.7808e-01, 2.7530e-01, 6.2053e-01, 2.2525e-01, 2.7897e-01, 4.7189e-01,\n",
      "         8.5736e-01, 5.7264e-01, 4.6582e-01, 6.3207e-01, 7.2771e-01, 3.2953e-01,\n",
      "         7.2579e-01, 2.6279e-01, 5.3050e-01, 3.9300e-01, 0.0000e+00, 1.7506e-01,\n",
      "         5.6296e-01, 9.3165e-02, 2.4613e-01, 8.0349e-02, 5.5988e-01, 7.4483e-01,\n",
      "         7.6789e-01, 1.4573e-01, 3.8387e-01, 3.5256e-01, 1.4830e-01, 3.7967e-01,\n",
      "         2.5265e-01, 3.1277e-01, 6.6858e-01, 5.9494e-01, 3.7081e-01, 1.1892e-02,\n",
      "         1.0416e-01, 8.7524e-01, 2.6427e-01, 7.2143e-01, 6.8491e-01, 7.6757e-01,\n",
      "         8.6254e-01, 6.1164e-01, 7.0835e-01, 1.1331e-01, 4.9540e-02, 3.3464e-02,\n",
      "         1.3906e-02, 8.3070e-01, 7.3103e-01, 7.0804e-01, 6.6507e-01, 6.0554e-01,\n",
      "         6.6143e-01, 2.1479e-01, 1.3755e-01, 1.0000e+00, 2.1516e-01, 1.0000e+00,\n",
      "         6.1760e-01, 2.7426e-01, 7.1044e-02, 1.4238e-01]], device='cuda:0')\n",
      "Predicted: \"[8990.975]\",\n",
      " Actual: \"[9118.421]\", Last: [4849.3267]\n",
      "Year: \"[2016.]\"\n",
      "tensor([[0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.2000, 0.1022, 0.0724, 0.2665, 0.0283, 0.4080, 0.3296,\n",
      "         0.3704, 0.0101, 0.0048, 0.0828, 0.8998, 0.0437, 0.0891, 0.1058, 0.1280,\n",
      "         0.0000, 0.1692, 0.0000, 0.3555, 0.3599, 0.2441, 0.0931, 0.1046, 0.0615,\n",
      "         0.0000, 0.1353, 0.3463, 0.4741, 0.8388, 0.0000, 0.2936, 0.2545, 0.0408,\n",
      "         0.3371, 0.3662, 0.2772, 0.0000, 0.7700, 0.1127, 0.0000, 0.0224, 0.0498,\n",
      "         0.0345, 0.2464, 0.6752, 0.6586, 0.0878, 0.3910, 0.6282, 0.3681, 0.7420,\n",
      "         0.2751, 0.3943, 0.6025, 0.5059, 0.2621, 0.0102, 0.1333, 0.7876, 0.1021,\n",
      "         0.5588, 0.5974, 0.8533, 0.8173, 0.7239, 0.1651, 0.1927, 0.0776, 0.0574,\n",
      "         0.0349, 0.5991, 0.4406, 0.7257, 0.2666, 0.6911, 0.4732, 0.2448, 0.0891,\n",
      "         0.5966, 0.0122, 0.5000, 0.1904, 0.2396, 0.0710, 0.0963]],\n",
      "       device='cuda:0')\n",
      "Predicted: \"[7677.3193]\",\n",
      " Actual: \"[8809.467]\", Last: [4849.3267]\n",
      "Year: \"[2016.]\"\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.2000, 0.0905, 0.1177, 0.2297, 0.2061, 0.2210, 0.3385,\n",
      "         0.2902, 0.0013, 0.0027, 0.0122, 0.5084, 0.6228, 0.1545, 0.3917, 0.0836,\n",
      "         0.1311, 0.1046, 0.0000, 0.1373, 0.1828, 0.2392, 0.1418, 0.1936, 0.3004,\n",
      "         0.0683, 0.1311, 0.1938, 0.3379, 0.3405, 0.2292, 0.5753, 0.6948, 0.4913,\n",
      "         0.2202, 0.2392, 0.0604, 0.3577, 0.0000, 0.1760, 0.8581, 0.0427, 0.1709,\n",
      "         0.0573, 0.4766, 0.4692, 0.6612, 0.1603, 0.3611, 0.3916, 0.1775, 0.6198,\n",
      "         0.5152, 0.5195, 0.8312, 0.8116, 0.3864, 0.0657, 0.1329, 0.7978, 0.2776,\n",
      "         0.5855, 0.4000, 0.4409, 0.7401, 0.8739, 0.1893, 0.0865, 0.0424, 0.0287,\n",
      "         0.0109, 0.4976, 0.3453, 0.6747, 0.2100, 0.6965, 0.7187, 0.1732, 0.1545,\n",
      "         0.6932, 0.1194, 0.5000, 0.2227, 0.2103, 0.1104, 0.0781]],\n",
      "       device='cuda:0')\n",
      "Predicted: \"[7522.3267]\",\n",
      " Actual: \"[8404.333]\", Last: [4849.3267]\n",
      "Year: \"[2016.]\"\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.2000, 0.5840, 0.2749, 0.0254, 0.0011, 0.0000, 0.0000,\n",
      "         0.0000, 0.2276, 0.2602, 0.8584, 0.0000, 0.1732, 0.4259, 0.4215, 0.0000,\n",
      "         0.0538, 0.0827, 0.0000, 0.0766, 0.1928, 0.1961, 0.1661, 0.1261, 0.3574,\n",
      "         0.2382, 0.1976, 0.5921, 0.4308, 0.5300, 0.5474, 0.3800, 0.1642, 0.1758,\n",
      "         0.1806, 0.1961, 0.0247, 0.2933, 0.0000, 0.5083, 0.9520, 0.0319, 0.4311,\n",
      "         0.3921, 0.5909, 0.4076, 0.6390, 0.3960, 0.6508, 0.5407, 0.9964, 0.3939,\n",
      "         0.5362, 0.4310, 0.5066, 0.3466, 0.3713, 0.3158, 0.5404, 0.3894, 0.4929,\n",
      "         0.2111, 0.6052, 0.5640, 0.5925, 0.5918, 0.1861, 0.5659, 0.5513, 0.6465,\n",
      "         0.5279, 0.1125, 0.0715, 0.4319, 0.0438, 0.3091, 0.3989, 0.4842, 0.4259,\n",
      "         0.5422, 0.2059, 0.0000, 0.0172, 0.3070, 0.2515, 0.5795]],\n",
      "       device='cuda:0')\n",
      "Predicted: \"[9364.324]\",\n",
      " Actual: \"[10864.071]\", Last: [4849.3267]\n",
      "Year: \"[2016.]\"\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.2000, 0.5096, 0.2146, 0.0655, 0.0041, 0.0000, 0.0000,\n",
      "         0.0000, 0.2840, 0.2166, 0.6089, 0.0753, 0.3667, 0.5233, 0.5743, 0.0566,\n",
      "         0.1775, 0.0241, 0.0000, 0.1143, 0.2917, 0.0270, 0.1988, 0.0848, 0.1842,\n",
      "         0.0809, 0.1567, 0.1777, 0.4567, 0.4733, 0.3490, 0.4110, 0.1821, 0.0912,\n",
      "         0.1490, 0.1619, 0.0409, 0.1211, 0.0000, 0.5781, 1.0000, 0.0396, 0.1563,\n",
      "         0.0655, 0.2361, 0.2198, 0.6279, 0.5523, 0.4422, 0.3744, 0.9016, 0.7637,\n",
      "         0.7443, 0.7613, 0.7620, 0.7963, 0.3884, 0.1698, 0.2871, 0.5612, 0.3099,\n",
      "         0.3236, 0.3126, 0.2682, 0.5451, 0.8486, 0.0596, 0.4497, 0.3615, 0.3419,\n",
      "         0.1748, 0.0783, 0.0792, 0.4049, 0.0464, 0.7111, 0.4308, 0.5202, 0.5233,\n",
      "         0.5770, 0.1764, 0.0000, 0.0599, 0.1444, 0.2080, 0.5049]],\n",
      "       device='cuda:0')\n",
      "Predicted: \"[5841.993]\",\n",
      " Actual: \"[7565.808]\", Last: [4849.3267]\n",
      "Year: \"[2016.]\"\n",
      "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 4.0000e-01, 5.1102e-02, 2.7963e-03, 4.5917e-01,\n",
      "         2.8705e-01, 6.5267e-01, 6.4742e-01, 6.5627e-01, 5.9151e-04, 1.6346e-03,\n",
      "         1.5562e-03, 8.6199e-01, 1.8667e-01, 1.0964e-02, 8.0049e-02, 6.9897e-01,\n",
      "         0.0000e+00, 1.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         3.3883e-01, 1.0000e+00, 8.0340e-01, 1.0000e+00, 4.1874e-01, 2.8879e-01,\n",
      "         6.7442e-01, 1.0000e+00, 0.0000e+00, 4.0087e-01, 1.0000e+00, 7.2944e-01,\n",
      "         0.0000e+00, 1.0000e+00, 5.0468e-01, 0.0000e+00, 0.0000e+00, 1.5278e-02,\n",
      "         6.0744e-01, 1.2217e-01, 2.5315e-01, 1.2972e-01, 7.1621e-01, 7.2422e-01,\n",
      "         7.2178e-01, 1.0181e-02, 3.5626e-01, 7.1494e-01, 3.3358e-01, 6.1885e-01,\n",
      "         0.0000e+00, 2.0194e-01, 7.8426e-01, 7.4145e-01, 8.5923e-02, 7.7189e-03,\n",
      "         3.7822e-02, 9.1960e-01, 1.4562e-01, 8.1956e-01, 8.7483e-01, 8.3046e-01,\n",
      "         8.7217e-01, 6.9609e-01, 3.0708e-01, 1.2629e-02, 1.2683e-02, 1.6128e-02,\n",
      "         1.0737e-02, 2.6384e-01, 5.5139e-01, 6.2397e-02, 7.5782e-01, 7.6388e-01,\n",
      "         3.2580e-01, 2.1563e-02, 1.0964e-02, 2.2324e-01, 4.3221e-01, 1.0000e+00,\n",
      "         4.6476e-01, 3.7438e-01, 4.0119e-04, 4.7933e-02]], device='cuda:0')\n",
      "Predicted: \"[8620.789]\",\n",
      " Actual: \"[9093.262]\", Last: [4849.3267]\n",
      "Year: \"[2017.]\"\n",
      "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 4.0000e-01, 5.7999e-02, 4.3249e-02, 3.7148e-01,\n",
      "         9.7939e-02, 4.0034e-01, 4.3609e-01, 4.2668e-01, 7.9540e-04, 1.7527e-02,\n",
      "         4.6557e-03, 7.8284e-01, 2.7778e-01, 1.3286e-02, 4.0540e-02, 3.3239e-01,\n",
      "         0.0000e+00, 4.6660e-01, 0.0000e+00, 4.8928e-01, 1.0387e-01, 3.1702e-01,\n",
      "         3.2225e-01, 3.1702e-01, 3.8855e-01, 5.4347e-01, 1.9619e-01, 8.1492e-01,\n",
      "         7.1497e-01, 8.0821e-01, 0.0000e+00, 2.5417e-01, 3.9392e-01, 2.8734e-01,\n",
      "         4.3778e-01, 9.5107e-01, 2.3999e-01, 0.0000e+00, 1.0000e+00, 1.9044e-02,\n",
      "         7.8875e-01, 5.3321e-02, 4.4544e-01, 1.5174e-01, 7.6410e-01, 7.1584e-01,\n",
      "         7.0081e-01, 1.3806e-02, 5.4669e-01, 6.6299e-01, 3.8019e-01, 1.4144e-01,\n",
      "         3.1861e-01, 2.8707e-01, 6.8505e-01, 8.0500e-01, 4.2234e-01, 7.9389e-03,\n",
      "         1.0846e-01, 9.2507e-01, 3.0326e-01, 7.5230e-01, 6.3433e-01, 8.2556e-01,\n",
      "         9.4114e-01, 6.6638e-01, 2.5719e-01, 4.9967e-02, 4.3825e-02, 3.2756e-02,\n",
      "         1.1688e-02, 1.4598e-01, 8.9814e-02, 1.9750e-01, 3.8331e-01, 7.5925e-01,\n",
      "         5.6626e-01, 1.7318e-02, 1.3286e-02, 7.2923e-01, 4.6452e-01, 5.0000e-01,\n",
      "         3.6791e-01, 3.6731e-01, 3.7411e-02, 6.0390e-02]], device='cuda:0')\n",
      "Predicted: \"[9748.096]\",\n",
      " Actual: \"[9210.62]\", Last: [4849.3267]\n",
      "Year: \"[2017.]\"\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.4000, 0.1412, 0.0261, 0.4852, 0.4126, 0.5159, 0.6459,\n",
      "         0.5685, 0.0010, 0.0059, 0.0038, 0.4590, 0.6937, 0.1256, 0.2877, 0.2961,\n",
      "         0.1548, 0.1984, 0.0000, 0.3023, 0.0925, 0.3765, 0.1914, 0.2286, 0.2860,\n",
      "         0.1614, 0.2066, 0.6937, 0.4949, 0.3952, 0.0406, 0.7546, 0.7175, 0.3625,\n",
      "         0.1300, 0.2824, 0.2850, 0.4223, 0.0000, 0.1497, 0.5161, 0.1084, 0.2348,\n",
      "         0.0854, 0.4641, 0.6292, 0.7046, 0.1252, 0.4561, 0.4681, 0.2401, 0.5482,\n",
      "         0.3714, 0.3525, 0.7762, 0.7364, 0.2572, 0.0332, 0.0684, 0.8413, 0.3063,\n",
      "         0.6012, 0.5846, 0.6525, 0.7774, 0.7540, 0.3406, 0.1008, 0.0590, 0.0296,\n",
      "         0.0168, 1.0000, 0.9335, 0.7441, 0.5984, 0.6959, 0.8581, 0.1904, 0.1256,\n",
      "         0.8335, 0.1207, 0.5000, 0.4029, 0.3425, 0.0261, 0.1381]],\n",
      "       device='cuda:0')\n",
      "Predicted: \"[10828.8955]\",\n",
      " Actual: \"[8356.127]\", Last: [4849.3267]\n",
      "Year: \"[2017.]\"\n",
      "tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.4000, 0.3732, 0.2125, 0.1964, 0.0272, 0.0683, 0.0848,\n",
      "         0.0798, 0.0272, 0.0701, 0.1233, 0.8114, 0.0831, 0.3705, 0.3879, 0.0779,\n",
      "         0.1222, 0.0964, 0.0000, 0.1754, 0.3045, 0.5576, 0.1606, 0.3398, 0.1512,\n",
      "         0.4460, 0.3584, 0.2584, 0.4675, 0.1579, 0.8468, 0.4917, 0.2904, 0.2625,\n",
      "         0.3080, 0.2230, 0.0281, 0.1668, 0.0000, 0.4508, 0.9248, 0.1132, 0.4798,\n",
      "         0.1860, 0.5876, 0.5308, 0.6039, 0.3554, 0.9793, 0.6150, 0.7183, 0.5661,\n",
      "         0.4089, 0.4111, 0.7690, 0.7264, 0.2526, 0.2482, 0.2494, 0.6483, 0.4232,\n",
      "         0.4580, 0.5426, 0.6469, 0.6768, 0.8506, 0.2742, 0.0566, 0.0468, 0.0483,\n",
      "         0.0231, 0.1139, 0.0665, 0.7244, 0.0444, 0.8597, 0.8164, 0.4351, 0.3705,\n",
      "         0.3670, 0.2820, 0.5000, 0.2303, 0.3764, 0.2127, 0.3717]],\n",
      "       device='cuda:0')\n",
      "Predicted: \"[11078.875]\",\n",
      " Actual: \"[10973.842]\", Last: [4849.3267]\n",
      "Year: \"[2017.]\"\n",
      "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 4.0000e-01, 1.5288e-01, 8.0523e-02, 7.0305e-01,\n",
      "         9.1186e-01, 9.0775e-01, 1.0000e+00, 1.0000e+00, 1.5658e-04, 6.9182e-04,\n",
      "         3.1752e-03, 2.1984e-01, 1.0000e+00, 1.3755e-01, 2.4048e-01, 3.6737e-01,\n",
      "         0.0000e+00, 7.1795e-01, 6.9628e-01, 3.5527e-01, 8.6101e-02, 6.1318e-01,\n",
      "         1.7808e-01, 2.7530e-01, 6.2053e-01, 2.2525e-01, 2.7897e-01, 4.7189e-01,\n",
      "         8.5736e-01, 5.7264e-01, 4.6582e-01, 6.3207e-01, 7.2771e-01, 3.2953e-01,\n",
      "         7.2579e-01, 2.6279e-01, 5.3050e-01, 3.9300e-01, 0.0000e+00, 1.7506e-01,\n",
      "         5.6296e-01, 9.3165e-02, 2.4613e-01, 8.0349e-02, 5.5988e-01, 7.4483e-01,\n",
      "         7.6789e-01, 1.4573e-01, 3.8387e-01, 3.5256e-01, 1.4830e-01, 3.7967e-01,\n",
      "         2.5265e-01, 3.1277e-01, 6.6858e-01, 5.9494e-01, 3.7081e-01, 1.1892e-02,\n",
      "         1.0416e-01, 8.7524e-01, 2.6427e-01, 7.2143e-01, 6.8491e-01, 7.6757e-01,\n",
      "         8.6254e-01, 6.1164e-01, 7.0835e-01, 1.1331e-01, 4.9540e-02, 3.3464e-02,\n",
      "         1.3906e-02, 8.3070e-01, 7.3103e-01, 7.0804e-01, 6.6507e-01, 6.0554e-01,\n",
      "         6.6143e-01, 2.1479e-01, 1.3755e-01, 1.0000e+00, 2.1516e-01, 1.0000e+00,\n",
      "         6.1760e-01, 2.6434e-01, 7.6317e-02, 1.5159e-01]], device='cuda:0')\n",
      "Predicted: \"[9189.622]\",\n",
      " Actual: \"[8576.56]\", Last: [4849.3267]\n",
      "Year: \"[2017.]\"\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.4000, 0.0483, 0.0414, 0.4282, 0.1362, 0.3815, 0.4535,\n",
      "         0.4210, 0.0013, 0.0064, 0.0084, 0.6708, 0.4196, 0.0602, 0.1746, 0.1672,\n",
      "         0.2622, 0.5911, 0.0000, 0.4300, 0.1045, 0.3189, 0.2431, 0.3872, 0.2698,\n",
      "         0.4100, 0.7307, 0.4030, 0.7537, 0.7262, 0.0000, 0.4474, 0.5954, 0.2897,\n",
      "         0.2202, 0.9566, 0.1207, 0.7153, 0.0000, 0.0761, 0.8583, 0.0788, 0.3778,\n",
      "         0.1407, 0.7175, 0.6177, 0.6169, 0.0613, 0.5436, 0.5101, 0.4393, 0.4683,\n",
      "         0.6939, 0.4123, 0.8209, 0.7639, 0.5022, 0.0367, 0.1408, 0.8306, 0.2354,\n",
      "         0.6509, 0.5383, 0.7750, 0.8526, 0.8213, 0.2134, 0.0469, 0.0477, 0.0564,\n",
      "         0.0285, 0.3953, 0.2710, 0.8603, 0.1659, 0.7560, 0.9289, 0.0733, 0.0602,\n",
      "         0.7675, 0.5171, 0.5000, 0.4394, 0.2623, 0.0448, 0.0421]],\n",
      "       device='cuda:0')\n",
      "Predicted: \"[8623.827]\",\n",
      " Actual: \"[8103.347]\", Last: [4849.3267]\n",
      "Year: \"[2017.]\"\n",
      "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 4.0000e-01, 5.5583e-01, 4.8358e-01, 0.0000e+00,\n",
      "         5.6319e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.7029e-01, 2.2329e-01,\n",
      "         2.8481e-01, 0.0000e+00, 8.3024e-01, 3.8628e-01, 3.6571e-01, 3.0006e-01,\n",
      "         1.0000e+00, 6.4829e-02, 0.0000e+00, 3.3888e-01, 7.0327e-01, 2.8619e-01,\n",
      "         1.0000e+00, 2.2487e-01, 9.3318e-01, 6.8993e-01, 1.0000e+00, 7.6963e-01,\n",
      "         3.6851e-01, 5.3267e-01, 0.0000e+00, 1.7209e-01, 0.0000e+00, 3.8406e-01,\n",
      "         4.9401e-02, 3.2197e-01, 2.7082e-02, 1.6050e-01, 0.0000e+00, 4.8010e-01,\n",
      "         8.3855e-01, 6.3090e-01, 5.6549e-01, 1.0000e+00, 0.0000e+00, 2.6095e-01,\n",
      "         4.4940e-01, 2.5980e-01, 1.5317e-01, 0.0000e+00, 9.9304e-01, 4.1677e-01,\n",
      "         8.3632e-01, 6.0445e-01, 0.0000e+00, 0.0000e+00, 4.0811e-01, 1.0000e+00,\n",
      "         1.0000e+00, 0.0000e+00, 1.0000e+00, 4.2122e-01, 0.0000e+00, 7.8786e-02,\n",
      "         0.0000e+00, 0.0000e+00, 3.1256e-02, 7.7636e-01, 6.9941e-01, 5.9688e-01,\n",
      "         3.1750e-01, 9.9332e-03, 0.0000e+00, 3.4999e-01, 0.0000e+00, 3.1255e-01,\n",
      "         6.7628e-01, 5.4762e-01, 3.8628e-01, 5.2926e-01, 1.9403e-01, 0.0000e+00,\n",
      "         0.0000e+00, 1.0000e+00, 4.3511e-01, 5.5041e-01]], device='cuda:0')\n",
      "Predicted: \"[24103.158]\",\n",
      " Actual: \"[23392.494]\", Last: [4849.3267]\n",
      "Year: \"[2017.]\"\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.4000, 0.5612, 0.3206, 0.0254, 0.0011, 0.0000, 0.0000,\n",
      "         0.0000, 0.2276, 0.2602, 0.8584, 0.0000, 0.1732, 0.4259, 0.4215, 0.0000,\n",
      "         0.0538, 0.0827, 0.0000, 0.0766, 0.1928, 0.1961, 0.1661, 0.1261, 0.3574,\n",
      "         0.2382, 0.1976, 0.5921, 0.4308, 0.5300, 0.5474, 0.3800, 0.1642, 0.1758,\n",
      "         0.1806, 0.1961, 0.0247, 0.2933, 0.0000, 0.5083, 0.9520, 0.0319, 0.4311,\n",
      "         0.3921, 0.5909, 0.4076, 0.6390, 0.3960, 0.6508, 0.5407, 0.9964, 0.3939,\n",
      "         0.5362, 0.4310, 0.5066, 0.3466, 0.3713, 0.3158, 0.5404, 0.3894, 0.4929,\n",
      "         0.2111, 0.6052, 0.5640, 0.5925, 0.5918, 0.1861, 0.5659, 0.5513, 0.6465,\n",
      "         0.5279, 0.1125, 0.0715, 0.4319, 0.0438, 0.3091, 0.3989, 0.4842, 0.4259,\n",
      "         0.5422, 0.2059, 0.0000, 0.0172, 0.3407, 0.2959, 0.5828]],\n",
      "       device='cuda:0')\n",
      "Predicted: \"[9139.212]\",\n",
      " Actual: \"[9449.608]\", Last: [4849.3267]\n",
      "Year: \"[2017.]\"\n",
      "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 4.0000e-01, 3.7036e-01, 3.9294e-01, 5.4152e-02,\n",
      "         4.4621e-03, 7.1957e-05, 6.4264e-03, 2.2249e-03, 3.0368e-02, 4.7332e-03,\n",
      "         6.1998e-01, 2.9458e-01, 1.9804e-01, 4.0195e-01, 5.3043e-01, 0.0000e+00,\n",
      "         1.1342e-01, 6.1887e-02, 0.0000e+00, 7.6910e-02, 2.4860e-01, 6.8977e-02,\n",
      "         3.2428e-01, 5.9123e-02, 2.1709e-01, 4.4342e-02, 1.2581e-01, 1.5815e-01,\n",
      "         4.6771e-01, 4.1339e-01, 5.8243e-01, 4.2859e-01, 1.2608e-01, 1.4814e-01,\n",
      "         4.7626e-02, 2.0693e-01, 0.0000e+00, 1.5473e-01, 0.0000e+00, 4.3038e-01,\n",
      "         9.6048e-01, 3.1567e-02, 5.5781e-03, 5.4949e-02, 2.2595e-01, 1.8073e-01,\n",
      "         7.3759e-01, 4.2818e-01, 1.0991e-01, 9.5451e-02, 8.5175e-01, 9.9062e-01,\n",
      "         8.7305e-01, 8.8339e-01, 7.0381e-01, 7.9151e-01, 1.4110e-01, 2.6754e-01,\n",
      "         5.6001e-01, 3.9579e-01, 2.6923e-01, 3.7004e-01, 3.3487e-01, 3.4886e-01,\n",
      "         6.9711e-01, 8.1409e-01, 4.7716e-03, 5.9606e-01, 5.5832e-01, 6.1120e-01,\n",
      "         3.6805e-01, 1.4455e-01, 1.2593e-01, 2.7327e-01, 5.8287e-02, 5.2228e-01,\n",
      "         2.1687e-01, 3.9387e-01, 4.0195e-01, 5.6612e-01, 2.0728e-01, 0.0000e+00,\n",
      "         4.5989e-02, 4.4362e-02, 3.7408e-01, 3.8344e-01]], device='cuda:0')\n",
      "Predicted: \"[3480.1826]\",\n",
      " Actual: \"[3950.0183]\", Last: [4849.3267]\n",
      "Year: \"[2017.]\"\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.4000, 0.4479, 0.2779, 0.0623, 0.0019, 0.0000, 0.0000,\n",
      "         0.0000, 0.1559, 0.2569, 0.8470, 0.0573, 0.1276, 0.3517, 0.3546, 0.0409,\n",
      "         0.1923, 0.1019, 0.0000, 0.0811, 0.2171, 0.0390, 0.2278, 0.1615, 0.1992,\n",
      "         0.0835, 0.1756, 0.4558, 0.7015, 0.6443, 1.0000, 0.5156, 0.1432, 0.2808,\n",
      "         0.1615, 0.1169, 0.0295, 0.1749, 0.0000, 0.4025, 0.9788, 0.0586, 0.1840,\n",
      "         0.1163, 0.2775, 0.2307, 0.5188, 0.3597, 0.5758, 0.4276, 0.9043, 0.7849,\n",
      "         0.8370, 0.7423, 0.7722, 0.7146, 0.4293, 0.1604, 0.3279, 0.5424, 0.2243,\n",
      "         0.4111, 0.3554, 0.4538, 0.6142, 0.8823, 0.0583, 0.3099, 0.2114, 0.1940,\n",
      "         0.1435, 0.0609, 0.1514, 0.3958, 0.0223, 0.7587, 0.2969, 0.3687, 0.3517,\n",
      "         0.5773, 0.1919, 0.0000, 0.0585, 0.2160, 0.2522, 0.4468]],\n",
      "       device='cuda:0')\n",
      "Predicted: \"[6842.985]\",\n",
      " Actual: \"[7131.1187]\", Last: [4849.3267]\n",
      "Year: \"[2017.]\"\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.4000, 0.5184, 0.2538, 0.0655, 0.0041, 0.0000, 0.0000,\n",
      "         0.0000, 0.2840, 0.2166, 0.6089, 0.0753, 0.3667, 0.5233, 0.5743, 0.0566,\n",
      "         0.1775, 0.0241, 0.0000, 0.1143, 0.2917, 0.0270, 0.1988, 0.0848, 0.1842,\n",
      "         0.0809, 0.1567, 0.1777, 0.4567, 0.4733, 0.3490, 0.4110, 0.1821, 0.0912,\n",
      "         0.1490, 0.1619, 0.0409, 0.1211, 0.0000, 0.5781, 1.0000, 0.0396, 0.1563,\n",
      "         0.0655, 0.2361, 0.2198, 0.6279, 0.5523, 0.4422, 0.3744, 0.9016, 0.7637,\n",
      "         0.7443, 0.7613, 0.7620, 0.7963, 0.3884, 0.1698, 0.2871, 0.5612, 0.3099,\n",
      "         0.3236, 0.3126, 0.2682, 0.5451, 0.8486, 0.0596, 0.4497, 0.3615, 0.3419,\n",
      "         0.1748, 0.0783, 0.0792, 0.4049, 0.0464, 0.7111, 0.4308, 0.5202, 0.5233,\n",
      "         0.5770, 0.1764, 0.0000, 0.0599, 0.1964, 0.2310, 0.5082]],\n",
      "       device='cuda:0')\n",
      "Predicted: \"[6257.7847]\",\n",
      " Actual: \"[6982.2007]\", Last: [4849.3267]\n",
      "Year: \"[2017.]\"\n",
      "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 4.0000e-01, 1.8118e-01, 5.9536e-01, 1.0480e-02,\n",
      "         1.5144e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.7466e-01, 2.1512e-01,\n",
      "         5.0346e-01, 0.0000e+00, 5.3062e-01, 2.6713e-01, 2.9248e-01, 0.0000e+00,\n",
      "         8.2086e-02, 9.7202e-02, 0.0000e+00, 1.7570e-01, 9.1595e-01, 3.4945e-01,\n",
      "         3.4252e-01, 1.4263e-01, 5.2733e-01, 5.1347e-01, 4.0059e-01, 8.4104e-01,\n",
      "         0.0000e+00, 1.7454e-01, 2.2242e-01, 3.2019e-01, 1.9296e-02, 7.5857e-02,\n",
      "         1.3787e-01, 2.9953e-01, 3.7791e-02, 0.0000e+00, 0.0000e+00, 3.6166e-01,\n",
      "         8.4507e-01, 3.4153e-02, 3.0257e-01, 4.5220e-01, 1.4968e-01, 2.4898e-03,\n",
      "         0.0000e+00, 2.1260e-01, 1.0616e-01, 2.2933e-01, 9.7433e-01, 6.7922e-01,\n",
      "         8.2215e-01, 8.3625e-01, 2.4775e-01, 5.0539e-02, 1.3469e-01, 2.7720e-01,\n",
      "         9.5611e-01, 1.0538e-01, 3.3072e-01, 3.9870e-01, 1.3737e-01, 2.9330e-01,\n",
      "         3.2827e-01, 3.5896e-01, 3.0995e-02, 4.6149e-01, 2.8406e-01, 2.8118e-01,\n",
      "         1.6095e-01, 2.9875e-02, 1.0613e-01, 3.3972e-01, 1.8902e-02, 0.0000e+00,\n",
      "         5.3506e-01, 3.9360e-01, 2.6713e-01, 5.3246e-01, 1.7991e-01, 0.0000e+00,\n",
      "         8.7350e-03, 4.1321e-01, 5.8336e-01, 1.8325e-01]], device='cuda:0')\n",
      "Predicted: \"[11572.795]\",\n",
      " Actual: \"[11421.345]\", Last: [4849.3267]\n",
      "Year: \"[2017.]\"\n",
      "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 4.0000e-01, 8.8699e-01, 1.6146e-01, 8.7568e-02,\n",
      "         1.9216e-02, 9.8097e-04, 4.9574e-03, 2.5007e-03, 4.9608e-02, 3.6235e-02,\n",
      "         3.3831e-01, 3.1775e-01, 4.7357e-01, 1.0000e+00, 1.0000e+00, 3.0498e-02,\n",
      "         9.5659e-02, 1.6247e-02, 0.0000e+00, 5.5417e-03, 1.1437e-01, 1.4544e-02,\n",
      "         1.4414e-01, 4.3632e-02, 1.7105e-01, 3.1166e-02, 4.0659e-02, 1.1273e-01,\n",
      "         3.6699e-01, 9.3590e-02, 6.8981e-02, 3.4982e-01, 1.1915e-01, 1.2556e-01,\n",
      "         2.4101e-01, 1.3090e-01, 2.2020e-02, 1.3050e-01, 0.0000e+00, 1.0000e+00,\n",
      "         9.9898e-01, 2.1340e-02, 2.1709e-01, 5.4034e-02, 2.4089e-01, 2.8147e-01,\n",
      "         6.8863e-01, 1.0000e+00, 5.1055e-01, 4.4560e-01, 5.8564e-01, 6.9047e-01,\n",
      "         5.2432e-01, 5.5964e-01, 9.0840e-01, 8.3820e-01, 4.4546e-01, 1.1011e-01,\n",
      "         1.2890e-01, 5.2900e-01, 4.4375e-01, 9.9120e-02, 2.9155e-01, 8.2482e-02,\n",
      "         3.7868e-01, 8.4671e-01, 1.0569e-01, 5.7674e-01, 4.9293e-01, 4.7548e-01,\n",
      "         2.8062e-01, 1.0689e-01, 1.3144e-01, 3.9658e-01, 8.2991e-02, 6.5854e-01,\n",
      "         4.1902e-01, 8.9713e-01, 1.0000e+00, 5.8135e-01, 1.2526e-01, 0.0000e+00,\n",
      "         8.9571e-02, 2.0216e-01, 1.3901e-01, 8.7049e-01]], device='cuda:0')\n",
      "Predicted: \"[6494.49]\",\n",
      " Actual: \"[6531.239]\", Last: [4849.3267]\n",
      "Year: \"[2017.]\"\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.4000, 0.7359, 0.2102, 0.0492, 0.0248, 0.0073, 0.0084,\n",
      "         0.0079, 0.1282, 0.1017, 0.1140, 0.6062, 0.3244, 0.6263, 0.7493, 0.0955,\n",
      "         0.0374, 0.1046, 0.0000, 0.0850, 0.0448, 0.1366, 0.1331, 0.0325, 0.2697,\n",
      "         0.0195, 0.1596, 0.2235, 0.1733, 0.0814, 0.0082, 0.2282, 0.1355, 0.1744,\n",
      "         0.1887, 0.3416, 0.0345, 0.1022, 0.0000, 0.6107, 0.9915, 0.0284, 0.3725,\n",
      "         0.1099, 0.3729, 0.4234, 0.9007, 0.6130, 0.7640, 0.6063, 0.7410, 0.5517,\n",
      "         0.1816, 0.2918, 0.8600, 0.8282, 0.4063, 0.1257, 0.0883, 0.5598, 0.5282,\n",
      "         0.0303, 0.4623, 0.0627, 0.5490, 0.7128, 0.1265, 0.5222, 0.5209, 0.6663,\n",
      "         0.4824, 0.0889, 0.1809, 0.4538, 0.1415, 0.3512, 0.3369, 0.5558, 0.6263,\n",
      "         0.5165, 0.2334, 0.0000, 0.0413, 0.3650, 0.1901, 0.7371]],\n",
      "       device='cuda:0')\n",
      "Predicted: \"[9780.481]\",\n",
      " Actual: \"[9348.482]\", Last: [4849.3267]\n",
      "Year: \"[2017.]\"\n",
      "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 4.0000e-01, 6.7918e-01, 1.2173e-01, 5.7697e-02,\n",
      "         2.1277e-02, 6.3064e-04, 2.1001e-03, 1.4870e-03, 2.8227e-02, 2.1167e-01,\n",
      "         1.9435e-01, 4.7706e-01, 3.7509e-01, 6.3936e-01, 6.3901e-01, 2.3414e-02,\n",
      "         7.3440e-02, 0.0000e+00, 0.0000e+00, 2.4950e-03, 1.0975e-01, 2.2332e-02,\n",
      "         1.0782e-01, 3.1902e-02, 8.0349e-02, 3.8283e-02, 3.3914e-02, 7.6768e-02,\n",
      "         1.5443e-01, 3.0555e-02, 0.0000e+00, 2.2380e-01, 4.7780e-02, 1.1239e-01,\n",
      "         4.0090e-01, 6.6995e-02, 1.6905e-02, 1.0019e-01, 0.0000e+00, 6.1806e-01,\n",
      "         9.5704e-01, 5.7822e-02, 1.1648e-01, 7.6775e-02, 2.2456e-01, 2.0791e-01,\n",
      "         5.3645e-01, 5.9935e-01, 5.9443e-01, 4.0313e-01, 6.4725e-01, 7.3613e-01,\n",
      "         6.2751e-01, 5.8651e-01, 8.1919e-01, 6.1285e-01, 1.9804e-01, 1.3443e-01,\n",
      "         2.5021e-01, 3.8916e-01, 5.3370e-01, 6.0359e-02, 1.4568e-01, 0.0000e+00,\n",
      "         2.6698e-01, 8.1711e-01, 1.3610e-01, 5.4507e-01, 4.6415e-01, 4.8787e-01,\n",
      "         2.7237e-01, 4.0400e-01, 1.0619e-01, 4.5437e-01, 2.4211e-01, 4.8409e-01,\n",
      "         8.5992e-01, 5.7167e-01, 6.3936e-01, 4.8955e-01, 1.7574e-01, 0.0000e+00,\n",
      "         5.3780e-02, 1.6181e-01, 9.9363e-02, 6.7557e-01]], device='cuda:0')\n",
      "Predicted: \"[6035.764]\",\n",
      " Actual: \"[5890.145]\", Last: [4849.3267]\n",
      "Year: \"[2017.]\"\n",
      "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 4.0000e-01, 1.4977e-01, 9.2922e-01, 1.3261e-02,\n",
      "         1.3557e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.2168e-01, 0.0000e+00,\n",
      "         9.0599e-01, 0.0000e+00, 1.6109e-01, 3.0094e-01, 3.0561e-01, 0.0000e+00,\n",
      "         7.3805e-01, 1.7203e-02, 0.0000e+00, 2.5751e-01, 8.9708e-01, 4.4885e-02,\n",
      "         6.1593e-01, 1.3465e-01, 6.9302e-01, 1.3465e-01, 6.5330e-01, 7.2649e-01,\n",
      "         7.2039e-01, 1.7845e-01, 2.9352e-01, 3.4187e-01, 5.4010e-02, 0.0000e+00,\n",
      "         5.5784e-01, 2.6931e-01, 3.3979e-02, 4.0275e-01, 0.0000e+00, 3.8076e-01,\n",
      "         8.7413e-01, 6.6272e-02, 1.8211e-01, 4.1452e-01, 1.2552e-01, 0.0000e+00,\n",
      "         1.6701e-01, 2.4932e-01, 9.7004e-03, 2.2255e-02, 1.0000e+00, 5.8359e-01,\n",
      "         9.8770e-01, 9.2377e-01, 3.7146e-01, 3.1563e-01, 8.2838e-02, 4.2237e-01,\n",
      "         9.8730e-01, 8.2657e-02, 3.1473e-01, 4.5911e-01, 1.4551e-01, 5.3181e-01,\n",
      "         4.4875e-01, 4.1358e-01, 1.8370e-02, 4.6338e-01, 3.5504e-01, 3.2623e-01,\n",
      "         1.7505e-01, 3.6802e-02, 1.2103e-01, 2.3906e-01, 2.2348e-02, 3.5132e-02,\n",
      "         5.1347e-01, 3.9973e-01, 3.0094e-01, 5.3910e-01, 1.8176e-01, 0.0000e+00,\n",
      "         1.1669e-02, 3.2221e-01, 9.4244e-01, 1.5020e-01]], device='cuda:0')\n",
      "Predicted: \"[9575.248]\",\n",
      " Actual: \"[8810.887]\", Last: [4849.3267]\n",
      "Year: \"[2017.]\"\n",
      "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 4.0000e-01, 9.0807e-02, 5.8648e-01, 4.0048e-02,\n",
      "         6.4525e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.8635e-01, 2.1787e-02,\n",
      "         9.5643e-01, 0.0000e+00, 1.5580e-01, 3.0261e-01, 3.1067e-01, 4.6827e-02,\n",
      "         3.6720e-01, 5.1101e-02, 0.0000e+00, 2.2942e-01, 5.4144e-01, 4.4663e-02,\n",
      "         3.5184e-01, 1.4037e-01, 3.1162e-01, 5.7423e-02, 2.5785e-01, 6.8237e-01,\n",
      "         1.0000e+00, 6.5027e-01, 5.1032e-01, 5.1922e-01, 1.3128e-01, 5.5910e-02,\n",
      "         1.8503e-01, 2.6798e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.3469e-01,\n",
      "         9.2121e-01, 6.3508e-02, 1.9649e-01, 1.3245e-01, 2.0877e-01, 5.3695e-02,\n",
      "         4.0019e-01, 2.9857e-01, 2.3431e-01, 2.3678e-01, 9.6425e-01, 7.4763e-01,\n",
      "         9.2365e-01, 9.5705e-01, 8.9117e-01, 7.0973e-01, 0.0000e+00, 2.2636e-01,\n",
      "         7.0416e-01, 2.4299e-01, 5.8944e-02, 4.6831e-01, 3.0804e-01, 7.8143e-01,\n",
      "         6.5872e-01, 8.8931e-01, 8.9217e-03, 3.8433e-01, 2.1784e-01, 2.1794e-01,\n",
      "         9.7111e-02, 2.1648e-02, 1.0740e-02, 3.5719e-01, 1.1301e-02, 7.6928e-01,\n",
      "         5.2753e-01, 3.2656e-01, 3.0261e-01, 5.4090e-01, 1.5846e-01, 0.0000e+00,\n",
      "         3.1817e-02, 9.4749e-02, 5.5591e-01, 8.0363e-02]], device='cuda:0')\n",
      "Predicted: \"[4520.101]\",\n",
      " Actual: \"[4592.678]\", Last: [4849.3267]\n",
      "Year: \"[2017.]\"\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.6000, 0.0616, 0.0220, 0.3287, 0.0984, 0.3200, 0.4438,\n",
      "         0.3733, 0.0016, 0.0111, 0.0078, 0.8440, 0.1988, 0.0226, 0.0000, 0.8333,\n",
      "         0.0000, 0.7913, 0.0000, 0.2547, 0.1736, 0.2649, 0.4040, 0.1892, 1.0000,\n",
      "         0.6813, 0.5955, 0.1691, 0.4578, 0.6921, 0.5712, 0.6372, 0.7783, 0.2215,\n",
      "         0.3659, 0.0000, 0.6017, 0.0000, 0.0000, 0.0337, 0.7644, 0.0488, 0.2620,\n",
      "         0.1215, 1.0000, 1.0000, 0.9312, 0.0226, 0.6607, 0.5862, 0.3563, 0.2532,\n",
      "         0.0422, 0.0416, 0.6343, 0.6771, 0.1420, 0.0157, 0.0000, 1.0000, 0.2959,\n",
      "         0.6546, 1.0000, 1.0000, 1.0000, 0.5886, 0.2420, 0.0628, 0.0150, 0.0070,\n",
      "         0.0000, 0.1347, 0.1801, 0.0992, 0.7179, 0.7545, 0.2819, 0.0344, 0.0226,\n",
      "         0.3506, 0.4057, 0.5000, 0.3117, 0.3467, 0.0111, 0.0557]],\n",
      "       device='cuda:0')\n",
      "Predicted: \"[9782.325]\",\n",
      " Actual: \"[9707.427]\", Last: [4849.3267]\n",
      "Year: \"[2018.]\"\n",
      "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 6.0000e-01, 6.3278e-02, 4.3062e-02, 3.7148e-01,\n",
      "         9.7939e-02, 4.0034e-01, 4.3609e-01, 4.2668e-01, 7.9540e-04, 1.7527e-02,\n",
      "         4.6557e-03, 7.8284e-01, 2.7778e-01, 1.3286e-02, 4.0540e-02, 3.3239e-01,\n",
      "         0.0000e+00, 4.6660e-01, 0.0000e+00, 4.8928e-01, 1.0387e-01, 3.1702e-01,\n",
      "         3.2225e-01, 3.1702e-01, 3.8855e-01, 5.4347e-01, 1.9619e-01, 8.1492e-01,\n",
      "         7.1497e-01, 8.0821e-01, 0.0000e+00, 2.5417e-01, 3.9392e-01, 2.8734e-01,\n",
      "         4.3778e-01, 9.5107e-01, 2.3999e-01, 0.0000e+00, 1.0000e+00, 1.9044e-02,\n",
      "         7.8875e-01, 5.3321e-02, 4.4544e-01, 1.5174e-01, 7.6410e-01, 7.1584e-01,\n",
      "         7.0081e-01, 1.3806e-02, 5.4669e-01, 6.6299e-01, 3.8019e-01, 1.4144e-01,\n",
      "         3.1861e-01, 2.8707e-01, 6.8505e-01, 8.0500e-01, 4.2234e-01, 7.9389e-03,\n",
      "         1.0846e-01, 9.2507e-01, 3.0326e-01, 7.5230e-01, 6.3433e-01, 8.2556e-01,\n",
      "         9.4114e-01, 6.6638e-01, 2.5719e-01, 4.9967e-02, 4.3825e-02, 3.2756e-02,\n",
      "         1.1688e-02, 1.4598e-01, 8.9814e-02, 1.9750e-01, 3.8331e-01, 7.5925e-01,\n",
      "         5.6626e-01, 1.7318e-02, 1.3286e-02, 7.2923e-01, 4.6452e-01, 5.0000e-01,\n",
      "         3.6791e-01, 2.6837e-01, 4.6638e-02, 5.5239e-02]], device='cuda:0')\n",
      "Predicted: \"[9576.547]\",\n",
      " Actual: \"[8412.205]\", Last: [4849.3267]\n",
      "Year: \"[2018.]\"\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.6000, 0.1372, 0.0312, 0.4852, 0.4126, 0.5159, 0.6459,\n",
      "         0.5685, 0.0010, 0.0059, 0.0038, 0.4590, 0.6937, 0.1256, 0.2877, 0.2961,\n",
      "         0.1548, 0.1984, 0.0000, 0.3023, 0.0925, 0.3765, 0.1914, 0.2286, 0.2860,\n",
      "         0.1614, 0.2066, 0.6937, 0.4949, 0.3952, 0.0406, 0.7546, 0.7175, 0.3625,\n",
      "         0.1300, 0.2824, 0.2850, 0.4223, 0.0000, 0.1497, 0.5161, 0.1084, 0.2348,\n",
      "         0.0854, 0.4641, 0.6292, 0.7046, 0.1252, 0.4561, 0.4681, 0.2401, 0.5482,\n",
      "         0.3714, 0.3525, 0.7762, 0.7364, 0.2572, 0.0332, 0.0684, 0.8413, 0.3063,\n",
      "         0.6012, 0.5846, 0.6525, 0.7774, 0.7540, 0.3406, 0.1008, 0.0590, 0.0296,\n",
      "         0.0168, 1.0000, 0.9335, 0.7441, 0.5984, 0.6959, 0.8581, 0.1904, 0.1256,\n",
      "         0.8335, 0.1207, 0.5000, 0.4029, 0.2310, 0.0282, 0.1387]],\n",
      "       device='cuda:0')\n",
      "Predicted: \"[10375.573]\",\n",
      " Actual: \"[9052.065]\", Last: [4849.3267]\n",
      "Year: \"[2018.]\"\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.6000, 0.0416, 0.1329, 0.5530, 0.0415, 0.2058, 0.2256,\n",
      "         0.2127, 0.0117, 0.0455, 0.0489, 0.7731, 0.2278, 0.1133, 0.1729, 0.1069,\n",
      "         0.3354, 0.2164, 0.0000, 0.1681, 0.1003, 0.7140, 0.2592, 0.3934, 0.3283,\n",
      "         0.5246, 0.4640, 0.2410, 0.5054, 0.2080, 0.0000, 0.4498, 0.2503, 0.2734,\n",
      "         0.5634, 0.3060, 0.0000, 0.4576, 0.0000, 0.1275, 0.9429, 0.1838, 0.7118,\n",
      "         0.1245, 0.4629, 0.4068, 0.5072, 0.1109, 0.7895, 0.5827, 0.4622, 0.0232,\n",
      "         0.7736, 0.3880, 0.9375, 0.7833, 1.0000, 0.1043, 0.1189, 0.7302, 0.3513,\n",
      "         0.4847, 0.4231, 0.3185, 0.6229, 0.9197, 0.4064, 0.0734, 0.0638, 0.0517,\n",
      "         0.0220, 0.2063, 0.1336, 0.9296, 0.0843, 0.6366, 0.9107, 0.1160, 0.1133,\n",
      "         0.8381, 0.6141, 0.5000, 0.5714, 0.2185, 0.1292, 0.0370]],\n",
      "       device='cuda:0')\n",
      "Predicted: \"[7567.6396]\",\n",
      " Actual: \"[7720.0835]\", Last: [4849.3267]\n",
      "Year: \"[2018.]\"\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.6000, 0.0091, 0.2933, 0.2357, 0.0699, 0.1566, 0.1607,\n",
      "         0.1623, 0.0011, 0.0017, 0.0182, 0.7629, 0.2934, 0.0488, 0.0892, 0.3800,\n",
      "         0.0000, 0.3977, 0.0000, 0.2638, 0.3563, 0.0000, 0.0921, 0.0777, 0.2672,\n",
      "         0.0000, 0.1206, 0.1812, 0.3568, 0.2559, 0.0000, 0.4359, 0.2360, 0.1157,\n",
      "         0.2503, 0.0000, 0.1372, 0.0000, 0.0000, 0.0457, 0.2522, 0.0445, 0.0000,\n",
      "         0.0000, 0.0385, 0.2520, 0.5205, 0.0449, 0.1109, 0.2990, 0.3281, 0.9672,\n",
      "         0.7108, 0.8480, 0.9536, 0.6988, 0.1268, 0.1193, 0.3935, 0.4828, 0.0370,\n",
      "         0.6239, 0.1647, 0.2293, 0.6184, 1.0000, 0.1142, 0.1171, 0.0402, 0.0359,\n",
      "         0.0062, 0.4124, 0.6962, 0.2084, 0.4587, 0.7877, 0.5158, 0.0841, 0.0488,\n",
      "         0.4031, 0.0441, 0.5000, 0.2177, 0.0271, 0.2770, 0.0044]],\n",
      "       device='cuda:0')\n",
      "Predicted: \"[3421.233]\",\n",
      " Actual: \"[3618.3208]\", Last: [4849.3267]\n",
      "Year: \"[2018.]\"\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.6000, 0.0312, 0.0705, 0.3176, 0.1529, 0.4460, 0.5155,\n",
      "         0.4741, 0.0010, 0.0067, 0.0081, 0.8717, 0.1651, 0.0744, 0.0758, 0.4359,\n",
      "         0.0000, 0.3001, 0.0000, 0.2435, 0.7719, 0.4158, 0.1761, 0.1782, 0.4716,\n",
      "         0.1188, 0.2208, 0.4330, 0.4642, 0.5912, 0.0000, 1.0000, 0.6453, 0.7626,\n",
      "         0.1914, 0.4158, 0.4196, 0.0000, 0.4372, 0.0901, 0.3510, 0.0257, 0.0747,\n",
      "         0.0226, 0.3801, 0.6385, 0.6986, 0.0771, 0.2511, 0.4764, 0.0605, 0.7462,\n",
      "         0.3116, 0.4918, 0.7643, 0.7335, 0.2319, 0.0205, 0.1263, 0.8442, 0.0677,\n",
      "         0.8223, 0.5191, 0.6069, 0.7446, 0.7963, 0.1761, 0.1104, 0.0510, 0.0374,\n",
      "         0.0193, 0.3585, 0.3074, 0.1878, 0.4801, 0.8279, 0.5612, 0.1341, 0.0744,\n",
      "         0.6850, 0.0000, 0.5000, 0.2720, 0.0803, 0.0649, 0.0303]],\n",
      "       device='cuda:0')\n",
      "Predicted: \"[4808.0464]\",\n",
      " Actual: \"[4881.097]\", Last: [4849.3267]\n",
      "Year: \"[2018.]\"\n",
      "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 6.0000e-01, 5.8164e-01, 4.8769e-01, 0.0000e+00,\n",
      "         5.6319e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.7029e-01, 2.2329e-01,\n",
      "         2.8481e-01, 0.0000e+00, 8.3024e-01, 3.8628e-01, 3.6571e-01, 3.0006e-01,\n",
      "         1.0000e+00, 6.4829e-02, 0.0000e+00, 3.3888e-01, 7.0327e-01, 2.8619e-01,\n",
      "         1.0000e+00, 2.2487e-01, 9.3318e-01, 6.8993e-01, 1.0000e+00, 7.6963e-01,\n",
      "         3.6851e-01, 5.3267e-01, 0.0000e+00, 1.7209e-01, 0.0000e+00, 3.8406e-01,\n",
      "         4.9401e-02, 3.2197e-01, 2.7082e-02, 1.6050e-01, 0.0000e+00, 4.8010e-01,\n",
      "         8.3855e-01, 6.3090e-01, 5.6549e-01, 1.0000e+00, 0.0000e+00, 2.6095e-01,\n",
      "         4.4940e-01, 2.5980e-01, 1.5317e-01, 0.0000e+00, 9.9304e-01, 4.1677e-01,\n",
      "         8.3632e-01, 6.0445e-01, 0.0000e+00, 0.0000e+00, 4.0811e-01, 1.0000e+00,\n",
      "         1.0000e+00, 0.0000e+00, 1.0000e+00, 4.2122e-01, 0.0000e+00, 7.8786e-02,\n",
      "         0.0000e+00, 0.0000e+00, 3.1256e-02, 7.7636e-01, 6.9941e-01, 5.9688e-01,\n",
      "         3.1750e-01, 9.9332e-03, 0.0000e+00, 3.4999e-01, 0.0000e+00, 3.1255e-01,\n",
      "         6.7628e-01, 5.4762e-01, 3.8628e-01, 5.2926e-01, 1.9403e-01, 0.0000e+00,\n",
      "         0.0000e+00, 8.8888e-01, 5.2046e-01, 5.5453e-01]], device='cuda:0')\n",
      "Predicted: \"[22553.947]\",\n",
      " Actual: \"[22141.488]\", Last: [4849.3267]\n",
      "Year: \"[2018.]\"\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.6000, 0.9749, 0.1913, 0.0382, 0.0046, 0.0000, 0.0000,\n",
      "         0.0000, 0.1294, 0.8232, 0.5841, 0.0769, 0.2005, 0.6841, 0.7051, 0.0220,\n",
      "         0.1377, 0.0788, 0.0000, 0.1174, 0.0480, 0.0209, 0.1117, 0.0628, 0.2946,\n",
      "         0.0538, 0.0669, 0.4017, 0.3544, 0.0872, 0.0451, 0.3442, 0.1807, 0.1513,\n",
      "         0.0289, 0.1885, 0.0317, 0.0000, 0.0000, 0.7114, 0.9868, 0.0081, 0.2406,\n",
      "         0.2023, 0.6155, 0.4989, 0.9743, 0.6733, 0.9923, 0.6860, 0.8386, 0.5202,\n",
      "         0.0891, 0.1378, 0.6284, 0.6434, 0.3553, 0.1740, 0.1571, 0.5032, 0.8163,\n",
      "         0.0000, 0.5536, 0.1642, 0.5293, 0.5689, 0.0703, 0.8154, 0.8397, 0.9356,\n",
      "         0.8186, 0.0822, 0.0501, 0.4327, 0.1429, 0.3112, 0.6064, 0.6452, 0.6841,\n",
      "         0.5081, 0.2103, 0.0000, 0.0320, 0.2293, 0.1985, 0.9367]],\n",
      "       device='cuda:0')\n",
      "Predicted: \"[8867.54]\",\n",
      " Actual: \"[9204.404]\", Last: [4849.3267]\n",
      "Year: \"[2018.]\"\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.6000, 0.5817, 0.2730, 0.1572, 0.0430, 0.0020, 0.0368,\n",
      "         0.0281, 0.0130, 0.0163, 0.2023, 0.5770, 0.3128, 0.5885, 0.6754, 0.0760,\n",
      "         0.1192, 0.0382, 0.0000, 0.1148, 0.2374, 0.0000, 0.2087, 0.0518, 0.2716,\n",
      "         0.0518, 0.0726, 0.4452, 0.5289, 0.4803, 0.1805, 0.4067, 0.1907, 0.1003,\n",
      "         0.1668, 0.1449, 0.0549, 0.3251, 0.0000, 0.6787, 0.3502, 0.0635, 0.0893,\n",
      "         0.0405, 0.2184, 0.4202, 0.5897, 0.5985, 0.4885, 0.4868, 0.4254, 0.7316,\n",
      "         0.6776, 0.6322, 0.7701, 0.6399, 0.2871, 0.0646, 0.1896, 0.6561, 0.1514,\n",
      "         0.3936, 0.3907, 0.6443, 0.6596, 0.8202, 0.1394, 0.2414, 0.0738, 0.0602,\n",
      "         0.0213, 0.3085, 0.4257, 0.4441, 0.1284, 0.7746, 0.1184, 0.9317, 0.5885,\n",
      "         0.5392, 0.0556, 0.0000, 0.1286, 0.1562, 0.2613, 0.5703]],\n",
      "       device='cuda:0')\n",
      "Predicted: \"[5961.402]\",\n",
      " Actual: \"[6482.193]\", Last: [4849.3267]\n",
      "Year: \"[2018.]\"\n",
      "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 6.0000e-01, 9.5544e-02, 5.6412e-01, 4.0048e-02,\n",
      "         6.4525e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.8635e-01, 2.1787e-02,\n",
      "         9.5643e-01, 0.0000e+00, 1.5580e-01, 3.0261e-01, 3.1067e-01, 4.6827e-02,\n",
      "         3.6720e-01, 5.1101e-02, 0.0000e+00, 2.2942e-01, 5.4144e-01, 4.4663e-02,\n",
      "         3.5184e-01, 1.4037e-01, 3.1162e-01, 5.7423e-02, 2.5785e-01, 6.8237e-01,\n",
      "         1.0000e+00, 6.5027e-01, 5.1032e-01, 5.1922e-01, 1.3128e-01, 5.5910e-02,\n",
      "         1.8503e-01, 2.6798e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.3469e-01,\n",
      "         9.2121e-01, 6.3508e-02, 1.9649e-01, 1.3245e-01, 2.0877e-01, 5.3695e-02,\n",
      "         4.0019e-01, 2.9857e-01, 2.3431e-01, 2.3678e-01, 9.6425e-01, 7.4763e-01,\n",
      "         9.2365e-01, 9.5705e-01, 8.9117e-01, 7.0973e-01, 0.0000e+00, 2.2636e-01,\n",
      "         7.0416e-01, 2.4299e-01, 5.8944e-02, 4.6831e-01, 3.0804e-01, 7.8143e-01,\n",
      "         6.5872e-01, 8.8931e-01, 8.9217e-03, 3.8433e-01, 2.1784e-01, 2.1794e-01,\n",
      "         9.7111e-02, 2.1648e-02, 1.0740e-02, 3.5719e-01, 1.1301e-02, 7.6928e-01,\n",
      "         5.2753e-01, 3.2656e-01, 3.0261e-01, 5.4090e-01, 1.5846e-01, 0.0000e+00,\n",
      "         3.1817e-02, 6.6325e-02, 6.3118e-01, 8.8144e-02]], device='cuda:0')\n",
      "Predicted: \"[4692.634]\",\n",
      " Actual: \"[4478.939]\", Last: [4849.3267]\n",
      "Year: \"[2018.]\"\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.8000, 0.0606, 0.0284, 0.3287, 0.0984, 0.3200, 0.4438,\n",
      "         0.3733, 0.0016, 0.0111, 0.0078, 0.8440, 0.1988, 0.0226, 0.0000, 0.8333,\n",
      "         0.0000, 0.7913, 0.0000, 0.2547, 0.1736, 0.2649, 0.4040, 0.1892, 1.0000,\n",
      "         0.6813, 0.5955, 0.1691, 0.4578, 0.6921, 0.5712, 0.6372, 0.7783, 0.2215,\n",
      "         0.3659, 0.0000, 0.6017, 0.0000, 0.0000, 0.0337, 0.7644, 0.0488, 0.2620,\n",
      "         0.1215, 1.0000, 1.0000, 0.9312, 0.0226, 0.6607, 0.5862, 0.3563, 0.2532,\n",
      "         0.0422, 0.0416, 0.6343, 0.6771, 0.1420, 0.0157, 0.0000, 1.0000, 0.2959,\n",
      "         0.6546, 1.0000, 1.0000, 1.0000, 0.5886, 0.2420, 0.0628, 0.0150, 0.0070,\n",
      "         0.0000, 0.1347, 0.1801, 0.0992, 0.7179, 0.7545, 0.2819, 0.0344, 0.0226,\n",
      "         0.3506, 0.4057, 0.5000, 0.3117, 0.2901, 0.0238, 0.0589]],\n",
      "       device='cuda:0')\n",
      "Predicted: \"[9355.198]\",\n",
      " Actual: \"[10570.08]\", Last: [4849.3267]\n",
      "Year: \"[2019.]\"\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.8000, 0.1419, 0.1039, 0.1538, 0.1194, 0.1578, 0.1878,\n",
      "         0.1762, 0.0025, 0.0053, 0.0170, 0.7652, 0.2903, 0.0979, 0.1446, 0.2388,\n",
      "         0.0000, 0.3305, 0.0000, 0.1687, 0.1493, 0.2278, 0.1737, 0.1139, 0.2611,\n",
      "         0.4393, 0.1216, 0.2038, 0.2575, 0.2240, 0.0000, 0.5479, 0.3456, 0.3185,\n",
      "         0.4718, 0.0000, 0.1724, 0.0000, 0.7185, 0.0991, 0.8951, 0.0875, 0.2917,\n",
      "         0.0674, 0.4191, 0.3937, 0.6619, 0.0941, 0.6491, 0.6274, 0.2483, 0.7071,\n",
      "         0.4638, 0.4933, 0.9205, 0.8533, 0.3225, 0.0536, 0.0551, 0.7337, 0.2993,\n",
      "         0.3828, 0.3606, 0.2362, 0.5601, 0.8515, 0.2536, 0.0967, 0.0655, 0.0726,\n",
      "         0.0275, 0.3662, 0.2499, 0.2383, 0.4196, 0.6756, 0.0941, 0.0939, 0.0979,\n",
      "         0.5358, 0.3439, 0.5000, 0.1434, 0.2890, 0.1164, 0.1393]],\n",
      "       device='cuda:0')\n",
      "Predicted: \"[10514.855]\",\n",
      " Actual: \"[10391.822]\", Last: [4849.3267]\n",
      "Year: \"[2019.]\"\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.8000, 0.0407, 0.1268, 0.5530, 0.0415, 0.2058, 0.2256,\n",
      "         0.2127, 0.0117, 0.0455, 0.0489, 0.7731, 0.2278, 0.1133, 0.1729, 0.1069,\n",
      "         0.3354, 0.2164, 0.0000, 0.1681, 0.1003, 0.7140, 0.2592, 0.3934, 0.3283,\n",
      "         0.5246, 0.4640, 0.2410, 0.5054, 0.2080, 0.0000, 0.4498, 0.2503, 0.2734,\n",
      "         0.5634, 0.3060, 0.0000, 0.4576, 0.0000, 0.1275, 0.9429, 0.1838, 0.7118,\n",
      "         0.1245, 0.4629, 0.4068, 0.5072, 0.1109, 0.7895, 0.5827, 0.4622, 0.0232,\n",
      "         0.7736, 0.3880, 0.9375, 0.7833, 1.0000, 0.1043, 0.1189, 0.7302, 0.3513,\n",
      "         0.4847, 0.4231, 0.3185, 0.6229, 0.9197, 0.4064, 0.0734, 0.0638, 0.0517,\n",
      "         0.0220, 0.2063, 0.1336, 0.9296, 0.0843, 0.6366, 0.9107, 0.1160, 0.1133,\n",
      "         0.8381, 0.6141, 0.5000, 0.5714, 0.2032, 0.1431, 0.0388]],\n",
      "       device='cuda:0')\n",
      "Predicted: \"[7838.7896]\",\n",
      " Actual: \"[8898.869]\", Last: [4849.3267]\n",
      "Year: \"[2019.]\"\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.8000, 0.0467, 0.0346, 0.7652, 0.2431, 1.0000, 0.9234,\n",
      "         0.9787, 0.0016, 0.0018, 0.0016, 0.9983, 0.0134, 0.0447, 0.0310, 1.0000,\n",
      "         0.0000, 0.8560, 0.0000, 0.4201, 1.0000, 0.5723, 0.0970, 0.4088, 0.7317,\n",
      "         0.6540, 0.9276, 0.7068, 0.4894, 0.5848, 0.0000, 0.8412, 0.5855, 0.6101,\n",
      "         0.7903, 0.5723, 0.4332, 0.8558, 0.0000, 0.0506, 0.8213, 0.0821, 0.5016,\n",
      "         0.1741, 0.8321, 0.6656, 0.6811, 0.0405, 0.4544, 0.4597, 0.3434, 0.4380,\n",
      "         0.2136, 0.2409, 0.8170, 0.6999, 0.3584, 0.0000, 0.0250, 0.8544, 0.2920,\n",
      "         0.6380, 0.5640, 0.5472, 0.6957, 0.7328, 1.0000, 0.1163, 0.1444, 0.1752,\n",
      "         0.1650, 0.2248, 0.7350, 1.0000, 0.4415, 0.5318, 0.9288, 0.0503, 0.0447,\n",
      "         0.3122, 0.9174, 1.0000, 0.7523, 0.3857, 0.0325, 0.0410]],\n",
      "       device='cuda:0')\n",
      "Predicted: \"[11964.365]\",\n",
      " Actual: \"[12262.345]\", Last: [4849.3267]\n",
      "Year: \"[2019.]\"\n",
      "tensor([[0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.8000, 0.1114, 0.1141, 0.2665, 0.0283, 0.4080, 0.3296,\n",
      "         0.3704, 0.0101, 0.0048, 0.0828, 0.8998, 0.0437, 0.0891, 0.1058, 0.1280,\n",
      "         0.0000, 0.1692, 0.0000, 0.3555, 0.3599, 0.2441, 0.0931, 0.1046, 0.0615,\n",
      "         0.0000, 0.1353, 0.3463, 0.4741, 0.8388, 0.0000, 0.2936, 0.2545, 0.0408,\n",
      "         0.3371, 0.3662, 0.2772, 0.0000, 0.7700, 0.1127, 0.0000, 0.0224, 0.0498,\n",
      "         0.0345, 0.2464, 0.6752, 0.6586, 0.0878, 0.3910, 0.6282, 0.3681, 0.7420,\n",
      "         0.2751, 0.3943, 0.6025, 0.5059, 0.2621, 0.0102, 0.1333, 0.7876, 0.1021,\n",
      "         0.5588, 0.5974, 0.8533, 0.8173, 0.7239, 0.1651, 0.1927, 0.0776, 0.0574,\n",
      "         0.0349, 0.5991, 0.4406, 0.7257, 0.2666, 0.6911, 0.4732, 0.2448, 0.0891,\n",
      "         0.5966, 0.0122, 0.5000, 0.1904, 0.1335, 0.1187, 0.1092]],\n",
      "       device='cuda:0')\n",
      "Predicted: \"[6465.024]\",\n",
      " Actual: \"[6672.0083]\", Last: [4849.3267]\n",
      "Year: \"[2019.]\"\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.8000, 0.3129, 0.0550, 0.2880, 0.0312, 0.2626, 0.2148,\n",
      "         0.2388, 0.0208, 0.0901, 0.0739, 0.7189, 0.2504, 0.2040, 0.8584, 0.0662,\n",
      "         0.1038, 0.1756, 0.0000, 0.1185, 0.2069, 0.4421, 0.2247, 0.2436, 0.4830,\n",
      "         0.2706, 0.2875, 0.5343, 0.5772, 0.7735, 0.4039, 0.6835, 0.4078, 0.2857,\n",
      "         0.0000, 0.3789, 0.0478, 0.5666, 0.0000, 0.2515, 0.8926, 0.0838, 0.5301,\n",
      "         0.2115, 0.6425, 0.5893, 0.7075, 0.2046, 0.9791, 0.9039, 0.6685, 0.0000,\n",
      "         0.5590, 0.1740, 0.7731, 0.7089, 0.4523, 0.0901, 0.0673, 0.8177, 0.8030,\n",
      "         0.3431, 0.6891, 0.5579, 0.6938, 0.7992, 0.3619, 0.1705, 0.1233, 0.1047,\n",
      "         0.0585, 0.3055, 0.2057, 0.6979, 0.1271, 0.5672, 0.8101, 0.2473, 0.2040,\n",
      "         0.7527, 0.0759, 0.5000, 0.3108, 0.7107, 0.0540, 0.3010]],\n",
      "       device='cuda:0')\n",
      "Predicted: \"[18189.014]\",\n",
      " Actual: \"[18397.027]\", Last: [4849.3267]\n",
      "Year: \"[2019.]\"\n",
      "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 8.0000e-01, 3.6062e-01, 3.6433e-01, 4.0594e-02,\n",
      "         1.8456e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.5416e-01, 1.4067e-01,\n",
      "         8.9548e-01, 1.2727e-08, 1.6978e-01, 5.0863e-01, 5.0215e-01, 5.8106e-02,\n",
      "         2.7339e-01, 4.1027e-03, 0.0000e+00, 1.8347e-01, 3.8132e-01, 2.2168e-01,\n",
      "         3.1688e-01, 1.5834e-01, 2.1633e-01, 1.1876e-01, 1.9757e-01, 4.3282e-01,\n",
      "         4.8274e-01, 6.2065e-01, 5.4562e-01, 4.1101e-01, 1.4079e-01, 2.0183e-01,\n",
      "         1.5306e-01, 4.1565e-01, 2.0977e-02, 2.4864e-01, 0.0000e+00, 5.8406e-01,\n",
      "         9.6025e-01, 7.6904e-02, 1.5388e-01, 2.0661e-01, 3.2366e-01, 3.0668e-01,\n",
      "         6.7389e-01, 4.9988e-01, 3.5562e-01, 3.2180e-01, 1.0000e+00, 8.2154e-01,\n",
      "         7.3610e-01, 7.5802e-01, 6.9136e-01, 6.0548e-01, 2.9340e-01, 3.7556e-01,\n",
      "         6.2761e-01, 3.3101e-01, 3.4885e-01, 4.6212e-01, 3.3237e-01, 6.6227e-01,\n",
      "         6.0138e-01, 7.5403e-01, 2.1315e-02, 5.7579e-01, 5.3564e-01, 5.1418e-01,\n",
      "         3.7086e-01, 3.9913e-02, 4.3573e-02, 2.6449e-01, 2.5457e-02, 5.2236e-01,\n",
      "         1.1643e-01, 5.4291e-01, 5.0863e-01, 5.5890e-01, 1.8880e-01, 0.0000e+00,\n",
      "         3.4270e-02, 7.0888e-02, 4.1472e-01, 3.6448e-01]], device='cuda:0')\n",
      "Predicted: \"[4490.]\",\n",
      " Actual: \"[5243.8843]\", Last: [4849.3267]\n",
      "Year: \"[2019.]\"\n",
      "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 8.0000e-01, 3.8587e-01, 3.4649e-01, 5.4152e-02,\n",
      "         4.4621e-03, 7.1957e-05, 6.4264e-03, 2.2249e-03, 3.0368e-02, 4.7332e-03,\n",
      "         6.1998e-01, 2.9458e-01, 1.9804e-01, 4.0195e-01, 5.3043e-01, 0.0000e+00,\n",
      "         1.1342e-01, 6.1887e-02, 0.0000e+00, 7.6910e-02, 2.4860e-01, 6.8977e-02,\n",
      "         3.2428e-01, 5.9123e-02, 2.1709e-01, 4.4342e-02, 1.2581e-01, 1.5815e-01,\n",
      "         4.6771e-01, 4.1339e-01, 5.8243e-01, 4.2859e-01, 1.2608e-01, 1.4814e-01,\n",
      "         4.7626e-02, 2.0693e-01, 0.0000e+00, 1.5473e-01, 0.0000e+00, 4.3038e-01,\n",
      "         9.6048e-01, 3.1567e-02, 5.5781e-03, 5.4949e-02, 2.2595e-01, 1.8073e-01,\n",
      "         7.3759e-01, 4.2818e-01, 1.0991e-01, 9.5451e-02, 8.5175e-01, 9.9062e-01,\n",
      "         8.7305e-01, 8.8339e-01, 7.0381e-01, 7.9151e-01, 1.4110e-01, 2.6754e-01,\n",
      "         5.6001e-01, 3.9579e-01, 2.6923e-01, 3.7004e-01, 3.3487e-01, 3.4886e-01,\n",
      "         6.9711e-01, 8.1409e-01, 4.7716e-03, 5.9606e-01, 5.5832e-01, 6.1120e-01,\n",
      "         3.6805e-01, 1.4455e-01, 1.2593e-01, 2.7327e-01, 5.8287e-02, 5.2228e-01,\n",
      "         2.1687e-01, 3.9387e-01, 4.0195e-01, 5.6612e-01, 2.0728e-01, 0.0000e+00,\n",
      "         4.5989e-02, 1.7950e-02, 3.9474e-01, 3.9848e-01]], device='cuda:0')\n",
      "Predicted: \"[3712.8972]\",\n",
      " Actual: \"[4049.719]\", Last: [4849.3267]\n",
      "Year: \"[2019.]\"\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.8000, 0.4319, 0.2544, 0.0623, 0.0019, 0.0000, 0.0000,\n",
      "         0.0000, 0.1559, 0.2569, 0.8470, 0.0573, 0.1276, 0.3517, 0.3546, 0.0409,\n",
      "         0.1923, 0.1019, 0.0000, 0.0811, 0.2171, 0.0390, 0.2278, 0.1615, 0.1992,\n",
      "         0.0835, 0.1756, 0.4558, 0.7015, 0.6443, 1.0000, 0.5156, 0.1432, 0.2808,\n",
      "         0.1615, 0.1169, 0.0295, 0.1749, 0.0000, 0.4025, 0.9788, 0.0586, 0.1840,\n",
      "         0.1163, 0.2775, 0.2307, 0.5188, 0.3597, 0.5758, 0.4276, 0.9043, 0.7849,\n",
      "         0.8370, 0.7423, 0.7722, 0.7146, 0.4293, 0.1604, 0.3279, 0.5424, 0.2243,\n",
      "         0.4111, 0.3554, 0.4538, 0.6142, 0.8823, 0.0583, 0.3099, 0.2114, 0.1940,\n",
      "         0.1435, 0.0609, 0.1514, 0.3958, 0.0223, 0.7587, 0.2969, 0.3687, 0.3517,\n",
      "         0.5773, 0.1919, 0.0000, 0.0585, 0.1681, 0.2899, 0.4478]],\n",
      "       device='cuda:0')\n",
      "Predicted: \"[6681.318]\",\n",
      " Actual: \"[6919.8486]\", Last: [4849.3267]\n",
      "Year: \"[2019.]\"\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.8000, 0.7674, 0.3779, 0.0373, 0.0027, 0.0000, 0.0000,\n",
      "         0.0000, 0.1644, 0.1606, 0.8078, 0.0000, 0.2781, 0.6022, 0.5879, 0.0248,\n",
      "         0.3886, 0.0551, 0.0000, 0.1072, 0.2013, 0.0236, 0.3003, 0.1114, 0.3517,\n",
      "         0.0506, 0.1683, 0.5120, 0.4272, 0.6104, 0.1648, 0.3316, 0.1260, 0.2750,\n",
      "         0.0653, 0.3545, 0.0358, 0.1060, 0.0000, 0.6631, 0.9728, 0.1020, 0.1527,\n",
      "         0.1814, 0.2982, 0.3176, 0.8340, 0.5944, 0.2742, 0.2832, 0.9960, 0.8638,\n",
      "         0.7326, 0.7254, 0.5615, 0.6005, 0.3234, 0.4603, 0.6055, 0.3194, 0.5136,\n",
      "         0.3270, 0.3577, 0.4351, 0.5479, 0.6439, 0.0144, 0.7930, 0.7699, 0.7471,\n",
      "         0.4510, 0.0683, 0.0388, 0.2358, 0.0280, 0.5141, 0.2849, 0.6058, 0.6022,\n",
      "         0.5558, 0.1708, 0.0000, 0.0357, 0.0937, 0.4275, 0.7790]],\n",
      "       device='cuda:0')\n",
      "Predicted: \"[5132.3755]\",\n",
      " Actual: \"[5851.4634]\", Last: [4849.3267]\n",
      "Year: \"[2019.]\"\n",
      "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 8.0000e-01, 1.8798e-01, 5.7233e-01, 1.0480e-02,\n",
      "         1.5144e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.7466e-01, 2.1512e-01,\n",
      "         5.0346e-01, 0.0000e+00, 5.3062e-01, 2.6713e-01, 2.9248e-01, 0.0000e+00,\n",
      "         8.2086e-02, 9.7202e-02, 0.0000e+00, 1.7570e-01, 9.1595e-01, 3.4945e-01,\n",
      "         3.4252e-01, 1.4263e-01, 5.2733e-01, 5.1347e-01, 4.0059e-01, 8.4104e-01,\n",
      "         0.0000e+00, 1.7454e-01, 2.2242e-01, 3.2019e-01, 1.9296e-02, 7.5857e-02,\n",
      "         1.3787e-01, 2.9953e-01, 3.7791e-02, 0.0000e+00, 0.0000e+00, 3.6166e-01,\n",
      "         8.4507e-01, 3.4153e-02, 3.0257e-01, 4.5220e-01, 1.4968e-01, 2.4898e-03,\n",
      "         0.0000e+00, 2.1260e-01, 1.0616e-01, 2.2933e-01, 9.7433e-01, 6.7922e-01,\n",
      "         8.2215e-01, 8.3625e-01, 2.4775e-01, 5.0539e-02, 1.3469e-01, 2.7720e-01,\n",
      "         9.5611e-01, 1.0538e-01, 3.3072e-01, 3.9870e-01, 1.3737e-01, 2.9330e-01,\n",
      "         3.2827e-01, 3.5896e-01, 3.0995e-02, 4.6149e-01, 2.8406e-01, 2.8118e-01,\n",
      "         1.6095e-01, 2.9875e-02, 1.0613e-01, 3.3972e-01, 1.8902e-02, 0.0000e+00,\n",
      "         5.3506e-01, 3.9360e-01, 2.6713e-01, 5.3246e-01, 1.7991e-01, 0.0000e+00,\n",
      "         8.7350e-03, 3.8287e-01, 6.2211e-01, 1.7900e-01]], device='cuda:0')\n",
      "Predicted: \"[11800.833]\",\n",
      " Actual: \"[11226.315]\", Last: [4849.3267]\n",
      "Year: \"[2019.]\"\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.8000, 0.5937, 0.3109, 0.0639, 0.0033, 0.0000, 0.0000,\n",
      "         0.0000, 0.2552, 0.4519, 0.5158, 0.0645, 0.4059, 0.4875, 0.5573, 0.0605,\n",
      "         0.0948, 0.1809, 0.0000, 0.1474, 0.2551, 0.0865, 0.2564, 0.1565, 0.2229,\n",
      "         0.0618, 0.1481, 0.4875, 0.5291, 0.6642, 0.4455, 0.3236, 0.1569, 0.1417,\n",
      "         0.1593, 0.1730, 0.0218, 0.1294, 0.0000, 0.5624, 0.9541, 0.0468, 0.1219,\n",
      "         0.1705, 0.3859, 0.2760, 0.5325, 0.4894, 0.4339, 0.3124, 0.9772, 0.8663,\n",
      "         0.6170, 0.7157, 0.6770, 0.5892, 0.2961, 0.1756, 0.3692, 0.4562, 0.2515,\n",
      "         0.2570, 0.3786, 0.5616, 0.5583, 0.7793, 0.0374, 0.4900, 0.3925, 0.3955,\n",
      "         0.2496, 0.1631, 0.1081, 0.3623, 0.0691, 0.6368, 0.3530, 0.5326, 0.4875,\n",
      "         0.5496, 0.1417, 0.0000, 0.0513, 0.1632, 0.3538, 0.5967]],\n",
      "       device='cuda:0')\n",
      "Predicted: \"[6543.1733]\",\n",
      " Actual: \"[7419.5054]\", Last: [4849.3267]\n",
      "Year: \"[2019.]\"\n",
      "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 8.0000e-01, 5.1258e-01, 4.7392e-01, 2.7659e-02,\n",
      "         8.8968e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.5404e-01, 2.0166e-02,\n",
      "         1.0000e+00, 0.0000e+00, 9.4834e-02, 4.8744e-01, 5.0859e-01, 9.0700e-02,\n",
      "         4.7415e-01, 2.6957e-02, 0.0000e+00, 1.9658e-01, 2.9288e-01, 5.7672e-02,\n",
      "         2.4914e-01, 1.1122e-01, 4.2206e-01, 4.9433e-02, 2.6863e-01, 5.8849e-01,\n",
      "         5.9467e-01, 3.8823e-01, 7.0455e-01, 2.7743e-01, 9.2262e-02, 1.7818e-01,\n",
      "         3.1856e-01, 1.7302e-01, 0.0000e+00, 2.5874e-01, 0.0000e+00, 5.7920e-01,\n",
      "         9.4089e-01, 4.2007e-02, 3.9033e-02, 2.7824e-01, 2.6376e-01, 1.7438e-01,\n",
      "         3.9932e-01, 4.5499e-01, 1.8925e-01, 1.1461e-01, 1.0000e+00, 9.7619e-01,\n",
      "         7.6164e-01, 8.5579e-01, 6.5535e-01, 5.2994e-01, 1.7829e-01, 3.2388e-01,\n",
      "         7.5931e-01, 2.0354e-01, 3.1408e-01, 3.8407e-01, 2.9396e-01, 6.0242e-01,\n",
      "         5.9177e-01, 7.0781e-01, 1.1412e-02, 5.8187e-01, 4.9276e-01, 4.7977e-01,\n",
      "         2.3561e-01, 0.0000e+00, 1.0360e-01, 2.4394e-01, 5.5775e-02, 4.2262e-01,\n",
      "         4.1509e-01, 5.5909e-01, 4.8744e-01, 5.4128e-01, 1.7171e-01, 0.0000e+00,\n",
      "         2.0841e-02, 5.1144e-02, 5.2448e-01, 5.3195e-01]], device='cuda:0')\n",
      "Predicted: \"[4188.656]\",\n",
      " Actual: \"[4799.397]\", Last: [4849.3267]\n",
      "Year: \"[2019.]\"\n",
      "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 8.0000e-01, 8.4416e-02, 5.2686e-01, 4.0048e-02,\n",
      "         6.4525e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.8635e-01, 2.1787e-02,\n",
      "         9.5643e-01, 0.0000e+00, 1.5580e-01, 3.0261e-01, 3.1067e-01, 4.6827e-02,\n",
      "         3.6720e-01, 5.1101e-02, 0.0000e+00, 2.2942e-01, 5.4144e-01, 4.4663e-02,\n",
      "         3.5184e-01, 1.4037e-01, 3.1162e-01, 5.7423e-02, 2.5785e-01, 6.8237e-01,\n",
      "         1.0000e+00, 6.5027e-01, 5.1032e-01, 5.1922e-01, 1.3128e-01, 5.5910e-02,\n",
      "         1.8503e-01, 2.6798e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.3469e-01,\n",
      "         9.2121e-01, 6.3508e-02, 1.9649e-01, 1.3245e-01, 2.0877e-01, 5.3695e-02,\n",
      "         4.0019e-01, 2.9857e-01, 2.3431e-01, 2.3678e-01, 9.6425e-01, 7.4763e-01,\n",
      "         9.2365e-01, 9.5705e-01, 8.9117e-01, 7.0973e-01, 0.0000e+00, 2.2636e-01,\n",
      "         7.0416e-01, 2.4299e-01, 5.8944e-02, 4.6831e-01, 3.0804e-01, 7.8143e-01,\n",
      "         6.5872e-01, 8.8931e-01, 8.9217e-03, 3.8433e-01, 2.1784e-01, 2.1794e-01,\n",
      "         9.7111e-02, 2.1648e-02, 1.0740e-02, 3.5719e-01, 1.1301e-02, 7.6928e-01,\n",
      "         5.2753e-01, 3.2656e-01, 3.0261e-01, 5.4090e-01, 1.5846e-01, 0.0000e+00,\n",
      "         3.1817e-02, 6.1348e-02, 6.0713e-01, 9.2894e-02]], device='cuda:0')\n",
      "Predicted: \"[4927.9146]\",\n",
      " Actual: \"[4849.3267]\", Last: [4849.3267]\n",
      "Year: \"[2019.]\"\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 1.0000, 0.6318, 0.1708, 0.0788, 0.0244, 0.0024, 0.0129,\n",
      "         0.0060, 0.0403, 0.0460, 0.1627, 0.5640, 0.3586, 0.5436, 0.4549, 0.0273,\n",
      "         0.0000, 0.0823, 0.0000, 0.0592, 0.1194, 0.0521, 0.1191, 0.0298, 0.2199,\n",
      "         0.0223, 0.0509, 0.0927, 0.4748, 0.1920, 0.0655, 0.2400, 0.1144, 0.1498,\n",
      "         0.1078, 0.0781, 0.0197, 0.0000, 0.0821, 0.5288, 0.9780, 0.0087, 0.1541,\n",
      "         0.0847, 0.4350, 0.3463, 0.7900, 0.5393, 0.5779, 0.3249, 0.7337, 0.7277,\n",
      "         0.5769, 0.4677, 0.7532, 0.6320, 0.2909, 0.1214, 0.1279, 0.5014, 0.3442,\n",
      "         0.0021, 0.4153, 0.0422, 0.4591, 0.7329, 0.1381, 0.5146, 0.5305, 0.6614,\n",
      "         0.4597, 0.2293, 0.1504, 0.4906, 0.0942, 0.2990, 0.2431, 0.4763, 0.5436,\n",
      "         0.5583, 0.2354, 0.0000, 0.0525, 0.1842, 0.1721, 0.8413]],\n",
      "       device='cuda:0')\n",
      "Predicted: \"[6947.733]\",\n",
      " Actual: \"[7268.006]\", Last: [4849.3267]\n",
      "Year: \"[2020.]\"\n",
      "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.0000e+00, 5.9653e-02, 5.9728e-02, 7.6545e-01,\n",
      "         2.6220e-01, 8.7650e-01, 8.2276e-01, 8.5768e-01, 1.2959e-04, 3.3148e-03,\n",
      "         0.0000e+00, 7.9075e-01, 2.7830e-01, 0.0000e+00, 3.0834e-02, 9.2333e-01,\n",
      "         0.0000e+00, 3.1884e-01, 1.0000e+00, 1.6714e-01, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 6.2502e-01, 1.8871e-01, 2.0724e-01, 4.7599e-01,\n",
      "         5.4999e-01, 9.2390e-01, 0.0000e+00, 1.7651e-01, 9.0766e-01, 1.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         7.0018e-01, 5.7694e-02, 4.3089e-02, 1.7136e-02, 6.3883e-01, 6.4024e-01,\n",
      "         7.8725e-01, 0.0000e+00, 1.6441e-02, 3.0711e-01, 0.0000e+00, 7.8738e-01,\n",
      "         1.6062e-01, 4.2501e-01, 7.8400e-01, 1.0000e+00, 2.9032e-01, 8.0827e-03,\n",
      "         2.5325e-02, 9.8980e-01, 1.2516e-01, 1.0000e+00, 5.6651e-01, 6.4567e-01,\n",
      "         7.2900e-01, 7.3836e-01, 5.2918e-01, 2.3072e-02, 0.0000e+00, 0.0000e+00,\n",
      "         1.3039e-02, 3.3243e-01, 3.9314e-01, 4.5244e-02, 6.8755e-01, 7.6651e-01,\n",
      "         4.7004e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.9186e-01, 1.0000e+00,\n",
      "         6.9871e-01, 2.3174e-01, 4.2506e-02, 7.7975e-02]], device='cuda:0')\n",
      "Predicted: \"[7786.9478]\",\n",
      " Actual: \"[8371.977]\", Last: [4849.3267]\n",
      "Year: \"[2020.]\"\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 1.0000, 0.0289, 0.0382, 0.7652, 0.2431, 1.0000, 0.9234,\n",
      "         0.9787, 0.0016, 0.0018, 0.0016, 0.9983, 0.0134, 0.0447, 0.0310, 1.0000,\n",
      "         0.0000, 0.8560, 0.0000, 0.4201, 1.0000, 0.5723, 0.0970, 0.4088, 0.7317,\n",
      "         0.6540, 0.9276, 0.7068, 0.4894, 0.5848, 0.0000, 0.8412, 0.5855, 0.6101,\n",
      "         0.7903, 0.5723, 0.4332, 0.8558, 0.0000, 0.0506, 0.8213, 0.0821, 0.5016,\n",
      "         0.1741, 0.8321, 0.6656, 0.6811, 0.0405, 0.4544, 0.4597, 0.3434, 0.4380,\n",
      "         0.2136, 0.2409, 0.8170, 0.6999, 0.3584, 0.0000, 0.0250, 0.8544, 0.2920,\n",
      "         0.6380, 0.5640, 0.5472, 0.6957, 0.7328, 1.0000, 0.1163, 0.1444, 0.1752,\n",
      "         0.1650, 0.2248, 0.7350, 1.0000, 0.4415, 0.5318, 0.9288, 0.0503, 0.0447,\n",
      "         0.3122, 0.9174, 1.0000, 0.7523, 0.4019, 0.0373, 0.0439]],\n",
      "       device='cuda:0')\n",
      "Predicted: \"[12155.63]\",\n",
      " Actual: \"[11586.586]\", Last: [4849.3267]\n",
      "Year: \"[2020.]\"\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 1.0000, 0.1636, 0.2491, 0.3440, 0.0974, 0.2835, 0.2692,\n",
      "         0.2811, 0.0217, 0.0106, 0.0218, 0.9838, 0.0021, 0.1840, 0.4435, 0.1446,\n",
      "         0.1134, 0.0882, 0.0000, 0.1017, 0.0904, 0.4137, 0.2628, 0.1970, 0.4418,\n",
      "         0.4433, 0.3202, 0.4898, 0.7477, 0.6658, 0.0000, 0.6081, 0.5729, 0.4096,\n",
      "         0.1904, 0.2069, 0.0522, 0.3094, 0.0000, 0.2074, 0.9004, 0.0989, 0.4718,\n",
      "         0.1558, 0.6591, 0.5440, 0.6201, 0.1780, 0.7157, 0.6322, 0.5135, 0.2330,\n",
      "         0.6788, 0.2728, 0.8455, 0.8271, 0.3803, 0.0293, 0.0878, 0.7671, 0.3483,\n",
      "         0.4115, 0.5153, 0.4688, 0.6070, 0.7674, 0.8017, 0.1499, 0.1622, 0.1959,\n",
      "         0.1888, 0.3306, 0.3038, 0.6749, 0.1993, 0.7542, 0.5355, 0.2008, 0.1840,\n",
      "         0.6702, 0.4918, 0.5000, 0.3393, 0.4362, 0.2406, 0.2263]],\n",
      "       device='cuda:0')\n",
      "Predicted: \"[12681.762]\",\n",
      " Actual: \"[13377.34]\", Last: [4849.3267]\n",
      "Year: \"[2020.]\"\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 1.0000, 0.0760, 0.1613, 0.2297, 0.2061, 0.2210, 0.3385,\n",
      "         0.2902, 0.0013, 0.0027, 0.0122, 0.5084, 0.6228, 0.1545, 0.3917, 0.0836,\n",
      "         0.1311, 0.1046, 0.0000, 0.1373, 0.1828, 0.2392, 0.1418, 0.1936, 0.3004,\n",
      "         0.0683, 0.1311, 0.1938, 0.3379, 0.3405, 0.2292, 0.5753, 0.6948, 0.4913,\n",
      "         0.2202, 0.2392, 0.0604, 0.3577, 0.0000, 0.1760, 0.8581, 0.0427, 0.1709,\n",
      "         0.0573, 0.4766, 0.4692, 0.6612, 0.1603, 0.3611, 0.3916, 0.1775, 0.6198,\n",
      "         0.5152, 0.5195, 0.8312, 0.8116, 0.3864, 0.0657, 0.1329, 0.7978, 0.2776,\n",
      "         0.5855, 0.4000, 0.4409, 0.7401, 0.8739, 0.1893, 0.0865, 0.0424, 0.0287,\n",
      "         0.0109, 0.4976, 0.3453, 0.6747, 0.2100, 0.6965, 0.7187, 0.1732, 0.1545,\n",
      "         0.6932, 0.1194, 0.5000, 0.2227, 0.2508, 0.1505, 0.1057]],\n",
      "       device='cuda:0')\n",
      "Predicted: \"[8421.764]\",\n",
      " Actual: \"[9116.998]\", Last: [4849.3267]\n",
      "Year: \"[2020.]\"\n",
      "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.0000e+00, 4.1557e-01, 4.7650e-01, 0.0000e+00,\n",
      "         5.6319e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.7029e-01, 2.2329e-01,\n",
      "         2.8481e-01, 0.0000e+00, 8.3024e-01, 3.8628e-01, 3.6571e-01, 3.0006e-01,\n",
      "         1.0000e+00, 6.4829e-02, 0.0000e+00, 3.3888e-01, 7.0327e-01, 2.8619e-01,\n",
      "         1.0000e+00, 2.2487e-01, 9.3318e-01, 6.8993e-01, 1.0000e+00, 7.6963e-01,\n",
      "         3.6851e-01, 5.3267e-01, 0.0000e+00, 1.7209e-01, 0.0000e+00, 3.8406e-01,\n",
      "         4.9401e-02, 3.2197e-01, 2.7082e-02, 1.6050e-01, 0.0000e+00, 4.8010e-01,\n",
      "         8.3855e-01, 6.3090e-01, 5.6549e-01, 1.0000e+00, 0.0000e+00, 2.6095e-01,\n",
      "         4.4940e-01, 2.5980e-01, 1.5317e-01, 0.0000e+00, 9.9304e-01, 4.1677e-01,\n",
      "         8.3632e-01, 6.0445e-01, 0.0000e+00, 0.0000e+00, 4.0811e-01, 1.0000e+00,\n",
      "         1.0000e+00, 0.0000e+00, 1.0000e+00, 4.2122e-01, 0.0000e+00, 7.8786e-02,\n",
      "         0.0000e+00, 0.0000e+00, 3.1256e-02, 7.7636e-01, 6.9941e-01, 5.9688e-01,\n",
      "         3.1750e-01, 9.9332e-03, 0.0000e+00, 3.4999e-01, 0.0000e+00, 3.1255e-01,\n",
      "         6.7628e-01, 5.4762e-01, 3.8628e-01, 5.2926e-01, 1.9403e-01, 0.0000e+00,\n",
      "         0.0000e+00, 8.0663e-01, 4.5066e-01, 5.8406e-01]], device='cuda:0')\n",
      "Predicted: \"[21158.002]\",\n",
      " Actual: \"[21397.629]\", Last: [4849.3267]\n",
      "Year: \"[2020.]\"\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 1.0000, 0.3071, 0.3419, 0.0209, 0.0013, 0.0000, 0.0000,\n",
      "         0.0000, 0.2585, 0.2309, 0.8498, 0.0000, 0.1881, 0.5034, 0.4815, 0.0000,\n",
      "         0.2300, 0.1110, 0.0000, 0.1329, 0.3208, 0.0839, 0.2062, 0.0999, 0.4459,\n",
      "         0.1439, 0.2411, 0.7335, 0.6205, 0.6424, 0.2875, 0.3477, 0.1429, 0.1341,\n",
      "         0.1159, 0.1679, 0.0212, 0.1255, 0.0000, 0.5904, 0.9517, 0.0381, 0.2128,\n",
      "         0.3835, 0.5416, 0.3727, 0.6323, 0.4612, 0.4912, 0.3208, 0.9891, 0.6484,\n",
      "         0.4921, 0.4976, 0.4987, 0.3551, 0.4121, 0.3236, 0.5374, 0.3760, 0.4904,\n",
      "         0.2198, 0.6001, 0.5667, 0.5845, 0.5300, 0.0745, 0.5691, 0.5529, 0.6584,\n",
      "         0.4828, 0.0948, 0.0973, 0.4620, 0.0640, 0.2893, 0.4628, 0.5648, 0.5034,\n",
      "         0.5280, 0.2130, 0.0000, 0.0177, 0.2159, 0.3299, 0.4351]],\n",
      "       device='cuda:0')\n",
      "Predicted: \"[7992.202]\",\n",
      " Actual: \"[7647.6143]\", Last: [4849.3267]\n",
      "Year: \"[2020.]\"\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 1.0000, 0.5572, 0.4017, 0.0373, 0.0027, 0.0000, 0.0000,\n",
      "         0.0000, 0.1644, 0.1606, 0.8078, 0.0000, 0.2781, 0.6022, 0.5879, 0.0248,\n",
      "         0.3886, 0.0551, 0.0000, 0.1072, 0.2013, 0.0236, 0.3003, 0.1114, 0.3517,\n",
      "         0.0506, 0.1683, 0.5120, 0.4272, 0.6104, 0.1648, 0.3316, 0.1260, 0.2750,\n",
      "         0.0653, 0.3545, 0.0358, 0.1060, 0.0000, 0.6631, 0.9728, 0.1020, 0.1527,\n",
      "         0.1814, 0.2982, 0.3176, 0.8340, 0.5944, 0.2742, 0.2832, 0.9960, 0.8638,\n",
      "         0.7326, 0.7254, 0.5615, 0.6005, 0.3234, 0.4603, 0.6055, 0.3194, 0.5136,\n",
      "         0.3270, 0.3577, 0.4351, 0.5479, 0.6439, 0.0144, 0.7930, 0.7699, 0.7471,\n",
      "         0.4510, 0.0683, 0.0388, 0.2358, 0.0280, 0.5141, 0.2849, 0.6058, 0.6022,\n",
      "         0.5558, 0.1708, 0.0000, 0.0357, 0.1214, 0.4067, 0.7667]],\n",
      "       device='cuda:0')\n",
      "Predicted: \"[5455.324]\",\n",
      " Actual: \"[6387.7363]\", Last: [4849.3267]\n",
      "Year: \"[2020.]\"\n",
      "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.0000e+00, 5.2328e-01, 1.4933e-01, 5.7697e-02,\n",
      "         2.1277e-02, 6.3064e-04, 2.1001e-03, 1.4870e-03, 2.8227e-02, 2.1167e-01,\n",
      "         1.9435e-01, 4.7706e-01, 3.7509e-01, 6.3936e-01, 6.3901e-01, 2.3414e-02,\n",
      "         7.3440e-02, 0.0000e+00, 0.0000e+00, 2.4950e-03, 1.0975e-01, 2.2332e-02,\n",
      "         1.0782e-01, 3.1902e-02, 8.0349e-02, 3.8283e-02, 3.3914e-02, 7.6768e-02,\n",
      "         1.5443e-01, 3.0555e-02, 0.0000e+00, 2.2380e-01, 4.7780e-02, 1.1239e-01,\n",
      "         4.0090e-01, 6.6995e-02, 1.6905e-02, 1.0019e-01, 0.0000e+00, 6.1806e-01,\n",
      "         9.5704e-01, 5.7822e-02, 1.1648e-01, 7.6775e-02, 2.2456e-01, 2.0791e-01,\n",
      "         5.3645e-01, 5.9935e-01, 5.9443e-01, 4.0313e-01, 6.4725e-01, 7.3613e-01,\n",
      "         6.2751e-01, 5.8651e-01, 8.1919e-01, 6.1285e-01, 1.9804e-01, 1.3443e-01,\n",
      "         2.5021e-01, 3.8916e-01, 5.3370e-01, 6.0359e-02, 1.4568e-01, 0.0000e+00,\n",
      "         2.6698e-01, 8.1711e-01, 1.3610e-01, 5.4507e-01, 4.6415e-01, 4.8787e-01,\n",
      "         2.7237e-01, 4.0400e-01, 1.0619e-01, 4.5437e-01, 2.4211e-01, 4.8409e-01,\n",
      "         8.5992e-01, 5.7167e-01, 6.3936e-01, 4.8955e-01, 1.7574e-01, 0.0000e+00,\n",
      "         5.3780e-02, 1.3371e-01, 1.4354e-01, 7.3719e-01]], device='cuda:0')\n",
      "Predicted: \"[6478.863]\",\n",
      " Actual: \"[6356.9473]\", Last: [4849.3267]\n",
      "Year: \"[2020.]\"\n",
      "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.0000e+00, 2.8587e-01, 2.7188e-01, 1.7712e-02,\n",
      "         4.5095e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.3663e-01, 4.4134e-01,\n",
      "         6.1610e-01, 0.0000e+00, 3.2751e-01, 2.4762e-01, 2.6540e-01, 1.6790e-01,\n",
      "         2.6331e-01, 2.6798e-01, 0.0000e+00, 3.2027e-01, 3.4978e-01, 5.3379e-01,\n",
      "         3.2555e-01, 1.9064e-01, 6.6095e-01, 1.8301e-01, 2.7697e-01, 8.7299e-01,\n",
      "         5.3586e-01, 2.6362e-01, 2.1481e-01, 3.4237e-01, 1.0603e-01, 2.2396e-01,\n",
      "         0.0000e+00, 4.8041e-01, 4.0409e-02, 2.3948e-01, 0.0000e+00, 2.8322e-01,\n",
      "         9.3466e-01, 4.7264e-02, 4.9441e-01, 3.8932e-01, 4.2829e-01, 3.4018e-01,\n",
      "         5.8521e-01, 2.1800e-01, 6.8783e-01, 4.8100e-01, 9.7062e-01, 5.7086e-01,\n",
      "         3.9757e-01, 3.9054e-01, 4.4735e-01, 3.0119e-01, 4.7000e-01, 3.3950e-01,\n",
      "         5.5036e-01, 2.8382e-01, 7.1758e-01, 1.7766e-01, 3.6474e-01, 3.4213e-01,\n",
      "         3.7059e-01, 5.7048e-01, 7.3623e-02, 6.6814e-01, 6.3288e-01, 6.9236e-01,\n",
      "         6.3243e-01, 5.0513e-03, 9.0835e-02, 5.0445e-01, 6.5907e-02, 3.7349e-01,\n",
      "         7.5148e-01, 2.7560e-01, 2.4762e-01, 5.1839e-01, 1.9544e-01, 0.0000e+00,\n",
      "         1.3858e-02, 3.0071e-01, 2.7695e-01, 3.9046e-01]], device='cuda:0')\n",
      "Predicted: \"[9581.204]\",\n",
      " Actual: \"[10239.549]\", Last: [4849.3267]\n",
      "Year: \"[2020.]\"\n",
      "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.0000e+00, 5.9048e-02, 5.9122e-01, 4.0048e-02,\n",
      "         6.4525e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.8635e-01, 2.1787e-02,\n",
      "         9.5643e-01, 0.0000e+00, 1.5580e-01, 3.0261e-01, 3.1067e-01, 4.6827e-02,\n",
      "         3.6720e-01, 5.1101e-02, 0.0000e+00, 2.2942e-01, 5.4144e-01, 4.4663e-02,\n",
      "         3.5184e-01, 1.4037e-01, 3.1162e-01, 5.7423e-02, 2.5785e-01, 6.8237e-01,\n",
      "         1.0000e+00, 6.5027e-01, 5.1032e-01, 5.1922e-01, 1.3128e-01, 5.5910e-02,\n",
      "         1.8503e-01, 2.6798e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.3469e-01,\n",
      "         9.2121e-01, 6.3508e-02, 1.9649e-01, 1.3245e-01, 2.0877e-01, 5.3695e-02,\n",
      "         4.0019e-01, 2.9857e-01, 2.3431e-01, 2.3678e-01, 9.6425e-01, 7.4763e-01,\n",
      "         9.2365e-01, 9.5705e-01, 8.9117e-01, 7.0973e-01, 0.0000e+00, 2.2636e-01,\n",
      "         7.0416e-01, 2.4299e-01, 5.8944e-02, 4.6831e-01, 3.0804e-01, 7.8143e-01,\n",
      "         6.5872e-01, 8.8931e-01, 8.9217e-03, 3.8433e-01, 2.1784e-01, 2.1794e-01,\n",
      "         9.7111e-02, 2.1648e-02, 1.0740e-02, 3.5719e-01, 1.1301e-02, 7.6928e-01,\n",
      "         5.2753e-01, 3.2656e-01, 3.0261e-01, 5.4090e-01, 1.5846e-01, 0.0000e+00,\n",
      "         3.1817e-02, 7.7554e-02, 5.6703e-01, 8.1734e-02]], device='cuda:0')\n",
      "Predicted: \"[5150.3457]\",\n",
      " Actual: \"[5319.0884]\", Last: [4849.3267]\n",
      "Year: \"[2020.]\"\n",
      "[827.4951]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    i = 0\n",
    "    target = 10\n",
    "    mse = 0\n",
    "    for x, y in test_dataloader:\n",
    "        i += 1\n",
    "        # if i > target:\n",
    "        #     break\n",
    "\n",
    "        out = np.hstack((x[:,56:], y.reshape(-1,1)))\n",
    "        old_x = scaler.inverse_transform(out)\n",
    "        # print(old_x)\n",
    "        year = old_x[:, year_idx]\n",
    "        crime = old_x[:, idx]\n",
    "        # y = y * s + m\n",
    "\n",
    "        # year = x[:,0] * s_m + y_m\n",
    "        # print(encoder.inverse_transform(x[:,:56]))\n",
    "        x = x.to(device)\n",
    "        print(x)\n",
    "\n",
    "\n",
    "        \n",
    "        pred = model(x)\n",
    "        pred = pred.detach().cpu().numpy()\n",
    "        x = x.detach().cpu().numpy()\n",
    "        out = np.hstack((x[:,56:], pred.reshape(-1,1)))\n",
    "        out = scaler.inverse_transform(out)\n",
    "        pred = out[:, idx]\n",
    "        last = out2[:, last_idx]\n",
    "\n",
    "        print(f'Predicted: \"{pred}\",\\n Actual: \"{crime}\", Last: {last}')\n",
    "        print(f'Year: \"{year}\"')\n",
    "\n",
    "        mse += (pred - crime) ** 2\n",
    "\n",
    "    print(np.sqrt(mse / i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1060,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = best_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1088,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGA: whittlesea, Year: 2015\n",
      "NN: 7958.64, NULL: 7374.25, Actual: 6975.47\n",
      "LGA: greatergeelong, Year: 2015\n",
      "NN: 8654.94, NULL: 8223.40, Actual: 8950.48\n",
      "LGA: benalla, Year: 2015\n",
      "NN: 9661.80, NULL: 8459.15, Actual: 8259.71\n",
      "LGA: campaspe, Year: 2015\n",
      "NN: 9681.36, NULL: 8003.35, Actual: 8196.85\n",
      "LGA: glenelg, Year: 2015\n",
      "NN: 8274.86, NULL: 8821.98, Actual: 8026.57\n",
      "LGA: wellington, Year: 2015\n",
      "NN: 9488.20, NULL: 9133.65, Actual: 10182.53\n",
      "LGA: greaterbendigo, Year: 2015\n",
      "NN: 8959.93, NULL: 8095.27, Actual: 7652.76\n",
      "LGA: ballarat, Year: 2015\n",
      "NN: 10600.26, NULL: 10220.67, Actual: 11142.21\n",
      "LGA: swanhill, Year: 2015\n",
      "NN: 11424.93, NULL: 10469.61, Actual: 10855.31\n",
      "LGA: greatershepparton, Year: 2015\n",
      "NN: 12989.14, NULL: 11293.91, Actual: 11862.49\n",
      "LGA: eastgippsland, Year: 2015\n",
      "NN: 9782.70, NULL: 8898.22, Actual: 9345.19\n",
      "LGA: basscoast, Year: 2015\n",
      "NN: 7272.14, NULL: 8158.14, Actual: 8552.31\n",
      "LGA: surfcoast, Year: 2015\n",
      "NN: 4487.95, NULL: 5145.50, Actual: 5198.31\n",
      "LGA: macedonranges, Year: 2015\n",
      "NN: 4816.94, NULL: 4865.47, Actual: 4584.56\n",
      "LGA: boroondara, Year: 2015\n",
      "NN: 4656.53, NULL: 4238.62, Actual: 4267.17\n",
      "LGA: banyule, Year: 2015\n",
      "NN: 7704.80, NULL: 7285.30, Actual: 7317.11\n",
      "LGA: greaterdandenong, Year: 2015\n",
      "NN: 11474.34, NULL: 10468.48, Actual: 12481.02\n",
      "LGA: frankston, Year: 2015\n",
      "NN: 11126.61, NULL: 10889.55, Actual: 10756.22\n",
      "LGA: yarraranges, Year: 2015\n",
      "NN: 5524.96, NULL: 4913.42, Actual: 5156.10\n",
      "LGA: brimbank, Year: 2015\n",
      "NN: 9391.71, NULL: 8815.09, Actual: 9572.84\n",
      "LGA: maribyrnong, Year: 2015\n",
      "NN: 10013.53, NULL: 9897.23, Actual: 10235.54\n",
      "LGA: bayside, Year: 2015\n",
      "NN: 5165.35, NULL: 4558.40, Actual: 4448.59\n",
      "LGA: mooneevalley, Year: 2015\n",
      "NN: 7121.26, NULL: 7346.05, Actual: 8002.10\n",
      "LGA: greatergeelong, Year: 2016\n",
      "NN: 8960.12, NULL: 9005.49, Actual: 9586.31\n",
      "LGA: moorabool, Year: 2016\n",
      "NN: 6826.83, NULL: 7017.09, Actual: 7755.88\n",
      "LGA: glenelg, Year: 2016\n",
      "NN: 7966.65, NULL: 8127.90, Actual: 8467.03\n",
      "LGA: wellington, Year: 2016\n",
      "NN: 9902.85, NULL: 10175.77, Actual: 10905.12\n",
      "LGA: greatershepparton, Year: 2016\n",
      "NN: 13223.48, NULL: 11771.51, Actual: 12907.24\n",
      "LGA: eastgippsland, Year: 2016\n",
      "NN: 9921.93, NULL: 9380.41, Actual: 9118.42\n",
      "LGA: basscoast, Year: 2016\n",
      "NN: 7438.24, NULL: 8627.28, Actual: 8809.47\n",
      "LGA: macedonranges, Year: 2016\n",
      "NN: 4783.35, NULL: 4858.46, Actual: 5172.70\n",
      "LGA: horsham, Year: 2016\n",
      "NN: 13078.20, NULL: 15107.82, Actual: 14202.37\n",
      "LGA: wangaratta, Year: 2016\n",
      "NN: 8839.30, NULL: 8637.83, Actual: 9072.47\n",
      "LGA: merribek, Year: 2016\n",
      "NN: 8601.16, NULL: 8447.48, Actual: 8628.27\n",
      "LGA: maroondah, Year: 2016\n",
      "NN: 6944.47, NULL: 7041.35, Actual: 8013.07\n",
      "LGA: portphillip, Year: 2016\n",
      "NN: 11613.06, NULL: 11604.15, Actual: 12520.83\n",
      "LGA: frankston, Year: 2016\n",
      "NN: 11018.04, NULL: 10720.70, Actual: 12120.26\n",
      "LGA: yarraranges, Year: 2016\n",
      "NN: 5628.81, NULL: 5401.35, Actual: 5744.53\n",
      "LGA: brimbank, Year: 2016\n",
      "NN: 9611.79, NULL: 9596.65, Actual: 9375.09\n",
      "LGA: maribyrnong, Year: 2016\n",
      "NN: 10072.38, NULL: 10226.13, Actual: 10511.61\n",
      "LGA: mooneevalley, Year: 2016\n",
      "NN: 7253.77, NULL: 8104.66, Actual: 7827.72\n",
      "LGA: whittlesea, Year: 2017\n",
      "NN: 8155.71, NULL: 8149.16, Actual: 7265.91\n",
      "LGA: mitchell, Year: 2017\n",
      "NN: 11046.32, NULL: 11208.05, Actual: 10224.18\n",
      "LGA: campaspe, Year: 2017\n",
      "NN: 10508.51, NULL: 10231.05, Actual: 8934.10\n",
      "LGA: greatershepparton, Year: 2017\n",
      "NN: 13487.88, NULL: 12763.88, Actual: 12199.23\n",
      "LGA: merribek, Year: 2017\n",
      "NN: 8593.60, NULL: 8699.44, Actual: 7277.71\n",
      "LGA: banyule, Year: 2017\n",
      "NN: 7800.56, NULL: 8011.17, Actual: 7504.27\n",
      "LGA: frankston, Year: 2017\n",
      "NN: 11448.90, NULL: 12016.35, Actual: 10153.56\n",
      "LGA: yarraranges, Year: 2017\n",
      "NN: 5763.38, NULL: 5960.27, Actual: 5238.81\n",
      "LGA: whittlesea, Year: 2018\n",
      "NN: 7788.04, NULL: 7405.38, Actual: 7078.39\n",
      "LGA: greatergeelong, Year: 2018\n",
      "NN: 8973.30, NULL: 9349.94, Actual: 8202.23\n",
      "LGA: colacotway, Year: 2018\n",
      "NN: 8277.77, NULL: 8166.00, Actual: 7313.38\n",
      "LGA: alpine, Year: 2018\n",
      "NN: 3755.93, NULL: 3902.81, Actual: 4515.68\n",
      "LGA: benalla, Year: 2018\n",
      "NN: 9925.00, NULL: 9252.59, Actual: 8412.21\n",
      "LGA: wellington, Year: 2018\n",
      "NN: 9194.31, NULL: 8440.94, Actual: 9052.07\n",
      "LGA: eastgippsland, Year: 2018\n",
      "NN: 9620.62, NULL: 8650.32, Actual: 9613.70\n",
      "LGA: surfcoast, Year: 2018\n",
      "NN: 3823.85, NULL: 4013.63, Actual: 3618.32\n",
      "LGA: horsham, Year: 2018\n",
      "NN: 12117.12, NULL: 11881.96, Actual: 15056.82\n",
      "LGA: darebin, Year: 2018\n",
      "NN: 9614.48, NULL: 9479.60, Actual: 9698.10\n",
      "LGA: kingston, Year: 2018\n",
      "NN: 6935.33, NULL: 6855.75, Actual: 6806.44\n",
      "LGA: greaterdandenong, Year: 2018\n",
      "NN: 11413.47, NULL: 11052.16, Actual: 11092.51\n",
      "LGA: frankston, Year: 2018\n",
      "NN: 10612.40, NULL: 10148.25, Actual: 10507.24\n",
      "LGA: morningtonpeninsula, Year: 2018\n",
      "NN: 6755.94, NULL: 6818.32, Actual: 6482.19\n",
      "LGA: gleneira, Year: 2018\n",
      "NN: 4668.71, NULL: 4802.98, Actual: 4245.71\n",
      "LGA: mooneevalley, Year: 2018\n",
      "NN: 6672.52, NULL: 7078.33, Actual: 6863.66\n",
      "LGA: northerngrampians, Year: 2019\n",
      "NN: 9480.72, NULL: 8570.33, Actual: 9430.26\n",
      "LGA: greaterbendigo, Year: 2019\n",
      "NN: 9309.38, NULL: 9127.96, Actual: 9688.36\n",
      "LGA: ballarat, Year: 2019\n",
      "NN: 10422.26, NULL: 10094.37, Actual: 10696.62\n",
      "LGA: greatershepparton, Year: 2019\n",
      "NN: 13447.05, NULL: 12932.47, Actual: 13045.34\n",
      "LGA: mildura, Year: 2019\n",
      "NN: 12602.12, NULL: 12899.32, Actual: 13080.47\n",
      "LGA: wangaratta, Year: 2019\n",
      "NN: 8653.30, NULL: 8253.51, Actual: 8563.47\n",
      "LGA: boroondara, Year: 2019\n",
      "NN: 4134.68, NULL: 4179.60, Actual: 4530.15\n",
      "LGA: banyule, Year: 2019\n",
      "NN: 7469.98, NULL: 7393.00, Actual: 7284.45\n",
      "LGA: monash, Year: 2019\n",
      "NN: 5651.37, NULL: 5460.06, Actual: 5851.46\n",
      "LGA: frankston, Year: 2019\n",
      "NN: 10702.89, NULL: 10484.20, Actual: 10509.97\n",
      "LGA: casey, Year: 2019\n",
      "NN: 6423.65, NULL: 6409.66, Actual: 6401.03\n",
      "LGA: yarra, Year: 2019\n",
      "NN: 14374.85, NULL: 14112.60, Actual: 13987.40\n",
      "LGA: stonnington, Year: 2019\n",
      "NN: 9401.59, NULL: 9539.78, Actual: 10326.89\n",
      "LGA: bayside, Year: 2019\n",
      "NN: 4749.06, NULL: 4758.13, Actual: 4849.33\n",
      "LGA: whittlesea, Year: 2020\n",
      "NN: 7718.27, NULL: 7424.63, Actual: 7268.01\n",
      "LGA: greatergeelong, Year: 2020\n",
      "NN: 8570.79, NULL: 8429.21, Actual: 8630.79\n",
      "LGA: mitchell, Year: 2020\n",
      "NN: 10590.97, NULL: 10374.57, Actual: 11097.71\n",
      "LGA: alpine, Year: 2020\n",
      "NN: 3974.80, NULL: 4699.52, Actual: 4458.40\n",
      "LGA: benalla, Year: 2020\n",
      "NN: 9850.04, NULL: 9237.14, Actual: 9796.97\n",
      "LGA: glenelg, Year: 2020\n",
      "NN: 8063.88, NULL: 8457.30, Actual: 8371.98\n",
      "LGA: wodonga, Year: 2020\n",
      "NN: 8632.05, NULL: 8956.47, Actual: 8362.63\n",
      "LGA: greaterbendigo, Year: 2020\n",
      "NN: 9506.42, NULL: 9706.38, Actual: 9221.56\n",
      "LGA: ballarat, Year: 2020\n",
      "NN: 10621.85, NULL: 10664.09, Actual: 8745.58\n",
      "LGA: swanhill, Year: 2020\n",
      "NN: 11998.52, NULL: 12151.31, Actual: 11586.59\n",
      "LGA: greatershepparton, Year: 2020\n",
      "NN: 13364.00, NULL: 12895.05, Actual: 13377.34\n",
      "LGA: mildura, Year: 2020\n",
      "NN: 12587.67, NULL: 12928.43, Actual: 11462.46\n",
      "LGA: latrobe, Year: 2020\n",
      "NN: 18663.26, NULL: 17978.43, Actual: 17764.68\n",
      "LGA: macedonranges, Year: 2020\n",
      "NN: 4692.15, NULL: 5131.69, Actual: 5371.95\n",
      "LGA: merribek, Year: 2020\n",
      "NN: 8314.24, NULL: 8114.23, Actual: 7647.61\n",
      "LGA: banyule, Year: 2020\n",
      "NN: 7509.91, NULL: 7422.99, Actual: 7257.43\n",
      "LGA: portphillip, Year: 2020\n",
      "NN: 11211.61, NULL: 11167.23, Actual: 12275.94\n",
      "LGA: kingston, Year: 2020\n",
      "NN: 7246.48, NULL: 7551.27, Actual: 7127.01\n",
      "LGA: frankston, Year: 2020\n",
      "NN: 10756.98, NULL: 10486.79, Actual: 10397.28\n",
      "LGA: hobsonsbay, Year: 2020\n",
      "NN: 6577.58, NULL: 6674.73, Actual: 6119.15\n",
      "LGA: morningtonpeninsula, Year: 2020\n",
      "NN: 6683.46, NULL: 6820.07, Actual: 6658.01\n",
      "LGA: stonnington, Year: 2020\n",
      "NN: 9706.42, NULL: 10312.89, Actual: 10291.27\n",
      "null 743.3373428086953 nn 770.2005649770618 cheating 1744.7080315982562\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.formula.api import ols\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "def null_model(train_set, test_set):\n",
    "    text = f\"crime ~ last_crime\"\n",
    "    model = ols(text, data=train_set).fit()\n",
    "    pred = model.predict(test_set)\n",
    "    mse = mean_squared_error(test_set['crime'], pred)\n",
    "    return np.sqrt(mse), model\n",
    "\n",
    "\n",
    "def all_model(train_set, test_set):\n",
    "    columns = [\n",
    "        'ariamin',\n",
    "        'publichospitals', \n",
    "        'homelessness', \n",
    "        'mentalhealth',\n",
    "        'unemployedpersons', \n",
    "        'dwellingswithnomotorvehicle'\n",
    "    ]\n",
    "\n",
    "    text = f'crime ~  {\" + \".join(columns)}'\n",
    "    model = ols(text, data=train_set).fit()\n",
    "    pred = model.predict(test_set)\n",
    "    mse = mean_squared_error(test_set['crime'], pred)\n",
    "\n",
    "    return np.sqrt(mse), model\n",
    "\n",
    "train_set = actual.loc[train_data.index]\n",
    "test_set = actual.loc[test_data.index]\n",
    "mse, null = null_model(train_set, test_set)\n",
    "mse, cheating = all_model(train_set, test_set)\n",
    "# print(mse)\n",
    "\n",
    "mse = {\n",
    "    'null': 0,\n",
    "    'nn': 0,\n",
    "    'cheating': 0\n",
    "}\n",
    "\n",
    "model.eval()\n",
    "size = len(test_data.index)\n",
    "for i in test_data.index:\n",
    "    x = test_data.loc[i].copy()\n",
    "    row = actual.loc[i]\n",
    "\n",
    "    crime = actual.loc[i]['crime']\n",
    "    features = x.drop(labels=['crime'], axis=0).values\n",
    "    features = scaler_x.transform(features.reshape(1,-1))\n",
    "    features = torch.tensor(features).to(device).reshape(1, -1).to(torch.float)\n",
    "    pred = model(features)\n",
    "\n",
    "    pred = pred.detach().cpu().numpy()\n",
    "    features = features.detach().cpu().numpy()\n",
    "    # result = np.hstack((features[:,56:], pred.reshape(-1,1)))\n",
    "    # result = scaler.inverse_transform(result)\n",
    "    pred = scaler_y.inverse_transform(pred.reshape(-1, 1))[0,0]\n",
    "    # pred = result[:, idx].item()\n",
    "    null_result = null.predict(actual.loc[[i]].drop(columns=['crime'], axis=1)).values[0]\n",
    "    cheating_result =cheating.predict(actual.loc[[i]].drop(columns=['crime'], axis=1)).values[0] \n",
    "    print(f'LGA: {row[\"lga\"]}, Year: {row[\"year\"]}')\n",
    "    print(f\"NN: {pred:.2f}, NULL: {null_result:.2f}, Actual: {crime:.2f}\")\n",
    "    mse['null'] += (null_result-crime)**2\n",
    "    mse['nn'] += (pred - crime)**2\n",
    "    mse['cheating'] += (cheating_result - crime)**2\n",
    "\n",
    "print('null', np.sqrt(mse['null']/size), 'nn', np.sqrt(mse['nn']/size), 'cheating', np.sqrt(mse['cheating']/size))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
